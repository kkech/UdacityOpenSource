{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated Learning on Nepali Cash Recognition for Visually Impaired using Pytorch and Pysyft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYjhjAIV7W0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## New\n",
        "!pip install syft\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULtVxaisARB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from torchvision import transforms, models, datasets\n",
        "\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, Resize, ToTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUsTAVh57dXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e276LoQ7f3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1YjixsAkG1w4j13Bc9a0WqTVp6t3jCR7e'})\n",
        "download.GetContentFile('full_data.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kusptNE970j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get_ipython().system_raw(\"unrar x full_data.rar\")\n",
        "!unzip full_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx1PNVUe8YZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory for our dataset\n",
        "data_dir  = \"full_data\"\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJbRo-EB8m9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP9qP-0l8pwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## New\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 224\n",
        "        self.test_batch_size = 32\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = True\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AzK2dG484i1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## New ##\n",
        "# Defining transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                        [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "validation_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "        \n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhfNZT0Iqd-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomImageFolder(ImageFolder):\n",
        "    def __init__(self, root, transform=None, target_transform=None):\n",
        "        super(CustomImageFolder, self).__init__(str(root), transform, target_transform) \n",
        "        self.data = self.imgs\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = CustomImageFolder(train_dir, transform=train_transforms)\n",
        "\n",
        "federated_train_dataset = train_dataset.federate((bob, alice))\n",
        "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "validation_data = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  validation_data, batch_size=args.test_batch_size, shuffle=True, **kwargs\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC7Gs0hEIPyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.densenet169(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ4PACDSwBBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze the features part\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "# Build our own classifier\n",
        "# We will be using a sequential model,\n",
        "# In sequential model we will give it list of different operation\n",
        "# and it will pass in tensors automatically sequentially.\n",
        "\n",
        "\n",
        "num_features = 1664 # See the classifier part in the printed model above, it consist in_features=1664\n",
        "\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                              ('fc1', nn.Linear(num_features, 512)),\n",
        "                              ('relu_1', nn.ReLU()),\n",
        "                              ('drpot', nn.Dropout(p=0.5)),\n",
        "                              ('hidden', nn.Linear(512, 100)),\n",
        "                              ('relu_2', nn.ReLU()),\n",
        "                              ('drpot_2', nn.Dropout(p=0.5)),\n",
        "                              ('fc2', nn.Linear(100, 7)),\n",
        "                              ('output', nn.LogSoftmax(dim=1)),\n",
        "                              ]))\n",
        "\n",
        "model.classifier = classifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpuA22pN6KQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Move our model from CPU to GPU\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5-p7rgswHTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7OSh8XEwf9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.step()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DQrVqS-yHff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "%%time\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "  model.class_to_idx = train_loaders.dataset.class_to_idx\n",
        "  checkpoint = {'input_size': [3, 224, 224],\n",
        "                 'batch_size': train_loaders.batch_size,\n",
        "                  'output_size': 7,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'optimizer_dict':optimizer.state_dict(),\n",
        "                  'class_to_idx': model.class_to_idx,\n",
        "               }\n",
        "  torch.save(checkpoint, \"cash_recognition.pt\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOmtyGMiySpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading a trained model\n",
        "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = models.densenet169(pretrained=False)\n",
        "    \n",
        "    classifier = nn.Sequential(OrderedDict([\n",
        "                              ('fc1', nn.Linear(1664, 512)),\n",
        "                              ('relu_1', nn.ReLU()),\n",
        "                              ('drpot', nn.Dropout(p=0.5)),\n",
        "                              ('hidden', nn.Linear(512, 100)),\n",
        "                              ('relu_2', nn.ReLU()),\n",
        "                              ('drpot_2', nn.Dropout(p=0.5)),\n",
        "                              ('fc2', nn.Linear(100, 7)),\n",
        "                              ('output', nn.LogSoftmax(dim=1)),\n",
        "                              ]))\n",
        "    \n",
        "    model.classifier = classifier\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    return model, checkpoint['class_to_idx']\n",
        "\n",
        "# class_to_idx will be used later in predicting section."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYL5xQ4t0nuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loaded_model, class_to_idx = load_checkpoint('cash_recognition.pt')\n",
        "idx_to_class = { v : k for k,v in class_to_idx.items()}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMv3XNSs0vag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_image(image):\n",
        "\n",
        "    size = 256, 256\n",
        "    image.thumbnail(size, Image.ANTIALIAS)\n",
        "    image = image.crop((128 - 112, 128 - 112, 128 + 112, 128 + 112))\n",
        "    npImage = np.array(image)\n",
        "    npImage = npImage/255.\n",
        "        \n",
        "    imgA = npImage[:,:,0]\n",
        "    imgB = npImage[:,:,1]\n",
        "    imgC = npImage[:,:,2]\n",
        "    \n",
        "    imgA = (imgA - 0.485)/(0.229) \n",
        "    imgB = (imgB - 0.456)/(0.224)\n",
        "    imgC = (imgC - 0.406)/(0.225)\n",
        "        \n",
        "    npImage[:,:,0] = imgA\n",
        "    npImage[:,:,1] = imgB\n",
        "    npImage[:,:,2] = imgC\n",
        "    \n",
        "    npImage = np.transpose(npImage, (2,0,1))\n",
        "    \n",
        "    return npImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvRGAniR00o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4OeIZEL01f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(image_path, model, topk=5):\n",
        "    \n",
        "    image = torch.FloatTensor([process_image(Image.open(image_path))])\n",
        "    model.eval()\n",
        "    output = model.forward(Variable(image))\n",
        "    pobabilities = torch.exp(output).data.numpy()[0]\n",
        "    \n",
        "\n",
        "    top_idx = np.argsort(pobabilities)[-topk:][::-1] \n",
        "    top_class = [idx_to_class[x] for x in top_idx]\n",
        "    top_probability = pobabilities[top_idx]\n",
        "\n",
        "    return top_probability, top_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MncIZIkD04KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_classify(img, probabilities, classes, mapper):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    img_filename = img.split('/')[-2]\n",
        "    img = Image.open(img)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n",
        "    cash_name = mapper[img_filename]\n",
        "    \n",
        "    ax1.set_title(cash_name)\n",
        "    ax1.imshow(img)\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    y_pos = np.arange(len(probabilities))\n",
        "    ax2.barh(y_pos, probabilities)\n",
        "    ax2.set_yticks(y_pos)\n",
        "    ax2.set_yticklabels([mapper[x] for x in classes])\n",
        "    ax2.invert_yaxis()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kfX_Lh_07Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_to_name = {\n",
        "    \"fifty\": \"Fifty\",\n",
        "    \"five\" : \"Five\",\n",
        "    \"fivehundred\": \"Five_Hundred\",\n",
        "    \"hundred\":\"Hundred\",\n",
        "    \"ten\": \"Ten\",\n",
        "    \"thousand\":\"Thousand\",\n",
        "    \"twenty\": \"Twenty\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv6fzC8A08N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 'full_data/valid/thousand/thousand_valid_21.jpg'\n",
        "p, c = predict(img, loaded_model)\n",
        "view_classify(img, p, c, cat_to_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZctTQYku0_3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 'full_data/valid/fifty/fifty_valid_91.jpg'\n",
        "p, c = predict(img, loaded_model)\n",
        "view_classify(img, p, c, cat_to_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}