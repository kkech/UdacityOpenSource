{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APTOS_2019_cross_federated_learning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SsBaB18NQBp",
        "colab_type": "code",
        "outputId": "feeb69b9-6187-4d17-984c-76e075c6a1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install wheel\n",
        "! pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "! pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
        "! pip install syft\n",
        "! pip install opencv-python; pip install Pillow; pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (0.33.4)\n",
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n",
            "Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n",
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.23a1)\n",
            "Requirement already satisfied: tf-encrypted!=0.5.7,>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.8)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.2.1)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.3)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0.2)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.1.0)\n",
            "Requirement already satisfied: torch==1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: torchvision==0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted!=0.5.7,>=0.5.4->syft) (5.1.2)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: python-socketio>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.9.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=4.3.0->flask-socketio>=3.3.2->syft) (3.9.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.16.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43cd2zZhOpDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as utils\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import glob\n",
        "import sys\n",
        "sys.setrecursionlimit(100000)  # To increase the capacity of the stack "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0r3YjOyj2hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/content/train_images'\n",
        "\n",
        "train = pd.read_csv('/content/train.csv') \n",
        "test = pd.read_csv('/content/test.csv')\n",
        "sample_submission = pd.read_csv('/content/sample_submission.csv')\n",
        "\n",
        "train1, train2 = train_test_split(train, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI01h15ARhym",
        "colab_type": "code",
        "outputId": "ca77f395-2996-4319-b801-e5ed80663752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 15:21:48.695934 140394537088896 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0818 15:21:48.709644 140394537088896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuF3ZT1zT2_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 32\n",
        "        self.epochs = 15\n",
        "        self.lr = 0.005\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgwAuVmEgm8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source code: https://www.kaggle.com/orkatz2/diabetic-retinopathy-preprocess\n",
        "\n",
        "def estimate_radius(img):\n",
        "    mx = img[img.shape[0] // 2,:,:].sum(1)\n",
        "    rx = (mx > mx.mean() / 10).sum() / 2\n",
        "    my = img[:,img.shape[1] // 2,:].sum(1)\n",
        "    ry = (my > my.mean() / 10).sum() / 2\n",
        "    return (ry, rx)\n",
        "\n",
        "def subtract_gaussian_blur(img):\n",
        "    gb_img = cv2.GaussianBlur(img, (0, 0), 5)\n",
        "    return cv2.addWeighted(img, 4, gb_img, -4, 128)\n",
        "\n",
        "def remove_outer_circle(a, p, r):\n",
        "    b = np.zeros(a.shape, dtype=np.uint8)\n",
        "    cv2.circle(b, (a.shape[1] // 2, a.shape[0] // 2), int(r * p), (1, 1, 1), -1, 8, 0)\n",
        "    return a * b + 128 * (1 - b)\n",
        "\n",
        "def crop_img(img, h, w):\n",
        "        h_margin = (img.shape[0] - h) // 2 if img.shape[0] > h else 0\n",
        "        w_margin = (img.shape[1] - w) // 2 if img.shape[1] > w else 0\n",
        "        crop_img = img[h_margin:h + h_margin,w_margin:w + w_margin,:]\n",
        "        return crop_img\n",
        "\n",
        "def place_in_square(img, r, h, w):\n",
        "    new_img = np.zeros((2 * r, 2 * r, 3), dtype=np.uint8)\n",
        "    new_img += 128\n",
        "    new_img[r - h // 2:r - h // 2 + img.shape[0], r - w // 2:r - w // 2 + img.shape[1]] = img\n",
        "    return new_img\n",
        "\n",
        "def preprocess(f, r, debug_plot=False):\n",
        "    img = cv2.imread(f)\n",
        "    ry, rx = estimate_radius(img)\n",
        "    resize_scale = r / max(rx, ry)\n",
        "    w = min(int(rx * resize_scale * 2), r * 2)\n",
        "    h = min(int(ry * resize_scale * 2), r * 2)\n",
        "    img = cv2.resize(img, (0,0), fx=resize_scale, fy=resize_scale)\n",
        "    img = crop_img(img, h, w)\n",
        "    if debug_plot:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(img)\n",
        "    img = subtract_gaussian_blur(img)\n",
        "    img = remove_outer_circle(img, 0.9, r)\n",
        "    img = place_in_square(img, r, h, w)\n",
        "    if debug_plot:\n",
        "        plt.figure()\n",
        "        plt.imshow(img)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp9TfoAAeobq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source Code: https://www.kaggle.com/artgor/basic-eda-and-baseline-pytorch-model\n",
        "\n",
        "class ImagesData(Dataset):\n",
        "    \n",
        "    def __init__(self, df, datatype):\n",
        "        self.datatype = datatype\n",
        "        self.image_files = [f'../input/{self.datatype}_images/{i}.png' for i in df['id_code'].values]\n",
        "        self.labels = df['diagnosis']\n",
        "        if self.datatype = 'train':\n",
        "            self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                             transforms.RandomVerticalFlip(p=0.25),\n",
        "                                             transforms.RandomHorizontalFlip(p=0.25), \n",
        "                                             transforms.ToTensor()])\n",
        "        if self.datatype = 'test':\n",
        "            self.transform = transforms.Compose([transform.ToPILImage(),\n",
        "                                                transforms.ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        size= 512\n",
        "        r=size//2\n",
        "        image = cv2.imread(self.image_files[index])\n",
        "        ry, rx = estimate_radius(image)\n",
        "        resize_scale = r / max(rx, ry)\n",
        "        w = min(int(rx * resize_scale * 2), r*2)\n",
        "        h = min(int(ry * resize_scale * 2), r*2)\n",
        "        image = cv2.resize(image, (0,0), fx=resize_scale, fy=resize_scale)\n",
        "        image = crop_img(image, h, w)\n",
        "        image = subtract_gaussian_blur(image)\n",
        "        image = remove_outer_circle(image, 0.9, r)\n",
        "        image = place_in_square(image, r, h, w)\n",
        "        #convert to grayscale\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        image = clahe.apply(image)\n",
        "        image_out = self.transform(image)\n",
        "        try:\n",
        "            label = torch.tensor(self.labels[index])\n",
        "        except:\n",
        "            label = torch.tensor(self.labels[index+len(train1)])\n",
        "        return image_out, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL2DzoJdUpxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    federated_dataset=ImagesData(df=train1, datatype='train'),\n",
        "    shuffle=True,\n",
        "    batch_size=64).federate((bob, alice)) # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "\n",
        "    \n",
        "    \n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    federated_dataset=ImagesData(df=train2, datatype='test'), \n",
        "    batch_size=32, \n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naWblBn9V1Dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class APTOSNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(APTOSNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(128*32*32, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 5)\n",
        "        self.drop = nn.Dropout2d(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.view(out.size(0), -1)    # flatten out a input for Dense Layer\n",
        "        out = self.fc1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3fg59vlWMLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QErsA88XeyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ouSUcktCbxXC",
        "colab": {}
      },
      "source": [
        "model = APTOSNet().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"aptos_cnn.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}