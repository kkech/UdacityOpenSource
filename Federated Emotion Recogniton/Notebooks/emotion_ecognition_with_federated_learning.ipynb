{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "emotion_ecognition_with_federated_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rupaai/caffeine_coders_emotion_recognition/blob/master/emotion_ecognition_with_federated_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh8tbVe1htu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne_Pp_VchtvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meFKh0n8tQlM",
        "colab_type": "code",
        "outputId": "21bc60bd-cdd3-454c-ee27-a909cd301cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tf-encrypted\n",
        "\n",
        "! URL=\"https://github.com/openmined/PySyft.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft; python setup.py install  > /dev/null\n",
        "\n",
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('./PySyft'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-encrypted in /usr/local/lib/python3.6/dist-packages (0.5.8)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.16.4)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (5.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (0.15.5)\n",
            "From https://github.com/openmined/PySyft\n",
            " * branch              HEAD       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Collecting lz4\n",
            "  Using cached https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: syft 0.1.23a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: lz4\n",
            "  Found existing installation: lz4 2.1.10\n",
            "    Uninstalling lz4-2.1.10:\n",
            "      Successfully uninstalled lz4-2.1.10\n",
            "Successfully installed lz4-2.1.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "lz4"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting websocket\n",
            "Collecting greenlet (from websocket)\n",
            "  Using cached https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting gevent (from websocket)\n",
            "  Using cached https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: greenlet, gevent, websocket\n",
            "  Found existing installation: greenlet 0.4.15\n",
            "    Uninstalling greenlet-0.4.15:\n",
            "      Successfully uninstalled greenlet-0.4.15\n",
            "  Found existing installation: gevent 1.4.0\n",
            "    Uninstalling gevent-1.4.0:\n",
            "      Successfully uninstalled gevent-1.4.0\n",
            "  Found existing installation: websocket 0.2.1\n",
            "    Uninstalling websocket-0.2.1:\n",
            "      Successfully uninstalled websocket-0.2.1\n",
            "Successfully installed gevent-1.4.0 greenlet-0.4.15 websocket-0.2.1\n",
            "Collecting websockets\n",
            "  Using cached https://files.pythonhosted.org/packages/f0/4b/ad228451b1c071c5c52616b7d4298ebcfcac5ae8515ede959db19e4cd56d/websockets-8.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: syft 0.1.23a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: websockets\n",
            "  Found existing installation: websockets 8.0.2\n",
            "    Uninstalling websockets-8.0.2:\n",
            "      Successfully uninstalled websockets-8.0.2\n",
            "Successfully installed websockets-8.0.2\n",
            "Collecting zstd\n",
            "\u001b[31mERROR: syft 0.1.23a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: zstd\n",
            "  Found existing installation: zstd 1.4.1.0\n",
            "    Uninstalling zstd-1.4.1.0:\n",
            "      Successfully uninstalled zstd-1.4.1.0\n",
            "Successfully installed zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmTM-h8LiUz7",
        "colab_type": "code",
        "outputId": "ed5bd800-c261-404a-91fb-02b1e7e7aa34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "# Create a couple of workers\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  \n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 19:52:14.407905 139985039218560 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0820 19:52:14.427928 139985039218560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE1RBUt0htvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def covert_into_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,'wb'))\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Fd-DBmi3zQ",
        "colab_type": "code",
        "outputId": "3e36a5d9-3126-4054-ff0e-0562c6aee89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwr_zutrhtvX",
        "colab_type": "code",
        "outputId": "79cbbab4-3c35-45ee-bceb-3a13564b1a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "#load data\n",
        "data = load_from_pickle(directory='/gdrive/My Drive/Resources/Dataset/emotion-detection/merged_training.pkl')\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f503f0e2e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERtf1/4EfnAP+MudQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_kDCyZhtvg",
        "colab_type": "code",
        "outputId": "215fb6df-880c-4f4e-f839-d30121accb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(data.shape)\n",
        "print(type(data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(416809, 2)\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzwaTnchtvn",
        "colab_type": "code",
        "outputId": "57dbae9f-f18d-491d-ee2c-d911b2df064f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27383</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110083</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140764</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100071</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2837</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "27383   i feel awful about it too because it s my job ...  sadness\n",
              "110083                              im alone i feel awful  sadness\n",
              "140764  ive probably mentioned this before but i reall...      joy\n",
              "100071           i was feeling a little low few days back  sadness\n",
              "2837    i beleive that i am much more sensitive to oth...     love"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDD3WA51htvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copying data with number of tokens less than 70\n",
        "data[\"token size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data[\"token size\"] < 70].copy()\n",
        "\n",
        "#sampling data\n",
        "data = data.sample(n=50000, replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3nzD7whtv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "#import nltk\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAiMtuMnhtv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConstructDictionary():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2index = {}\n",
        "        self.index2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        \n",
        "        #creating tokens from sentences and adding them to dictionary\n",
        "        for sentence in self.sentences:\n",
        "            self.vocab.update(word_tokenize(sentence))\n",
        "            \n",
        "        #sorting the dictionary\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        \n",
        "        #adding padding token to 0 index\n",
        "        self.word2index['<pad>'] = 0\n",
        "           \n",
        "        #creating a word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2index[word] = index + 1         #adding 1 becuase of padding element at 0 index\n",
        "            \n",
        "        #creating a index to word mapping\n",
        "        for index, word in self.word2index.items():\n",
        "            self.index2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayaey_t4htwD",
        "colab_type": "code",
        "outputId": "aaa5a47b-b03e-4d20-a74d-0ddb96d56ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "inputs = ConstructDictionary(data[\"text\"].values.tolist())\n",
        "inputs.vocab[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaaaall',\n",
              " 'aactually',\n",
              " 'aad',\n",
              " 'aaishwaryaa',\n",
              " 'aakash',\n",
              " 'aardvarkartglass',\n",
              " 'aaron']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZgGx3ghtwL",
        "colab_type": "code",
        "outputId": "8cd89d91-7f0a-47be-cc70-2c7e13b615b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(inputs.vocab)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1njUEuBQhtwV",
        "colab_type": "code",
        "outputId": "8febc995-5927-450e-dfb9-c83c30aba833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "input_tensors = [[inputs.word2index[word] for word in word_tokenize(sentence) ] for sentence in data['text'].values.tolist() ]\n",
        "input_tensors[:2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11378,\n",
              "  8598,\n",
              "  25779,\n",
              "  1,\n",
              "  11210,\n",
              "  17426,\n",
              "  14363,\n",
              "  21304,\n",
              "  13174,\n",
              "  11409,\n",
              "  17413,\n",
              "  9917,\n",
              "  3244,\n",
              "  26582,\n",
              "  4191,\n",
              "  17413,\n",
              "  9917,\n",
              "  3244,\n",
              "  22075,\n",
              "  26582,\n",
              "  10192,\n",
              "  16341,\n",
              "  23587],\n",
              " [11378, 9123, 16344, 10379, 2071, 7060, 4899, 871, 25613, 8608, 17653, 7316]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXxqSUVhtwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7A6E0gIhtwn",
        "colab_type": "code",
        "outputId": "63fff37f-a156-499b-f062-54f6cbe9bc7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_length_input = max_length(input_tensors)\n",
        "print(max_length_input)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLLtdK88htwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len=max_length_input):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVekMjUKhtwz",
        "colab_type": "code",
        "outputId": "363ba4f0-5f8c-4277-ecd5-2bc736713087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "input_tensors = [pad_sequences(x, max_length_input) for x in input_tensors]\n",
        "input_tensors[:2]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([11378,  8598, 25779,     1, 11210, 17426, 14363, 21304, 13174,\n",
              "        11409, 17413,  9917,  3244, 26582,  4191, 17413,  9917,  3244,\n",
              "        22075, 26582, 10192, 16341, 23587,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([11378,  9123, 16344, 10379,  2071,  7060,  4899,   871, 25613,\n",
              "         8608, 17653,  7316,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJzGHvyRhtw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we are using transforming our target values using one-hot encoding\n",
        "\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "\n",
        "data_labels = [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1sm89-Khtw_",
        "colab_type": "code",
        "outputId": "0decc603-91ef-4057-eb6c-8c1883af61e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor[:2]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJoH_SIhtxK",
        "colab_type": "code",
        "outputId": "b701cff8-96c6-40e4-8598-26d2a741d106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75181</th>\n",
              "      <td>i feel welcomed a href photos martatom sizes l...</td>\n",
              "      <td>joy</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77509</th>\n",
              "      <td>i for one had been drinking constantly and was...</td>\n",
              "      <td>joy</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text emotions  token size\n",
              "75181  i feel welcomed a href photos martatom sizes l...      joy          23\n",
              "77509  i for one had been drinking constantly and was...      joy          12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sg2_4mvhtxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emotion(x):\n",
        "    return np.argmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dOo1JfThtxa",
        "colab_type": "code",
        "outputId": "32328fb5-1a64-4410-f644-996ce11676a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5vkesnMhtxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5azl83WJhtx3",
        "colab_type": "code",
        "outputId": "45ce9164-ad53-4b84-933a-e5e02b442783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'joy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkAKaQ9Ohtx8",
        "colab_type": "code",
        "outputId": "eda1222a-dd94-4b8d-e4ee-42f69852f195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensors, target_tensor, test_size=0.2)\n",
        "\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 40000, 5000, 5000, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbM3x4v8htyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2index)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixHQIf5nhtyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ffJwLzhtyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRmE0hXAtXBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amr8h84ttAv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cH5v6JvhtyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = sy.BaseDataset(input_tensor_train, target_tensor_train).federate((alice,bob))\n",
        "val_dataset = sy.BaseDataset(input_tensor_val, target_tensor_val).federate((alice,bob))\n",
        "test_dataset = sy.BaseDataset(input_tensor_test, target_tensor_test).federate((alice,bob))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "federated_train_loader = sy.FederatedDataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "federated_val_loader = sy.FederatedDataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "federated_test_loader = sy.FederatedDataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udCamEpjhtyb",
        "colab_type": "code",
        "outputId": "611af396-66b9-41ba-f738-3936dd84180c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "input, labels = next(iter(federated_train_loader))\n",
        "print(input[0].get(), labels[0].get())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([11378,  8598,  2782, 23844,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0]) tensor([1, 0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvWr6JoNxDiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dNkVDtDxKIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWYN-1RVxQQi",
        "colab_type": "code",
        "outputId": "63cbf38f-2731-46e8-b3d6-734effda14e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(federated_train_loader)\n",
        "x, y = next(it)\n",
        "\n",
        "model.send(x.location)\n",
        "x = x.transpose(0,1)\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "#xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", x.get().size())\n",
        "\n",
        "output, _ = model(x.to(device), device)\n",
        "model.get()\n",
        "print(output.size())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([69, 64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    300\u001b[0m             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.unwrap_args_from_function(\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36munwrap_args_from_function\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mfive_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a0e033cad5b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input size: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-599a384d97fb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# max_len X batch_size X hidden_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m         return F.embedding(\n\u001b[1;32m    116\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.1.23a1-py3.6.egg/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUType instead (while checking arguments for embedding)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epSEEYlBxVV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJiNky4fkmm0",
        "colab_type": "code",
        "outputId": "6e8dca40-8dc7-473b-cf47-650fe7d6ae41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    batch = 1\n",
        "    \n",
        "    ### Training\n",
        "    #model.train()\n",
        "    \n",
        "    for input, label in federated_train_loader:\n",
        "        loss = 0\n",
        "        print(\"i\")\n",
        "        #print(model.location)\n",
        "        \n",
        "        model = model.send(input.location)\n",
        "        \n",
        "        predictions, _ = model.forward(input.to(device), device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(label.to(device), predictions).get()\n",
        "        batch_loss = (loss / int(label.shape[1])).get()  \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(label.to(device), predictions).get()\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        model = model.get()\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "        batch += 1\n",
        "            \n",
        "    ### Validating\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for input, label in federated_val_loader: \n",
        "          model = model.send(input.location)\n",
        "          predictions,_ = model(input.permute(1, 0).to(device), device)        \n",
        "          batch_accuracy = accuracy(label.to(device), predictions).get()\n",
        "          val_accuracy += batch_accuracy\n",
        "          model = model.get()\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "  \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} '.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             ))\n",
        "  \n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-de40e5623954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO:don't need _\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-599a384d97fb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# max_len X batch_size X hidden_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvq9htcTqhYA",
        "colab_type": "code",
        "outputId": "49ceca0c-e966-4e18-c7ce-b034098e2ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.get()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmoGRU(\n",
              "  (embedding): Embedding(26592, 256)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}