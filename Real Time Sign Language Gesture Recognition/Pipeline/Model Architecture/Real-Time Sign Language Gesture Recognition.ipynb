{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport pickle\nfrom os.path import join, exists\nimport argparse\nfrom tqdm import tqdm\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torchvision import transforms, utils\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, let's check the number of classes there are in our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = os.listdir('../input/lsa64-hand-gesture-recognition-dataset/lsa40/LSA40/train')\nprint(len(classes))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to have the classes and video names in a DataFrame so that our dataloader can access it easily. "},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = []\nfor dirname, _, filenames in os.walk('/kaggle/input/lsa64-hand-gesture-recognition-dataset/lsa40/LSA40/train'):\n\n    for filename in filenames:\n        dataset.append([dirname[71:],filename])\n\nprint(len(dataset))\n\ndf = pd.DataFrame(dataset,columns=['Gesture','File'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to encode the categorical values in Gesture column to numerical values so that our model can use it"},{"metadata":{"trusted":true},"cell_type":"code","source":"#TODO: Setting categorical values to integers starting from 0\ndf['Folder'] = df['Gesture']\nencode_dict = {k: v for v, k in enumerate(classes)}\ndf.replace({\"Gesture\": encode_dict},inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting in Training and Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,valid_df = np.split(df, [int(.8*len(df))])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Configuration Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config():\n    rootDir = '../input/lsa64-hand-gesture-recognition-dataset/lsa40/LSA40/train/'\n    batch_size = 8\n    train_number_epochs = 10\n    num_workers = 8","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{},"cell_type":"markdown","source":"On exploring the dataset, it is found that for the videos in training dataset, minimum number of frames is 58 and maximum number of frames is 212. So, we'll work on an input size of 200 frames"},{"metadata":{"trusted":true},"cell_type":"code","source":"class videoDataset(Dataset):\n    \"\"\"Dataset Class for Loading Video\"\"\"\n\n    def __init__(self, df, rootDir, channels, timeDepth, xSize, ySize, transform=None):\n        \"\"\"\n        Args:\n            clipsList (string): Path to the clipsList file with labels.\n            rootDir (string): Directory with all the videoes.\n            transform (callable, optional): Optional transform to be applied\n                    on a sample.\n            channels: Number of channels of frames\n            timeDepth: Number of frames to be loaded in a sample\n            xSize, ySize: Dimensions of the frames\n            mean: Mean valuse of the training set videos over each channel\n        \"\"\"\n        self.df = df\n        self.rootDir = rootDir\n        self.channels = channels\n        self.timeDepth = timeDepth\n        self.xSize = xSize\n        self.ySize = ySize\n        self.transform = transform\n        self.length = 0\n\n    def __len__(self):\n        return len(self.df)\n    \n    def handsegment(self,frame):\n        \n        boundaries = [([0, 120, 0], [140, 255, 100]),\n                        ([25, 0, 75], [180, 38, 255])]\n        \n        lower, upper = boundaries[0]\n        lower = np.array(lower, dtype=\"uint8\")\n        upper = np.array(upper, dtype=\"uint8\")\n        mask1 = cv2.inRange(frame, lower, upper)\n\n        lower, upper = boundaries[1]\n        lower = np.array(lower, dtype=\"uint8\")\n        upper = np.array(upper, dtype=\"uint8\")\n        mask2 = cv2.inRange(frame, lower, upper)\n\n        mask = cv2.bitwise_or(mask1, mask2)\n        output = cv2.bitwise_and(frame, frame, mask=mask)\n        return output\n\n    def readVideo(self, videoFilePath):\n        # Open the video file\n        cap = cv2.VideoCapture(videoFilePath)\n        self.length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        # nFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        frames = torch.zeros(self.timeDepth,self.channels,self.xSize,self.ySize)\n        \n        f=0\n        while f<self.timeDepth:\n            ret, frame = cap.read()\n            if ret:\n                frame = self.handsegment(frame)\n                frame = torch.from_numpy(frame)\n                frame = frame.permute(2, 1, 0)\n                # HWC2CHW\n                if self.transform:\n                    frame = self.transform(frame)\n                frames[f,:, :, :] = frame\n            else:\n                \n                break\n            f+=1\n\n#         for c in range(3):\n#             frames[c] -= self.mean[c]\n#         frames /= 255\n        return frames\n\n    def __getitem__(self, idx):\n        label = self.df.iloc[idx,0]\n        fileName = self.df.iloc[idx,1]\n        folder = self.df.iloc[idx,2]\n        \n        videoFilePath = self.rootDir + folder +'/' + fileName\n        clip = self.readVideo(videoFilePath)\n        \n        sample = {'clip': clip, 'label': label}\n\n        return clip,label\n#         cap = cv2.VideoCapture(videoFilePath)\n#         length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        \n#         return length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize(299),\n    transforms.CenterCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ntrain_dataset = videoDataset(df=train_df, rootDir=Config.rootDir, channels=3, timeDepth=200, xSize=299, ySize=299, transform = transform)\nvalid_dataset = videoDataset(df=valid_df, rootDir=Config.rootDir, channels=3, timeDepth=200, xSize=299, ySize=299, transform = transform)\n#train_loader = torch.utils.data.DataLoader(dataset,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataloaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img,text=None,should_save=False):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    if text:\n        plt.text(75, 8, text, style='italic',fontweight='bold',\n            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()    \n\ndef show_plot(iteration,loss):\n    plt.plot(iteration,loss)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clip = train_dataset.__getitem__(0)[0]\nimshow(clip[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check CUDA Availability"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking if CUDA is available or not\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN Encoder - Inception v3"},{"metadata":{},"cell_type":"markdown","source":"Our idea is to take the video, split into frames, and then feed these frames to RNN. These individual frames are input into Inception pretrained model to get spatial information.\n**Input size for each image** = 3 x 299 x 299\n**Output** = 1 x 1000\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Inception_v3_pt_mcn(nn.Module):\n\n    def __init__(self):\n        super(Inception_v3_pt_mcn, self).__init__()\n        self.meta = {'mean': [0.485, 0.456, 0.406],\n                     'std': [0.229, 0.224, 0.225],\n                     'imageSize': [299, 299]}\n        self.features_0_conv = nn.Conv2d(3, 32, kernel_size=[3, 3], stride=(2, 2), bias=False)\n        self.features_0_bn = nn.BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n        self.features_0_relu = nn.ReLU()\n        self.features_1_conv = nn.Conv2d(32, 32, kernel_size=[3, 3], stride=(1, 1), bias=False)\n        self.features_1_bn = nn.BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n        self.features_1_relu = nn.ReLU()\n        self.features_2_conv = nn.Conv2d(32, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_2_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_2_relu = nn.ReLU()\n        self.features_3 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n        self.features_4_conv = nn.Conv2d(64, 80, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_4_bn = nn.BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True)\n        self.features_4_relu = nn.ReLU()\n        self.features_5_conv = nn.Conv2d(80, 192, kernel_size=[3, 3], stride=(1, 1), bias=False)\n        self.features_5_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_5_relu = nn.ReLU()\n        self.features_6 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n        self.features_7_branch1x1_conv = nn.Conv2d(192, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_7_branch1x1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch1x1_relu = nn.ReLU()\n        self.features_7_branch5x5_1_conv = nn.Conv2d(192, 48, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_7_branch5x5_1_bn = nn.BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch5x5_1_relu = nn.ReLU()\n        self.features_7_branch5x5_2_conv = nn.Conv2d(48, 64, kernel_size=[5, 5], stride=(1, 1), padding=(2, 2), bias=False)\n        self.features_7_branch5x5_2_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch5x5_2_relu = nn.ReLU()\n        self.features_7_branch3x3dbl_1_conv = nn.Conv2d(192, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_7_branch3x3dbl_1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch3x3dbl_1_relu = nn.ReLU()\n        self.features_7_branch3x3dbl_2_conv = nn.Conv2d(64, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_7_branch3x3dbl_2_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch3x3dbl_2_relu = nn.ReLU()\n        self.features_7_branch3x3dbl_3_conv = nn.Conv2d(96, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_7_branch3x3dbl_3_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch3x3dbl_3_relu = nn.ReLU()\n        self.features_7_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_7_branch_pool_conv = nn.Conv2d(192, 32, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_7_branch_pool_bn = nn.BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n        self.features_7_branch_pool_relu = nn.ReLU()\n        self.features_8_branch1x1_conv = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_8_branch1x1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch1x1_relu = nn.ReLU()\n        self.features_8_branch5x5_1_conv = nn.Conv2d(256, 48, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_8_branch5x5_1_bn = nn.BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch5x5_1_relu = nn.ReLU()\n        self.features_8_branch5x5_2_conv = nn.Conv2d(48, 64, kernel_size=[5, 5], stride=(1, 1), padding=(2, 2), bias=False)\n        self.features_8_branch5x5_2_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch5x5_2_relu = nn.ReLU()\n        self.features_8_branch3x3dbl_1_conv = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_8_branch3x3dbl_1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch3x3dbl_1_relu = nn.ReLU()\n        self.features_8_branch3x3dbl_2_conv = nn.Conv2d(64, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_8_branch3x3dbl_2_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch3x3dbl_2_relu = nn.ReLU()\n        self.features_8_branch3x3dbl_3_conv = nn.Conv2d(96, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_8_branch3x3dbl_3_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch3x3dbl_3_relu = nn.ReLU()\n        self.features_8_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_8_branch_pool_conv = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_8_branch_pool_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_8_branch_pool_relu = nn.ReLU()\n        self.features_9_branch1x1_conv = nn.Conv2d(288, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_9_branch1x1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch1x1_relu = nn.ReLU()\n        self.features_9_branch5x5_1_conv = nn.Conv2d(288, 48, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_9_branch5x5_1_bn = nn.BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch5x5_1_relu = nn.ReLU()\n        self.features_9_branch5x5_2_conv = nn.Conv2d(48, 64, kernel_size=[5, 5], stride=(1, 1), padding=(2, 2), bias=False)\n        self.features_9_branch5x5_2_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch5x5_2_relu = nn.ReLU()\n        self.features_9_branch3x3dbl_1_conv = nn.Conv2d(288, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_9_branch3x3dbl_1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch3x3dbl_1_relu = nn.ReLU()\n        self.features_9_branch3x3dbl_2_conv = nn.Conv2d(64, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_9_branch3x3dbl_2_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch3x3dbl_2_relu = nn.ReLU()\n        self.features_9_branch3x3dbl_3_conv = nn.Conv2d(96, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_9_branch3x3dbl_3_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch3x3dbl_3_relu = nn.ReLU()\n        self.features_9_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_9_branch_pool_conv = nn.Conv2d(288, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_9_branch_pool_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_9_branch_pool_relu = nn.ReLU()\n        self.features_10_branch3x3_conv = nn.Conv2d(288, 384, kernel_size=[3, 3], stride=(2, 2), bias=False)\n        self.features_10_branch3x3_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_10_branch3x3_relu = nn.ReLU()\n        self.features_10_branch3x3dbl_1_conv = nn.Conv2d(288, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_10_branch3x3dbl_1_bn = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n        self.features_10_branch3x3dbl_1_relu = nn.ReLU()\n        self.features_10_branch3x3dbl_2_conv = nn.Conv2d(64, 96, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_10_branch3x3dbl_2_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_10_branch3x3dbl_2_relu = nn.ReLU()\n        self.features_10_branch3x3dbl_3_conv = nn.Conv2d(96, 96, kernel_size=[3, 3], stride=(2, 2), bias=False)\n        self.features_10_branch3x3dbl_3_bn = nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n        self.features_10_branch3x3dbl_3_relu = nn.ReLU()\n        self.features_10_branch_pool = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n        self.features_11_branch1x1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_11_branch1x1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch1x1_relu = nn.ReLU()\n        self.features_11_branch7x7_1_conv = nn.Conv2d(768, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_11_branch7x7_1_bn = nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7_1_relu = nn.ReLU()\n        self.features_11_branch7x7_2_conv = nn.Conv2d(128, 128, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_11_branch7x7_2_bn = nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7_2_relu = nn.ReLU()\n        self.features_11_branch7x7_3_conv = nn.Conv2d(128, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_11_branch7x7_3_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7_3_relu = nn.ReLU()\n        self.features_11_branch7x7dbl_1_conv = nn.Conv2d(768, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_11_branch7x7dbl_1_bn = nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7dbl_1_relu = nn.ReLU()\n        self.features_11_branch7x7dbl_2_conv = nn.Conv2d(128, 128, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_11_branch7x7dbl_2_bn = nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7dbl_2_relu = nn.ReLU()\n        self.features_11_branch7x7dbl_3_conv = nn.Conv2d(128, 128, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_11_branch7x7dbl_3_bn = nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7dbl_3_relu = nn.ReLU()\n        self.features_11_branch7x7dbl_4_conv = nn.Conv2d(128, 128, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_11_branch7x7dbl_4_bn = nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7dbl_4_relu = nn.ReLU()\n        self.features_11_branch7x7dbl_5_conv = nn.Conv2d(128, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_11_branch7x7dbl_5_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch7x7dbl_5_relu = nn.ReLU()\n        self.features_11_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_11_branch_pool_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_11_branch_pool_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_11_branch_pool_relu = nn.ReLU()\n        self.features_12_branch1x1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_12_branch1x1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch1x1_relu = nn.ReLU()\n        self.features_12_branch7x7_1_conv = nn.Conv2d(768, 160, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_12_branch7x7_1_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7_1_relu = nn.ReLU()\n        self.features_12_branch7x7_2_conv = nn.Conv2d(160, 160, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_12_branch7x7_2_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7_2_relu = nn.ReLU()\n        self.features_12_branch7x7_3_conv = nn.Conv2d(160, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_12_branch7x7_3_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7_3_relu = nn.ReLU()\n        self.features_12_branch7x7dbl_1_conv = nn.Conv2d(768, 160, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_12_branch7x7dbl_1_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7dbl_1_relu = nn.ReLU()\n        self.features_12_branch7x7dbl_2_conv = nn.Conv2d(160, 160, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_12_branch7x7dbl_2_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7dbl_2_relu = nn.ReLU()\n        self.features_12_branch7x7dbl_3_conv = nn.Conv2d(160, 160, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_12_branch7x7dbl_3_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7dbl_3_relu = nn.ReLU()\n        self.features_12_branch7x7dbl_4_conv = nn.Conv2d(160, 160, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_12_branch7x7dbl_4_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7dbl_4_relu = nn.ReLU()\n        self.features_12_branch7x7dbl_5_conv = nn.Conv2d(160, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_12_branch7x7dbl_5_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch7x7dbl_5_relu = nn.ReLU()\n        self.features_12_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_12_branch_pool_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_12_branch_pool_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_12_branch_pool_relu = nn.ReLU()\n        self.features_13_branch1x1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_13_branch1x1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch1x1_relu = nn.ReLU()\n        self.features_13_branch7x7_1_conv = nn.Conv2d(768, 160, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_13_branch7x7_1_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7_1_relu = nn.ReLU()\n        self.features_13_branch7x7_2_conv = nn.Conv2d(160, 160, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_13_branch7x7_2_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7_2_relu = nn.ReLU()\n        self.features_13_branch7x7_3_conv = nn.Conv2d(160, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_13_branch7x7_3_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7_3_relu = nn.ReLU()\n        self.features_13_branch7x7dbl_1_conv = nn.Conv2d(768, 160, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_13_branch7x7dbl_1_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7dbl_1_relu = nn.ReLU()\n        self.features_13_branch7x7dbl_2_conv = nn.Conv2d(160, 160, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_13_branch7x7dbl_2_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7dbl_2_relu = nn.ReLU()\n        self.features_13_branch7x7dbl_3_conv = nn.Conv2d(160, 160, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_13_branch7x7dbl_3_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7dbl_3_relu = nn.ReLU()\n        self.features_13_branch7x7dbl_4_conv = nn.Conv2d(160, 160, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_13_branch7x7dbl_4_bn = nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7dbl_4_relu = nn.ReLU()\n        self.features_13_branch7x7dbl_5_conv = nn.Conv2d(160, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_13_branch7x7dbl_5_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch7x7dbl_5_relu = nn.ReLU()\n        self.features_13_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_13_branch_pool_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_13_branch_pool_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_13_branch_pool_relu = nn.ReLU()\n        self.features_14_branch1x1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_14_branch1x1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch1x1_relu = nn.ReLU()\n        self.features_14_branch7x7_1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_14_branch7x7_1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7_1_relu = nn.ReLU()\n        self.features_14_branch7x7_2_conv = nn.Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_14_branch7x7_2_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7_2_relu = nn.ReLU()\n        self.features_14_branch7x7_3_conv = nn.Conv2d(192, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_14_branch7x7_3_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7_3_relu = nn.ReLU()\n        self.features_14_branch7x7dbl_1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_14_branch7x7dbl_1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7dbl_1_relu = nn.ReLU()\n        self.features_14_branch7x7dbl_2_conv = nn.Conv2d(192, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_14_branch7x7dbl_2_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7dbl_2_relu = nn.ReLU()\n        self.features_14_branch7x7dbl_3_conv = nn.Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_14_branch7x7dbl_3_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7dbl_3_relu = nn.ReLU()\n        self.features_14_branch7x7dbl_4_conv = nn.Conv2d(192, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_14_branch7x7dbl_4_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7dbl_4_relu = nn.ReLU()\n        self.features_14_branch7x7dbl_5_conv = nn.Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_14_branch7x7dbl_5_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch7x7dbl_5_relu = nn.ReLU()\n        self.features_14_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_14_branch_pool_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_14_branch_pool_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_14_branch_pool_relu = nn.ReLU()\n        self.features_15_branch3x3_1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_15_branch3x3_1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_15_branch3x3_1_relu = nn.ReLU()\n        self.features_15_branch3x3_2_conv = nn.Conv2d(192, 320, kernel_size=[3, 3], stride=(2, 2), bias=False)\n        self.features_15_branch3x3_2_bn = nn.BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True)\n        self.features_15_branch3x3_2_relu = nn.ReLU()\n        self.features_15_branch7x7x3_1_conv = nn.Conv2d(768, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_15_branch7x7x3_1_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_15_branch7x7x3_1_relu = nn.ReLU()\n        self.features_15_branch7x7x3_2_conv = nn.Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=(0, 3), bias=False)\n        self.features_15_branch7x7x3_2_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_15_branch7x7x3_2_relu = nn.ReLU()\n        self.features_15_branch7x7x3_3_conv = nn.Conv2d(192, 192, kernel_size=[7, 1], stride=(1, 1), padding=(3, 0), bias=False)\n        self.features_15_branch7x7x3_3_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_15_branch7x7x3_3_relu = nn.ReLU()\n        self.features_15_branch7x7x3_4_conv = nn.Conv2d(192, 192, kernel_size=[3, 3], stride=(2, 2), bias=False)\n        self.features_15_branch7x7x3_4_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_15_branch7x7x3_4_relu = nn.ReLU()\n        self.features_15_branch_maxpool = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n        self.features_16_branch1x1_conv = nn.Conv2d(1280, 320, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_16_branch1x1_bn = nn.BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch1x1_relu = nn.ReLU()\n        self.features_16_branch3x3_1_conv = nn.Conv2d(1280, 384, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_16_branch3x3_1_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3_1_relu = nn.ReLU()\n        self.features_16_branch3x3_2a_conv = nn.Conv2d(384, 384, kernel_size=[1, 3], stride=(1, 1), padding=(0, 1), bias=False)\n        self.features_16_branch3x3_2a_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3_2a_relu = nn.ReLU()\n        self.features_16_branch3x3_2b_conv = nn.Conv2d(384, 384, kernel_size=[3, 1], stride=(1, 1), padding=(1, 0), bias=False)\n        self.features_16_branch3x3_2b_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3_2b_relu = nn.ReLU()\n        self.features_16_branch3x3dbl_1_conv = nn.Conv2d(1280, 448, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_16_branch3x3dbl_1_bn = nn.BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3dbl_1_relu = nn.ReLU()\n        self.features_16_branch3x3dbl_2_conv = nn.Conv2d(448, 384, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_16_branch3x3dbl_2_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3dbl_2_relu = nn.ReLU()\n        self.features_16_branch3x3dbl_3a_conv = nn.Conv2d(384, 384, kernel_size=[1, 3], stride=(1, 1), padding=(0, 1), bias=False)\n        self.features_16_branch3x3dbl_3a_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3dbl_3a_relu = nn.ReLU()\n        self.features_16_branch3x3dbl_3b_conv = nn.Conv2d(384, 384, kernel_size=[3, 1], stride=(1, 1), padding=(1, 0), bias=False)\n        self.features_16_branch3x3dbl_3b_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch3x3dbl_3b_relu = nn.ReLU()\n        self.features_16_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_16_branch_pool_conv = nn.Conv2d(1280, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_16_branch_pool_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_16_branch_pool_relu = nn.ReLU()\n        self.features_17_branch1x1_conv = nn.Conv2d(2048, 320, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_17_branch1x1_bn = nn.BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch1x1_relu = nn.ReLU()\n        self.features_17_branch3x3_1_conv = nn.Conv2d(2048, 384, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_17_branch3x3_1_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3_1_relu = nn.ReLU()\n        self.features_17_branch3x3_2a_conv = nn.Conv2d(384, 384, kernel_size=[1, 3], stride=(1, 1), padding=(0, 1), bias=False)\n        self.features_17_branch3x3_2a_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3_2a_relu = nn.ReLU()\n        self.features_17_branch3x3_2b_conv = nn.Conv2d(384, 384, kernel_size=[3, 1], stride=(1, 1), padding=(1, 0), bias=False)\n        self.features_17_branch3x3_2b_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3_2b_relu = nn.ReLU()\n        self.features_17_branch3x3dbl_1_conv = nn.Conv2d(2048, 448, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_17_branch3x3dbl_1_bn = nn.BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3dbl_1_relu = nn.ReLU()\n        self.features_17_branch3x3dbl_2_conv = nn.Conv2d(448, 384, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n        self.features_17_branch3x3dbl_2_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3dbl_2_relu = nn.ReLU()\n        self.features_17_branch3x3dbl_3a_conv = nn.Conv2d(384, 384, kernel_size=[1, 3], stride=(1, 1), padding=(0, 1), bias=False)\n        self.features_17_branch3x3dbl_3a_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3dbl_3a_relu = nn.ReLU()\n        self.features_17_branch3x3dbl_3b_conv = nn.Conv2d(384, 384, kernel_size=[3, 1], stride=(1, 1), padding=(1, 0), bias=False)\n        self.features_17_branch3x3dbl_3b_bn = nn.BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch3x3dbl_3b_relu = nn.ReLU()\n        self.features_17_branch_avgpool = nn.AvgPool2d(kernel_size=[3, 3], stride=[1, 1], padding=1, ceil_mode=False, count_include_pad=False)\n        self.features_17_branch_pool_conv = nn.Conv2d(2048, 192, kernel_size=[1, 1], stride=(1, 1), bias=False)\n        self.features_17_branch_pool_bn = nn.BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n        self.features_17_branch_pool_relu = nn.ReLU()\n        self.features_18 = nn.AvgPool2d(kernel_size=[8, 8], stride=[8, 8], padding=0, ceil_mode=False, count_include_pad=False)\n        self.features_19 = nn.Dropout(p=0.5)\n        self.classifier_0 = nn.Linear(in_features=2048, out_features=1000, bias=True)\n\n    def forward(self, data):\n        features_0_conv = self.features_0_conv(data)\n        features_0_bn = self.features_0_bn(features_0_conv)\n        features_0_relu = self.features_0_relu(features_0_bn)\n        features_1_conv = self.features_1_conv(features_0_relu)\n        features_1_bn = self.features_1_bn(features_1_conv)\n        features_1_relu = self.features_1_relu(features_1_bn)\n        features_2_conv = self.features_2_conv(features_1_relu)\n        features_2_bn = self.features_2_bn(features_2_conv)\n        features_2_relu = self.features_2_relu(features_2_bn)\n        features_3 = self.features_3(features_2_relu)\n        features_4_conv = self.features_4_conv(features_3)\n        features_4_bn = self.features_4_bn(features_4_conv)\n        features_4_relu = self.features_4_relu(features_4_bn)\n        features_5_conv = self.features_5_conv(features_4_relu)\n        features_5_bn = self.features_5_bn(features_5_conv)\n        features_5_relu = self.features_5_relu(features_5_bn)\n        features_6 = self.features_6(features_5_relu)\n        features_7_branch1x1_conv = self.features_7_branch1x1_conv(features_6)\n        features_7_branch1x1_bn = self.features_7_branch1x1_bn(features_7_branch1x1_conv)\n        features_7_branch1x1_relu = self.features_7_branch1x1_relu(features_7_branch1x1_bn)\n        features_7_branch5x5_1_conv = self.features_7_branch5x5_1_conv(features_6)\n        features_7_branch5x5_1_bn = self.features_7_branch5x5_1_bn(features_7_branch5x5_1_conv)\n        features_7_branch5x5_1_relu = self.features_7_branch5x5_1_relu(features_7_branch5x5_1_bn)\n        features_7_branch5x5_2_conv = self.features_7_branch5x5_2_conv(features_7_branch5x5_1_relu)\n        features_7_branch5x5_2_bn = self.features_7_branch5x5_2_bn(features_7_branch5x5_2_conv)\n        features_7_branch5x5_2_relu = self.features_7_branch5x5_2_relu(features_7_branch5x5_2_bn)\n        features_7_branch3x3dbl_1_conv = self.features_7_branch3x3dbl_1_conv(features_6)\n        features_7_branch3x3dbl_1_bn = self.features_7_branch3x3dbl_1_bn(features_7_branch3x3dbl_1_conv)\n        features_7_branch3x3dbl_1_relu = self.features_7_branch3x3dbl_1_relu(features_7_branch3x3dbl_1_bn)\n        features_7_branch3x3dbl_2_conv = self.features_7_branch3x3dbl_2_conv(features_7_branch3x3dbl_1_relu)\n        features_7_branch3x3dbl_2_bn = self.features_7_branch3x3dbl_2_bn(features_7_branch3x3dbl_2_conv)\n        features_7_branch3x3dbl_2_relu = self.features_7_branch3x3dbl_2_relu(features_7_branch3x3dbl_2_bn)\n        features_7_branch3x3dbl_3_conv = self.features_7_branch3x3dbl_3_conv(features_7_branch3x3dbl_2_relu)\n        features_7_branch3x3dbl_3_bn = self.features_7_branch3x3dbl_3_bn(features_7_branch3x3dbl_3_conv)\n        features_7_branch3x3dbl_3_relu = self.features_7_branch3x3dbl_3_relu(features_7_branch3x3dbl_3_bn)\n        features_7_branch_avgpool = self.features_7_branch_avgpool(features_6)\n        features_7_branch_pool_conv = self.features_7_branch_pool_conv(features_7_branch_avgpool)\n        features_7_branch_pool_bn = self.features_7_branch_pool_bn(features_7_branch_pool_conv)\n        features_7_branch_pool_relu = self.features_7_branch_pool_relu(features_7_branch_pool_bn)\n        features_7_cat = torch.cat((features_7_branch1x1_relu,features_7_branch5x5_2_relu,features_7_branch3x3dbl_3_relu,features_7_branch_pool_relu), dim=1)\n        features_8_branch1x1_conv = self.features_8_branch1x1_conv(features_7_cat)\n        features_8_branch1x1_bn = self.features_8_branch1x1_bn(features_8_branch1x1_conv)\n        features_8_branch1x1_relu = self.features_8_branch1x1_relu(features_8_branch1x1_bn)\n        features_8_branch5x5_1_conv = self.features_8_branch5x5_1_conv(features_7_cat)\n        features_8_branch5x5_1_bn = self.features_8_branch5x5_1_bn(features_8_branch5x5_1_conv)\n        features_8_branch5x5_1_relu = self.features_8_branch5x5_1_relu(features_8_branch5x5_1_bn)\n        features_8_branch5x5_2_conv = self.features_8_branch5x5_2_conv(features_8_branch5x5_1_relu)\n        features_8_branch5x5_2_bn = self.features_8_branch5x5_2_bn(features_8_branch5x5_2_conv)\n        features_8_branch5x5_2_relu = self.features_8_branch5x5_2_relu(features_8_branch5x5_2_bn)\n        features_8_branch3x3dbl_1_conv = self.features_8_branch3x3dbl_1_conv(features_7_cat)\n        features_8_branch3x3dbl_1_bn = self.features_8_branch3x3dbl_1_bn(features_8_branch3x3dbl_1_conv)\n        features_8_branch3x3dbl_1_relu = self.features_8_branch3x3dbl_1_relu(features_8_branch3x3dbl_1_bn)\n        features_8_branch3x3dbl_2_conv = self.features_8_branch3x3dbl_2_conv(features_8_branch3x3dbl_1_relu)\n        features_8_branch3x3dbl_2_bn = self.features_8_branch3x3dbl_2_bn(features_8_branch3x3dbl_2_conv)\n        features_8_branch3x3dbl_2_relu = self.features_8_branch3x3dbl_2_relu(features_8_branch3x3dbl_2_bn)\n        features_8_branch3x3dbl_3_conv = self.features_8_branch3x3dbl_3_conv(features_8_branch3x3dbl_2_relu)\n        features_8_branch3x3dbl_3_bn = self.features_8_branch3x3dbl_3_bn(features_8_branch3x3dbl_3_conv)\n        features_8_branch3x3dbl_3_relu = self.features_8_branch3x3dbl_3_relu(features_8_branch3x3dbl_3_bn)\n        features_8_branch_avgpool = self.features_8_branch_avgpool(features_7_cat)\n        features_8_branch_pool_conv = self.features_8_branch_pool_conv(features_8_branch_avgpool)\n        features_8_branch_pool_bn = self.features_8_branch_pool_bn(features_8_branch_pool_conv)\n        features_8_branch_pool_relu = self.features_8_branch_pool_relu(features_8_branch_pool_bn)\n        features_8_cat = torch.cat((features_8_branch1x1_relu,features_8_branch5x5_2_relu,features_8_branch3x3dbl_3_relu,features_8_branch_pool_relu), dim=1)\n        features_9_branch1x1_conv = self.features_9_branch1x1_conv(features_8_cat)\n        features_9_branch1x1_bn = self.features_9_branch1x1_bn(features_9_branch1x1_conv)\n        features_9_branch1x1_relu = self.features_9_branch1x1_relu(features_9_branch1x1_bn)\n        features_9_branch5x5_1_conv = self.features_9_branch5x5_1_conv(features_8_cat)\n        features_9_branch5x5_1_bn = self.features_9_branch5x5_1_bn(features_9_branch5x5_1_conv)\n        features_9_branch5x5_1_relu = self.features_9_branch5x5_1_relu(features_9_branch5x5_1_bn)\n        features_9_branch5x5_2_conv = self.features_9_branch5x5_2_conv(features_9_branch5x5_1_relu)\n        features_9_branch5x5_2_bn = self.features_9_branch5x5_2_bn(features_9_branch5x5_2_conv)\n        features_9_branch5x5_2_relu = self.features_9_branch5x5_2_relu(features_9_branch5x5_2_bn)\n        features_9_branch3x3dbl_1_conv = self.features_9_branch3x3dbl_1_conv(features_8_cat)\n        features_9_branch3x3dbl_1_bn = self.features_9_branch3x3dbl_1_bn(features_9_branch3x3dbl_1_conv)\n        features_9_branch3x3dbl_1_relu = self.features_9_branch3x3dbl_1_relu(features_9_branch3x3dbl_1_bn)\n        features_9_branch3x3dbl_2_conv = self.features_9_branch3x3dbl_2_conv(features_9_branch3x3dbl_1_relu)\n        features_9_branch3x3dbl_2_bn = self.features_9_branch3x3dbl_2_bn(features_9_branch3x3dbl_2_conv)\n        features_9_branch3x3dbl_2_relu = self.features_9_branch3x3dbl_2_relu(features_9_branch3x3dbl_2_bn)\n        features_9_branch3x3dbl_3_conv = self.features_9_branch3x3dbl_3_conv(features_9_branch3x3dbl_2_relu)\n        features_9_branch3x3dbl_3_bn = self.features_9_branch3x3dbl_3_bn(features_9_branch3x3dbl_3_conv)\n        features_9_branch3x3dbl_3_relu = self.features_9_branch3x3dbl_3_relu(features_9_branch3x3dbl_3_bn)\n        features_9_branch_avgpool = self.features_9_branch_avgpool(features_8_cat)\n        features_9_branch_pool_conv = self.features_9_branch_pool_conv(features_9_branch_avgpool)\n        features_9_branch_pool_bn = self.features_9_branch_pool_bn(features_9_branch_pool_conv)\n        features_9_branch_pool_relu = self.features_9_branch_pool_relu(features_9_branch_pool_bn)\n        features_9_cat = torch.cat((features_9_branch1x1_relu,features_9_branch5x5_2_relu,features_9_branch3x3dbl_3_relu,features_9_branch_pool_relu), dim=1)\n        features_10_branch3x3_conv = self.features_10_branch3x3_conv(features_9_cat)\n        features_10_branch3x3_bn = self.features_10_branch3x3_bn(features_10_branch3x3_conv)\n        features_10_branch3x3_relu = self.features_10_branch3x3_relu(features_10_branch3x3_bn)\n        features_10_branch3x3dbl_1_conv = self.features_10_branch3x3dbl_1_conv(features_9_cat)\n        features_10_branch3x3dbl_1_bn = self.features_10_branch3x3dbl_1_bn(features_10_branch3x3dbl_1_conv)\n        features_10_branch3x3dbl_1_relu = self.features_10_branch3x3dbl_1_relu(features_10_branch3x3dbl_1_bn)\n        features_10_branch3x3dbl_2_conv = self.features_10_branch3x3dbl_2_conv(features_10_branch3x3dbl_1_relu)\n        features_10_branch3x3dbl_2_bn = self.features_10_branch3x3dbl_2_bn(features_10_branch3x3dbl_2_conv)\n        features_10_branch3x3dbl_2_relu = self.features_10_branch3x3dbl_2_relu(features_10_branch3x3dbl_2_bn)\n        features_10_branch3x3dbl_3_conv = self.features_10_branch3x3dbl_3_conv(features_10_branch3x3dbl_2_relu)\n        features_10_branch3x3dbl_3_bn = self.features_10_branch3x3dbl_3_bn(features_10_branch3x3dbl_3_conv)\n        features_10_branch3x3dbl_3_relu = self.features_10_branch3x3dbl_3_relu(features_10_branch3x3dbl_3_bn)\n        features_10_branch_pool = self.features_10_branch_pool(features_9_cat)\n        features_10_cat = torch.cat((features_10_branch3x3_relu,features_10_branch3x3dbl_3_relu,features_10_branch_pool), dim=1)\n        features_11_branch1x1_conv = self.features_11_branch1x1_conv(features_10_cat)\n        features_11_branch1x1_bn = self.features_11_branch1x1_bn(features_11_branch1x1_conv)\n        features_11_branch1x1_relu = self.features_11_branch1x1_relu(features_11_branch1x1_bn)\n        features_11_branch7x7_1_conv = self.features_11_branch7x7_1_conv(features_10_cat)\n        features_11_branch7x7_1_bn = self.features_11_branch7x7_1_bn(features_11_branch7x7_1_conv)\n        features_11_branch7x7_1_relu = self.features_11_branch7x7_1_relu(features_11_branch7x7_1_bn)\n        features_11_branch7x7_2_conv = self.features_11_branch7x7_2_conv(features_11_branch7x7_1_relu)\n        features_11_branch7x7_2_bn = self.features_11_branch7x7_2_bn(features_11_branch7x7_2_conv)\n        features_11_branch7x7_2_relu = self.features_11_branch7x7_2_relu(features_11_branch7x7_2_bn)\n        features_11_branch7x7_3_conv = self.features_11_branch7x7_3_conv(features_11_branch7x7_2_relu)\n        features_11_branch7x7_3_bn = self.features_11_branch7x7_3_bn(features_11_branch7x7_3_conv)\n        features_11_branch7x7_3_relu = self.features_11_branch7x7_3_relu(features_11_branch7x7_3_bn)\n        features_11_branch7x7dbl_1_conv = self.features_11_branch7x7dbl_1_conv(features_10_cat)\n        features_11_branch7x7dbl_1_bn = self.features_11_branch7x7dbl_1_bn(features_11_branch7x7dbl_1_conv)\n        features_11_branch7x7dbl_1_relu = self.features_11_branch7x7dbl_1_relu(features_11_branch7x7dbl_1_bn)\n        features_11_branch7x7dbl_2_conv = self.features_11_branch7x7dbl_2_conv(features_11_branch7x7dbl_1_relu)\n        features_11_branch7x7dbl_2_bn = self.features_11_branch7x7dbl_2_bn(features_11_branch7x7dbl_2_conv)\n        features_11_branch7x7dbl_2_relu = self.features_11_branch7x7dbl_2_relu(features_11_branch7x7dbl_2_bn)\n        features_11_branch7x7dbl_3_conv = self.features_11_branch7x7dbl_3_conv(features_11_branch7x7dbl_2_relu)\n        features_11_branch7x7dbl_3_bn = self.features_11_branch7x7dbl_3_bn(features_11_branch7x7dbl_3_conv)\n        features_11_branch7x7dbl_3_relu = self.features_11_branch7x7dbl_3_relu(features_11_branch7x7dbl_3_bn)\n        features_11_branch7x7dbl_4_conv = self.features_11_branch7x7dbl_4_conv(features_11_branch7x7dbl_3_relu)\n        features_11_branch7x7dbl_4_bn = self.features_11_branch7x7dbl_4_bn(features_11_branch7x7dbl_4_conv)\n        features_11_branch7x7dbl_4_relu = self.features_11_branch7x7dbl_4_relu(features_11_branch7x7dbl_4_bn)\n        features_11_branch7x7dbl_5_conv = self.features_11_branch7x7dbl_5_conv(features_11_branch7x7dbl_4_relu)\n        features_11_branch7x7dbl_5_bn = self.features_11_branch7x7dbl_5_bn(features_11_branch7x7dbl_5_conv)\n        features_11_branch7x7dbl_5_relu = self.features_11_branch7x7dbl_5_relu(features_11_branch7x7dbl_5_bn)\n        features_11_branch_avgpool = self.features_11_branch_avgpool(features_10_cat)\n        features_11_branch_pool_conv = self.features_11_branch_pool_conv(features_11_branch_avgpool)\n        features_11_branch_pool_bn = self.features_11_branch_pool_bn(features_11_branch_pool_conv)\n        features_11_branch_pool_relu = self.features_11_branch_pool_relu(features_11_branch_pool_bn)\n        features_11_cat = torch.cat((features_11_branch1x1_relu,features_11_branch7x7_3_relu,features_11_branch7x7dbl_5_relu,features_11_branch_pool_relu), dim=1)\n        features_12_branch1x1_conv = self.features_12_branch1x1_conv(features_11_cat)\n        features_12_branch1x1_bn = self.features_12_branch1x1_bn(features_12_branch1x1_conv)\n        features_12_branch1x1_relu = self.features_12_branch1x1_relu(features_12_branch1x1_bn)\n        features_12_branch7x7_1_conv = self.features_12_branch7x7_1_conv(features_11_cat)\n        features_12_branch7x7_1_bn = self.features_12_branch7x7_1_bn(features_12_branch7x7_1_conv)\n        features_12_branch7x7_1_relu = self.features_12_branch7x7_1_relu(features_12_branch7x7_1_bn)\n        features_12_branch7x7_2_conv = self.features_12_branch7x7_2_conv(features_12_branch7x7_1_relu)\n        features_12_branch7x7_2_bn = self.features_12_branch7x7_2_bn(features_12_branch7x7_2_conv)\n        features_12_branch7x7_2_relu = self.features_12_branch7x7_2_relu(features_12_branch7x7_2_bn)\n        features_12_branch7x7_3_conv = self.features_12_branch7x7_3_conv(features_12_branch7x7_2_relu)\n        features_12_branch7x7_3_bn = self.features_12_branch7x7_3_bn(features_12_branch7x7_3_conv)\n        features_12_branch7x7_3_relu = self.features_12_branch7x7_3_relu(features_12_branch7x7_3_bn)\n        features_12_branch7x7dbl_1_conv = self.features_12_branch7x7dbl_1_conv(features_11_cat)\n        features_12_branch7x7dbl_1_bn = self.features_12_branch7x7dbl_1_bn(features_12_branch7x7dbl_1_conv)\n        features_12_branch7x7dbl_1_relu = self.features_12_branch7x7dbl_1_relu(features_12_branch7x7dbl_1_bn)\n        features_12_branch7x7dbl_2_conv = self.features_12_branch7x7dbl_2_conv(features_12_branch7x7dbl_1_relu)\n        features_12_branch7x7dbl_2_bn = self.features_12_branch7x7dbl_2_bn(features_12_branch7x7dbl_2_conv)\n        features_12_branch7x7dbl_2_relu = self.features_12_branch7x7dbl_2_relu(features_12_branch7x7dbl_2_bn)\n        features_12_branch7x7dbl_3_conv = self.features_12_branch7x7dbl_3_conv(features_12_branch7x7dbl_2_relu)\n        features_12_branch7x7dbl_3_bn = self.features_12_branch7x7dbl_3_bn(features_12_branch7x7dbl_3_conv)\n        features_12_branch7x7dbl_3_relu = self.features_12_branch7x7dbl_3_relu(features_12_branch7x7dbl_3_bn)\n        features_12_branch7x7dbl_4_conv = self.features_12_branch7x7dbl_4_conv(features_12_branch7x7dbl_3_relu)\n        features_12_branch7x7dbl_4_bn = self.features_12_branch7x7dbl_4_bn(features_12_branch7x7dbl_4_conv)\n        features_12_branch7x7dbl_4_relu = self.features_12_branch7x7dbl_4_relu(features_12_branch7x7dbl_4_bn)\n        features_12_branch7x7dbl_5_conv = self.features_12_branch7x7dbl_5_conv(features_12_branch7x7dbl_4_relu)\n        features_12_branch7x7dbl_5_bn = self.features_12_branch7x7dbl_5_bn(features_12_branch7x7dbl_5_conv)\n        features_12_branch7x7dbl_5_relu = self.features_12_branch7x7dbl_5_relu(features_12_branch7x7dbl_5_bn)\n        features_12_branch_avgpool = self.features_12_branch_avgpool(features_11_cat)\n        features_12_branch_pool_conv = self.features_12_branch_pool_conv(features_12_branch_avgpool)\n        features_12_branch_pool_bn = self.features_12_branch_pool_bn(features_12_branch_pool_conv)\n        features_12_branch_pool_relu = self.features_12_branch_pool_relu(features_12_branch_pool_bn)\n        features_12_cat = torch.cat((features_12_branch1x1_relu,features_12_branch7x7_3_relu,features_12_branch7x7dbl_5_relu,features_12_branch_pool_relu), dim=1)\n        features_13_branch1x1_conv = self.features_13_branch1x1_conv(features_12_cat)\n        features_13_branch1x1_bn = self.features_13_branch1x1_bn(features_13_branch1x1_conv)\n        features_13_branch1x1_relu = self.features_13_branch1x1_relu(features_13_branch1x1_bn)\n        features_13_branch7x7_1_conv = self.features_13_branch7x7_1_conv(features_12_cat)\n        features_13_branch7x7_1_bn = self.features_13_branch7x7_1_bn(features_13_branch7x7_1_conv)\n        features_13_branch7x7_1_relu = self.features_13_branch7x7_1_relu(features_13_branch7x7_1_bn)\n        features_13_branch7x7_2_conv = self.features_13_branch7x7_2_conv(features_13_branch7x7_1_relu)\n        features_13_branch7x7_2_bn = self.features_13_branch7x7_2_bn(features_13_branch7x7_2_conv)\n        features_13_branch7x7_2_relu = self.features_13_branch7x7_2_relu(features_13_branch7x7_2_bn)\n        features_13_branch7x7_3_conv = self.features_13_branch7x7_3_conv(features_13_branch7x7_2_relu)\n        features_13_branch7x7_3_bn = self.features_13_branch7x7_3_bn(features_13_branch7x7_3_conv)\n        features_13_branch7x7_3_relu = self.features_13_branch7x7_3_relu(features_13_branch7x7_3_bn)\n        features_13_branch7x7dbl_1_conv = self.features_13_branch7x7dbl_1_conv(features_12_cat)\n        features_13_branch7x7dbl_1_bn = self.features_13_branch7x7dbl_1_bn(features_13_branch7x7dbl_1_conv)\n        features_13_branch7x7dbl_1_relu = self.features_13_branch7x7dbl_1_relu(features_13_branch7x7dbl_1_bn)\n        features_13_branch7x7dbl_2_conv = self.features_13_branch7x7dbl_2_conv(features_13_branch7x7dbl_1_relu)\n        features_13_branch7x7dbl_2_bn = self.features_13_branch7x7dbl_2_bn(features_13_branch7x7dbl_2_conv)\n        features_13_branch7x7dbl_2_relu = self.features_13_branch7x7dbl_2_relu(features_13_branch7x7dbl_2_bn)\n        features_13_branch7x7dbl_3_conv = self.features_13_branch7x7dbl_3_conv(features_13_branch7x7dbl_2_relu)\n        features_13_branch7x7dbl_3_bn = self.features_13_branch7x7dbl_3_bn(features_13_branch7x7dbl_3_conv)\n        features_13_branch7x7dbl_3_relu = self.features_13_branch7x7dbl_3_relu(features_13_branch7x7dbl_3_bn)\n        features_13_branch7x7dbl_4_conv = self.features_13_branch7x7dbl_4_conv(features_13_branch7x7dbl_3_relu)\n        features_13_branch7x7dbl_4_bn = self.features_13_branch7x7dbl_4_bn(features_13_branch7x7dbl_4_conv)\n        features_13_branch7x7dbl_4_relu = self.features_13_branch7x7dbl_4_relu(features_13_branch7x7dbl_4_bn)\n        features_13_branch7x7dbl_5_conv = self.features_13_branch7x7dbl_5_conv(features_13_branch7x7dbl_4_relu)\n        features_13_branch7x7dbl_5_bn = self.features_13_branch7x7dbl_5_bn(features_13_branch7x7dbl_5_conv)\n        features_13_branch7x7dbl_5_relu = self.features_13_branch7x7dbl_5_relu(features_13_branch7x7dbl_5_bn)\n        features_13_branch_avgpool = self.features_13_branch_avgpool(features_12_cat)\n        features_13_branch_pool_conv = self.features_13_branch_pool_conv(features_13_branch_avgpool)\n        features_13_branch_pool_bn = self.features_13_branch_pool_bn(features_13_branch_pool_conv)\n        features_13_branch_pool_relu = self.features_13_branch_pool_relu(features_13_branch_pool_bn)\n        features_13_cat = torch.cat((features_13_branch1x1_relu,features_13_branch7x7_3_relu,features_13_branch7x7dbl_5_relu,features_13_branch_pool_relu), dim=1)\n        features_14_branch1x1_conv = self.features_14_branch1x1_conv(features_13_cat)\n        features_14_branch1x1_bn = self.features_14_branch1x1_bn(features_14_branch1x1_conv)\n        features_14_branch1x1_relu = self.features_14_branch1x1_relu(features_14_branch1x1_bn)\n        features_14_branch7x7_1_conv = self.features_14_branch7x7_1_conv(features_13_cat)\n        features_14_branch7x7_1_bn = self.features_14_branch7x7_1_bn(features_14_branch7x7_1_conv)\n        features_14_branch7x7_1_relu = self.features_14_branch7x7_1_relu(features_14_branch7x7_1_bn)\n        features_14_branch7x7_2_conv = self.features_14_branch7x7_2_conv(features_14_branch7x7_1_relu)\n        features_14_branch7x7_2_bn = self.features_14_branch7x7_2_bn(features_14_branch7x7_2_conv)\n        features_14_branch7x7_2_relu = self.features_14_branch7x7_2_relu(features_14_branch7x7_2_bn)\n        features_14_branch7x7_3_conv = self.features_14_branch7x7_3_conv(features_14_branch7x7_2_relu)\n        features_14_branch7x7_3_bn = self.features_14_branch7x7_3_bn(features_14_branch7x7_3_conv)\n        features_14_branch7x7_3_relu = self.features_14_branch7x7_3_relu(features_14_branch7x7_3_bn)\n        features_14_branch7x7dbl_1_conv = self.features_14_branch7x7dbl_1_conv(features_13_cat)\n        features_14_branch7x7dbl_1_bn = self.features_14_branch7x7dbl_1_bn(features_14_branch7x7dbl_1_conv)\n        features_14_branch7x7dbl_1_relu = self.features_14_branch7x7dbl_1_relu(features_14_branch7x7dbl_1_bn)\n        features_14_branch7x7dbl_2_conv = self.features_14_branch7x7dbl_2_conv(features_14_branch7x7dbl_1_relu)\n        features_14_branch7x7dbl_2_bn = self.features_14_branch7x7dbl_2_bn(features_14_branch7x7dbl_2_conv)\n        features_14_branch7x7dbl_2_relu = self.features_14_branch7x7dbl_2_relu(features_14_branch7x7dbl_2_bn)\n        features_14_branch7x7dbl_3_conv = self.features_14_branch7x7dbl_3_conv(features_14_branch7x7dbl_2_relu)\n        features_14_branch7x7dbl_3_bn = self.features_14_branch7x7dbl_3_bn(features_14_branch7x7dbl_3_conv)\n        features_14_branch7x7dbl_3_relu = self.features_14_branch7x7dbl_3_relu(features_14_branch7x7dbl_3_bn)\n        features_14_branch7x7dbl_4_conv = self.features_14_branch7x7dbl_4_conv(features_14_branch7x7dbl_3_relu)\n        features_14_branch7x7dbl_4_bn = self.features_14_branch7x7dbl_4_bn(features_14_branch7x7dbl_4_conv)\n        features_14_branch7x7dbl_4_relu = self.features_14_branch7x7dbl_4_relu(features_14_branch7x7dbl_4_bn)\n        features_14_branch7x7dbl_5_conv = self.features_14_branch7x7dbl_5_conv(features_14_branch7x7dbl_4_relu)\n        features_14_branch7x7dbl_5_bn = self.features_14_branch7x7dbl_5_bn(features_14_branch7x7dbl_5_conv)\n        features_14_branch7x7dbl_5_relu = self.features_14_branch7x7dbl_5_relu(features_14_branch7x7dbl_5_bn)\n        features_14_branch_avgpool = self.features_14_branch_avgpool(features_13_cat)\n        features_14_branch_pool_conv = self.features_14_branch_pool_conv(features_14_branch_avgpool)\n        features_14_branch_pool_bn = self.features_14_branch_pool_bn(features_14_branch_pool_conv)\n        features_14_branch_pool_relu = self.features_14_branch_pool_relu(features_14_branch_pool_bn)\n        features_14_cat = torch.cat((features_14_branch1x1_relu,features_14_branch7x7_3_relu,features_14_branch7x7dbl_5_relu,features_14_branch_pool_relu), dim=1)\n        features_15_branch3x3_1_conv = self.features_15_branch3x3_1_conv(features_14_cat)\n        features_15_branch3x3_1_bn = self.features_15_branch3x3_1_bn(features_15_branch3x3_1_conv)\n        features_15_branch3x3_1_relu = self.features_15_branch3x3_1_relu(features_15_branch3x3_1_bn)\n        features_15_branch3x3_2_conv = self.features_15_branch3x3_2_conv(features_15_branch3x3_1_relu)\n        features_15_branch3x3_2_bn = self.features_15_branch3x3_2_bn(features_15_branch3x3_2_conv)\n        features_15_branch3x3_2_relu = self.features_15_branch3x3_2_relu(features_15_branch3x3_2_bn)\n        features_15_branch7x7x3_1_conv = self.features_15_branch7x7x3_1_conv(features_14_cat)\n        features_15_branch7x7x3_1_bn = self.features_15_branch7x7x3_1_bn(features_15_branch7x7x3_1_conv)\n        features_15_branch7x7x3_1_relu = self.features_15_branch7x7x3_1_relu(features_15_branch7x7x3_1_bn)\n        features_15_branch7x7x3_2_conv = self.features_15_branch7x7x3_2_conv(features_15_branch7x7x3_1_relu)\n        features_15_branch7x7x3_2_bn = self.features_15_branch7x7x3_2_bn(features_15_branch7x7x3_2_conv)\n        features_15_branch7x7x3_2_relu = self.features_15_branch7x7x3_2_relu(features_15_branch7x7x3_2_bn)\n        features_15_branch7x7x3_3_conv = self.features_15_branch7x7x3_3_conv(features_15_branch7x7x3_2_relu)\n        features_15_branch7x7x3_3_bn = self.features_15_branch7x7x3_3_bn(features_15_branch7x7x3_3_conv)\n        features_15_branch7x7x3_3_relu = self.features_15_branch7x7x3_3_relu(features_15_branch7x7x3_3_bn)\n        features_15_branch7x7x3_4_conv = self.features_15_branch7x7x3_4_conv(features_15_branch7x7x3_3_relu)\n        features_15_branch7x7x3_4_bn = self.features_15_branch7x7x3_4_bn(features_15_branch7x7x3_4_conv)\n        features_15_branch7x7x3_4_relu = self.features_15_branch7x7x3_4_relu(features_15_branch7x7x3_4_bn)\n        features_15_branch_maxpool = self.features_15_branch_maxpool(features_14_cat)\n        features_15_cat = torch.cat((features_15_branch3x3_2_relu,features_15_branch7x7x3_4_relu,features_15_branch_maxpool), dim=1)\n        features_16_branch1x1_conv = self.features_16_branch1x1_conv(features_15_cat)\n        features_16_branch1x1_bn = self.features_16_branch1x1_bn(features_16_branch1x1_conv)\n        features_16_branch1x1_relu = self.features_16_branch1x1_relu(features_16_branch1x1_bn)\n        features_16_branch3x3_1_conv = self.features_16_branch3x3_1_conv(features_15_cat)\n        features_16_branch3x3_1_bn = self.features_16_branch3x3_1_bn(features_16_branch3x3_1_conv)\n        features_16_branch3x3_1_relu = self.features_16_branch3x3_1_relu(features_16_branch3x3_1_bn)\n        features_16_branch3x3_2a_conv = self.features_16_branch3x3_2a_conv(features_16_branch3x3_1_relu)\n        features_16_branch3x3_2a_bn = self.features_16_branch3x3_2a_bn(features_16_branch3x3_2a_conv)\n        features_16_branch3x3_2a_relu = self.features_16_branch3x3_2a_relu(features_16_branch3x3_2a_bn)\n        features_16_branch3x3_2b_conv = self.features_16_branch3x3_2b_conv(features_16_branch3x3_1_relu)\n        features_16_branch3x3_2b_bn = self.features_16_branch3x3_2b_bn(features_16_branch3x3_2b_conv)\n        features_16_branch3x3_2b_relu = self.features_16_branch3x3_2b_relu(features_16_branch3x3_2b_bn)\n        features_16_branch2_cat = torch.cat((features_16_branch3x3_2a_relu,features_16_branch3x3_2b_relu), dim=1)\n        features_16_branch3x3dbl_1_conv = self.features_16_branch3x3dbl_1_conv(features_15_cat)\n        features_16_branch3x3dbl_1_bn = self.features_16_branch3x3dbl_1_bn(features_16_branch3x3dbl_1_conv)\n        features_16_branch3x3dbl_1_relu = self.features_16_branch3x3dbl_1_relu(features_16_branch3x3dbl_1_bn)\n        features_16_branch3x3dbl_2_conv = self.features_16_branch3x3dbl_2_conv(features_16_branch3x3dbl_1_relu)\n        features_16_branch3x3dbl_2_bn = self.features_16_branch3x3dbl_2_bn(features_16_branch3x3dbl_2_conv)\n        features_16_branch3x3dbl_2_relu = self.features_16_branch3x3dbl_2_relu(features_16_branch3x3dbl_2_bn)\n        features_16_branch3x3dbl_3a_conv = self.features_16_branch3x3dbl_3a_conv(features_16_branch3x3dbl_2_relu)\n        features_16_branch3x3dbl_3a_bn = self.features_16_branch3x3dbl_3a_bn(features_16_branch3x3dbl_3a_conv)\n        features_16_branch3x3dbl_3a_relu = self.features_16_branch3x3dbl_3a_relu(features_16_branch3x3dbl_3a_bn)\n        features_16_branch3x3dbl_3b_conv = self.features_16_branch3x3dbl_3b_conv(features_16_branch3x3dbl_2_relu)\n        features_16_branch3x3dbl_3b_bn = self.features_16_branch3x3dbl_3b_bn(features_16_branch3x3dbl_3b_conv)\n        features_16_branch3x3dbl_3b_relu = self.features_16_branch3x3dbl_3b_relu(features_16_branch3x3dbl_3b_bn)\n        features_16_branch3_cat = torch.cat((features_16_branch3x3dbl_3a_relu,features_16_branch3x3dbl_3b_relu), dim=1)\n        features_16_branch_avgpool = self.features_16_branch_avgpool(features_15_cat)\n        features_16_branch_pool_conv = self.features_16_branch_pool_conv(features_16_branch_avgpool)\n        features_16_branch_pool_bn = self.features_16_branch_pool_bn(features_16_branch_pool_conv)\n        features_16_branch_pool_relu = self.features_16_branch_pool_relu(features_16_branch_pool_bn)\n        features_16_cat = torch.cat((features_16_branch1x1_relu,features_16_branch2_cat,features_16_branch3_cat,features_16_branch_pool_relu), dim=1)\n        features_17_branch1x1_conv = self.features_17_branch1x1_conv(features_16_cat)\n        features_17_branch1x1_bn = self.features_17_branch1x1_bn(features_17_branch1x1_conv)\n        features_17_branch1x1_relu = self.features_17_branch1x1_relu(features_17_branch1x1_bn)\n        features_17_branch3x3_1_conv = self.features_17_branch3x3_1_conv(features_16_cat)\n        features_17_branch3x3_1_bn = self.features_17_branch3x3_1_bn(features_17_branch3x3_1_conv)\n        features_17_branch3x3_1_relu = self.features_17_branch3x3_1_relu(features_17_branch3x3_1_bn)\n        features_17_branch3x3_2a_conv = self.features_17_branch3x3_2a_conv(features_17_branch3x3_1_relu)\n        features_17_branch3x3_2a_bn = self.features_17_branch3x3_2a_bn(features_17_branch3x3_2a_conv)\n        features_17_branch3x3_2a_relu = self.features_17_branch3x3_2a_relu(features_17_branch3x3_2a_bn)\n        features_17_branch3x3_2b_conv = self.features_17_branch3x3_2b_conv(features_17_branch3x3_1_relu)\n        features_17_branch3x3_2b_bn = self.features_17_branch3x3_2b_bn(features_17_branch3x3_2b_conv)\n        features_17_branch3x3_2b_relu = self.features_17_branch3x3_2b_relu(features_17_branch3x3_2b_bn)\n        features_17_branch2_cat = torch.cat((features_17_branch3x3_2a_relu,features_17_branch3x3_2b_relu), dim=1)\n        features_17_branch3x3dbl_1_conv = self.features_17_branch3x3dbl_1_conv(features_16_cat)\n        features_17_branch3x3dbl_1_bn = self.features_17_branch3x3dbl_1_bn(features_17_branch3x3dbl_1_conv)\n        features_17_branch3x3dbl_1_relu = self.features_17_branch3x3dbl_1_relu(features_17_branch3x3dbl_1_bn)\n        features_17_branch3x3dbl_2_conv = self.features_17_branch3x3dbl_2_conv(features_17_branch3x3dbl_1_relu)\n        features_17_branch3x3dbl_2_bn = self.features_17_branch3x3dbl_2_bn(features_17_branch3x3dbl_2_conv)\n        features_17_branch3x3dbl_2_relu = self.features_17_branch3x3dbl_2_relu(features_17_branch3x3dbl_2_bn)\n        features_17_branch3x3dbl_3a_conv = self.features_17_branch3x3dbl_3a_conv(features_17_branch3x3dbl_2_relu)\n        features_17_branch3x3dbl_3a_bn = self.features_17_branch3x3dbl_3a_bn(features_17_branch3x3dbl_3a_conv)\n        features_17_branch3x3dbl_3a_relu = self.features_17_branch3x3dbl_3a_relu(features_17_branch3x3dbl_3a_bn)\n        features_17_branch3x3dbl_3b_conv = self.features_17_branch3x3dbl_3b_conv(features_17_branch3x3dbl_2_relu)\n        features_17_branch3x3dbl_3b_bn = self.features_17_branch3x3dbl_3b_bn(features_17_branch3x3dbl_3b_conv)\n        features_17_branch3x3dbl_3b_relu = self.features_17_branch3x3dbl_3b_relu(features_17_branch3x3dbl_3b_bn)\n        features_17_branch3_cat = torch.cat((features_17_branch3x3dbl_3a_relu,features_17_branch3x3dbl_3b_relu), dim=1)\n        features_17_branch_avgpool = self.features_17_branch_avgpool(features_16_cat)\n        features_17_branch_pool_conv = self.features_17_branch_pool_conv(features_17_branch_avgpool)\n        features_17_branch_pool_bn = self.features_17_branch_pool_bn(features_17_branch_pool_conv)\n        features_17_branch_pool_relu = self.features_17_branch_pool_relu(features_17_branch_pool_bn)\n        features_17_cat = torch.cat((features_17_branch1x1_relu,features_17_branch2_cat,features_17_branch3_cat,features_17_branch_pool_relu), dim=1)\n        features_18 = self.features_18(features_17_cat)\n#         features_19 = self.features_19(features_18)\n        classifier_flatten = features_18.view(features_18.size(0), -1)\n#         classifier_0 = self.classifier_0(classifier_flatten)\n        return classifier_flatten\n\ndef inception_v3_pt_mcn(weights_path=None, **kwargs):\n    \"\"\"\n    load imported model instance\n\n    Args:\n        weights_path (str): If set, loads model weights from the given path\n    \"\"\"\n    model = Inception_v3_pt_mcn()\n    if weights_path:\n        state_dict = torch.load(weights_path)\n        model.load_state_dict(state_dict)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_encoder = inception_v3_pt_mcn(weights_path='../input/pytorch-inception-v3/inception_v3_pt_mcn.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clip2 = train_dataset.__getitem__(0)[0]\ncnn_encoder(clip2[0].unsqueeze(0)).shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RNN Decoder"},{"metadata":{},"cell_type":"markdown","source":"This RNN will receive an array of encoded spatial data. So for each of the 200 frames, there will be a tensor of shape 1x2048 **Input shape** 200 x 1 x 2048 **Output** 1x40"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, CNN_embed_dim=2048, h_RNN_layers=200, h_RNN=512, h_FC_dim=256, drop_p=0.3, num_classes=40):\n        super(DecoderRNN, self).__init__()\n\n        self.RNN_input_size = CNN_embed_dim\n        self.h_RNN_layers = h_RNN_layers   # RNN hidden layers\n        self.h_RNN = h_RNN                 # RNN hidden nodes\n        self.h_FC_dim = h_FC_dim\n        self.drop_p = drop_p\n        self.num_classes = num_classes\n\n        self.LSTM = nn.LSTM(\n            input_size=self.RNN_input_size,\n            hidden_size=self.h_RNN,        \n            num_layers=h_RNN_layers,       \n            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n        )\n\n        self.fc1 = nn.Linear(self.h_RNN, self.h_FC_dim)\n        self.fc2 = nn.Linear(self.h_FC_dim, self.num_classes)\n\n    def forward(self, x_RNN):\n        \n        self.LSTM.flatten_parameters()\n        RNN_out, (h_n, h_c) = self.LSTM(x_RNN, None)  \n        \"\"\" h_n shape (n_layers, batch, hidden_size), h_c shape (n_layers, batch, hidden_size) \"\"\" \n        \"\"\" None represents zero initial hidden state. RNN_out has shape=(batch, time_step, output_size) \"\"\"\n\n        # FC layers\n        x = self.fc1(RNN_out[:, -1, :])   # choose RNN_out at the last time step\n        x = F.relu(x)\n        x = F.dropout(x, p=self.drop_p, training=self.training)\n        x = self.fc2(x)\n        last_output = x[-1].unsqueeze(0)\n        return last_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnn_decoder = DecoderRNN(drop_p=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if train_on_gpu:\n    cnn_encoder = cnn_encoder.cuda()\n    rnn_decoder = rnn_decoder.cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(rnn_decoder.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_counter = []\ntrain_loss_history = []\ntrain_iteration_number= 0\n\nvalid_counter = []\nvalid_loss_history = []\nvalid_iteration_number= 0\n\n# initialize tracker for minimum validation loss\nvalid_loss_min = np.Inf # set initial \"min\" to infinity\n\ntrain_class_correct = list(0 for i in range(40))\ntrain_class_total = list(0 for i in range(40))\n\nvalid_class_correct = list(0 for i in range(40))\nvalid_class_total = list(0 for i in range(40))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spatial_data2 = torch.zeros(200,1,1000)\n# spatial_data2 = spatial_data2.cuda()\n# o = rnn_decoder(spatial_data2)\n# print(o.shape)\n# # y_pred = torch.max(o, 1)\n# # y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_count = 0   # counting total trained sample in one epoch\nlog_interval = 1\n\nfor epoch in range(0,Config.train_number_epochs):\n    rnn_decoder.train()\n    for batch, (clip, label) in enumerate(train_loader):\n        # distribute data to device\n        spatial_data = torch.zeros(200,1,2048)\n        spatial_data = spatial_data.cuda()\n        clip = clip.cuda()\n        label = label.cuda()\n        N_count += clip.size(0)\n        optimizer.zero_grad()\n\n        count=0\n        for i in clip[0]:\n            spatial_frame = i\n            spatial_data[count,:,:] = cnn_encoder(spatial_frame.unsqueeze(0))\n            count+=1\n\n        output = rnn_decoder(spatial_data)   # output has dim = (batch, number of classes)\n\n        loss = F.cross_entropy(output, label)\n\n        pred = torch.max(output, 1)[1]\n\n        loss.backward()\n        optimizer.step()\n\n        correct = pred.eq(label.view_as(pred))\n        for j in range(len(label)):\n            target = label[j].data\n            train_class_correct[target] += correct[j].item()\n            train_class_total[target] += 1\n\n        if batch%1 == 0:\n            print(\"Clip number {}\\n Current loss {}\\n\".format(batch+1,loss.item()))\n            train_iteration_number +=1\n            train_counter.append(train_iteration_number)\n            train_loss_history.append(loss.item())\n\n#             for i in range(40):\n#                 if train_class_total[i] > 0:\n#                     print('\\nTraining Accuracy of %5s: %2d%% (%2d/%2d)' % (\n#                         str(i), 100 * train_class_correct[i] / train_class_total[i],\n#                         np.sum(train_class_correct[i]), np.sum(train_class_total[i])))\n\n            print('\\nTraining Accuracy (Overall): %2d%% (%2d/%2d)' % (\n                100. * np.sum(train_class_correct) / np.sum(train_class_total),\n                np.sum(train_class_correct), np.sum(train_class_total)))\n            \n    rnn_decoder.eval()\n    for batch, (clip, label) in enumerate(valid_loader):\n        # distribute data to device\n        spatial_data = torch.zeros(200,1,2048)\n        spatial_data = spatial_data.cuda()\n        clip = clip.cuda()\n        label = label.cuda()\n        N_count += clip.size(0)\n\n        count=0\n        for i in clip[0]:\n            spatial_frame = i\n            spatial_data[count,:,:] = cnn_encoder(spatial_frame.unsqueeze(0))\n            count+=1\n\n        output = rnn_decoder(spatial_data)   # output has dim = (batch, number of classes)\n\n        loss = F.cross_entropy(output, label)\n\n        pred = torch.max(output, 1)[1]\n\n        correct = pred.eq(label.view_as(pred))\n        for j in range(len(label)):\n            target = label[j].data\n            valid_class_correct[target] += correct[j].item()\n            valid_class_total[target] += 1\n\n        if batch%1 == 0:\n            print(\"Clip number {}\\n Current loss {}\\n\".format(batch+1,loss.item()))\n            valid_iteration_number +=1\n            valid_counter.append(train_iteration_number)\n            valid_loss_history.append(loss.item())\n\n#             for i in range(40):\n#                 if valid_class_total[i] > 0:\n#                     print('\\nValidation Accuracy of %5s: %2d%% (%2d/%2d)' % (\n#                         str(i), 100 * valid_class_correct[i] / valid_class_total[i],\n#                         np.sum(valid_class_correct[i]), np.sum(valid_class_total[i])))\n\n            print('\\nValidation Accuracy (Overall): %2d%% (%2d/%2d)' % (\n                100. * np.sum(valid_class_correct) / np.sum(valid_class_total),\n                np.sum(valid_class_correct), np.sum(valid_class_total)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Model"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}