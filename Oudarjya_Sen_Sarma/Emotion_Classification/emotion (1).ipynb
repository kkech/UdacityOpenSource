{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotion.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"PNhxpnodPREF","colab_type":"code","outputId":"5999b3cd-83ef-4234-fd0a-b034fc1de9a6","executionInfo":{"status":"ok","timestamp":1565430057532,"user_tz":-330,"elapsed":6470,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GN0n3EWjQLz0","colab_type":"code","colab":{}},"source":["\n","import torch\n","import torch.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VEOWDifCQa3y","colab_type":"code","outputId":"c1d94814-b384-475b-ba3a-42006a7b68f9","executionInfo":{"status":"ok","timestamp":1565430057534,"user_tz":-330,"elapsed":6459,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["\n","c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n","d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n","e = torch.matmul(c, d)\n","print(e)\n","print(c.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 3.],\n","        [3., 7.]])\n","torch.Size([2, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Z8uuEYGSW8C","colab_type":"code","outputId":"f753bb59-0a82-4f05-af32-b5f3ff4c1265","executionInfo":{"status":"ok","timestamp":1565430057534,"user_tz":-330,"elapsed":6452,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["\n","### Automatic differentiation with PyTorch\n","x = torch.ones(2, 2, requires_grad=True)\n","\n","# an operation of tensor\n","y = x + 2 # y inherits grad_fn\n","\n","# apply operations on y\n","z = y * y * 3\n","out = z.mean()\n","\n","print(out)\n","\n","out.backward()\n","\n","print(x.grad) # d(out)/dx"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(27., grad_fn=<MeanBackward1>)\n","tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LpHIcGSbShmB","colab_type":"code","outputId":"e6168837-daf0-4970-d25c-0ffb2c62ee8f","executionInfo":{"status":"ok","timestamp":1565430057534,"user_tz":-330,"elapsed":6444,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(\"X shape: \", x.size())\n","\n","# add dimension\n","print(x.unsqueeze(1).size()) \n","\n","# transpose \n","torch.transpose(x, 0,1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X shape:  torch.Size([2, 3])\n","torch.Size([2, 1, 3])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 4],\n","        [2, 5],\n","        [3, 6]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"x8GTXWvYSqNR","colab_type":"code","colab":{}},"source":["# emotion dataset starts from here"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekqRbUCZSudq","colab_type":"code","colab":{}},"source":["import re\n","import numpy as np\n","import time\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import itertools\n","import pandas as pd\n","from scipy import stats\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmYmZbgSSzp6","colab_type":"code","colab":{}},"source":["\n","### Helper functions\n","import pickle\n","\n","def convert_to_pickle(item, directory):\n","    pickle.dump(item, open(directory,\"wb\"))\n","\n","\n","def load_from_pickle(directory):\n","    return pickle.load(open(directory,\"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FQCv6aIS5Py","colab_type":"code","outputId":"5a32a4ff-2213-4651-840b-89b38b636187","executionInfo":{"status":"ok","timestamp":1565430079383,"user_tz":-330,"elapsed":28249,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["### read data from your Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WmV1OesSS_Sa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rS3Pe8CgTMqK","colab_type":"code","outputId":"0c9bbcf2-b56d-4c81-ea04-164f399f3b74","executionInfo":{"status":"ok","timestamp":1565430101149,"user_tz":-330,"elapsed":50003,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cP8Or-zJTNvR","colab_type":"code","outputId":"a40b64aa-8683-455b-cc4b-01665d39c5eb","executionInfo":{"status":"ok","timestamp":1565430101627,"user_tz":-330,"elapsed":50475,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":317}},"source":["# load data\n","data = load_from_pickle(directory=\"/content/drive/My Drive/Colab Notebooks/merged_training.pkl\")\n","data.emotions.value_counts().plot.bar()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7ff4934b78d0>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERtf1/4EfnAP+MudQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"WVi08k9MTq6C","colab_type":"code","outputId":"cd9027c6-6653-455e-8b2f-061a505ce61e","executionInfo":{"status":"ok","timestamp":1565430101628,"user_tz":-330,"elapsed":50468,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":349}},"source":["data.head(10)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>emotions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27383</th>\n","      <td>i feel awful about it too because it s my job ...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>110083</th>\n","      <td>im alone i feel awful</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>140764</th>\n","      <td>ive probably mentioned this before but i reall...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>100071</th>\n","      <td>i was feeling a little low few days back</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>2837</th>\n","      <td>i beleive that i am much more sensitive to oth...</td>\n","      <td>love</td>\n","    </tr>\n","    <tr>\n","      <th>18231</th>\n","      <td>i find myself frustrated with christians becau...</td>\n","      <td>love</td>\n","    </tr>\n","    <tr>\n","      <th>10714</th>\n","      <td>i am one of those people who feels like going ...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>35177</th>\n","      <td>i feel especially pleased about this as this h...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>122177</th>\n","      <td>i was struggling with these awful feelings and...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>26723</th>\n","      <td>i feel so enraged but helpless at the same time</td>\n","      <td>anger</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     text emotions\n","27383   i feel awful about it too because it s my job ...  sadness\n","110083                              im alone i feel awful  sadness\n","140764  ive probably mentioned this before but i reall...      joy\n","100071           i was feeling a little low few days back  sadness\n","2837    i beleive that i am much more sensitive to oth...     love\n","18231   i find myself frustrated with christians becau...     love\n","10714   i am one of those people who feels like going ...      joy\n","35177   i feel especially pleased about this as this h...      joy\n","122177  i was struggling with these awful feelings and...      joy\n","26723     i feel so enraged but helpless at the same time    anger"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"4nAglO8ET126","colab_type":"code","colab":{}},"source":["# PRE-PROCESSINGN DATA!!!\n","\n","# Tokenizing and Sampling!!!\n","\n","\n","# retain only text that contain less that 70 tokens to avoid too much padding\n","data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n","data = data.loc[data['token_size'] < 70].copy()\n","\n","# sampling\n","data = data.sample(n=50000);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"72dIniIaT60q","colab_type":"code","colab":{}},"source":["# Constructing Vocabulary and Index-Word Mapping\n","\n","# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n","# (e.g., 5 -> \"dad\") for the dataset\n","class ConstructVocab():\n","    def __init__(self, sentences):\n","        self.sentences = sentences\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab = set()\n","        self.create_index()\n","        \n","    def create_index(self):\n","        for s in self.sentences:\n","            # update with individual tokens\n","            self.vocab.update(s.split(' '))\n","            \n","        # sort the vocab\n","        self.vocab = sorted(self.vocab)\n","\n","        # add a padding token with index 0\n","        self.word2idx['<pad>'] = 0\n","        \n","        # word to index mapping\n","        for index, word in enumerate(self.vocab):\n","            self.word2idx[word] = index + 1 # +1 because of pad token\n","        \n","        # index to word mapping\n","        for word, index in self.word2idx.items():\n","            self.idx2word[index] = word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vsno_Y4lUjrK","colab_type":"code","outputId":"424aa714-6f5b-4c53-fedf-21816f557060","executionInfo":{"status":"ok","timestamp":1565430102543,"user_tz":-330,"elapsed":51365,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["# construct vocab and indexing\n","inputs = ConstructVocab(data[\"text\"].values.tolist())\n","\n","# examples of what is in the vocab\n","inputs.vocab[0:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a',\n"," 'aa',\n"," 'aaaaaand',\n"," 'aaaah',\n"," 'aaah',\n"," 'aahed',\n"," 'aahhing',\n"," 'aand',\n"," 'aaron',\n"," 'aarons']"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"qJq3hyxgUplq","colab_type":"code","colab":{}},"source":["# Converting Data into Tensors(for convenience!!!)\n","\n","\n","# vectorize to tensor\n","input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3rzx6esVXVq","colab_type":"code","outputId":"9b195398-5d0b-409b-a43a-07b137afb476","executionInfo":{"status":"ok","timestamp":1565430102937,"user_tz":-330,"elapsed":51749,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":656}},"source":["# examples of what is in the input tensors\n","input_tensor[0:2]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[11503,\n","  22837,\n","  23927,\n","  1,\n","  4215,\n","  13419,\n","  16119,\n","  16629,\n","  9836,\n","  18823,\n","  898,\n","  11503,\n","  784,\n","  8683,\n","  1,\n","  2388,\n","  12101,\n","  61,\n","  18941,\n","  24554,\n","  1,\n","  13868,\n","  16516,\n","  1427,\n","  16739,\n","  21177,\n","  18826,\n","  4628,\n","  24166,\n","  1215,\n","  13595,\n","  10055,\n","  4628,\n","  24530,\n","  26908,\n","  26809],\n"," [11503, 8673, 11592, 898, 16261, 24569]]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"g3vgYzoJVZe5","colab_type":"code","colab":{}},"source":["#  Padding data\n","\n","# In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length.\n","\n","\n","def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEcmwjc3V4WJ","colab_type":"code","outputId":"f54f7724-fe75-4fe9-dec1-bad94743ec0e","executionInfo":{"status":"ok","timestamp":1565430102938,"user_tz":-330,"elapsed":51739,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# calculate the max_length of input tensor\n","max_length_inp = max_length(input_tensor)\n","print(max_length_inp)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["69\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VbCqiv17Wya5","colab_type":"code","colab":{}},"source":["def pad_sequences(x, max_len):\n","    padded = np.zeros((max_len), dtype=np.int64)\n","    if len(x) > max_len: padded[:] = x[:max_len]\n","    else: padded[:len(x)] = x\n","    return padded"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbAQ3IugXLpZ","colab_type":"code","colab":{}},"source":["# inplace padding\n","input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QtlMSHdXbiJ","colab_type":"code","outputId":"72ebe7e0-df4d-4bd5-c76e-a22fea1d53c8","executionInfo":{"status":"ok","timestamp":1565430103533,"user_tz":-330,"elapsed":52320,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":294}},"source":["input_tensor[0:2]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([11503, 22837, 23927,     1,  4215, 13419, 16119, 16629,  9836,\n","        18823,   898, 11503,   784,  8683,     1,  2388, 12101,    61,\n","        18941, 24554,     1, 13868, 16516,  1427, 16739, 21177, 18826,\n","         4628, 24166,  1215, 13595, 10055,  4628, 24530, 26908, 26809,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0]),\n"," array([11503,  8673, 11592,   898, 16261, 24569,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0])]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"M_XWxYJeXebB","colab_type":"code","colab":{}},"source":["# Binarization\n","\n","# We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Molm3QhIYYkZ","colab_type":"code","colab":{}},"source":["### convert targets to one-hot encoding vectors\n","emotions = list(set(data.emotions.unique()))\n","num_emotions = len(emotions)\n","# binarizer\n","mlb = preprocessing.MultiLabelBinarizer()\n","data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n","bin_emotions = mlb.fit_transform(data_labels)\n","target_tensor = np.array(bin_emotions.tolist())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"la6wARN1ZHzx","colab_type":"code","outputId":"40284cbd-0015-476a-de82-445c44ffde57","executionInfo":{"status":"ok","timestamp":1565430103535,"user_tz":-330,"elapsed":52309,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["target_tensor[0:2]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 1, 0]])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"frPCFCJaZJ4w","colab_type":"code","outputId":"2695e384-befe-45df-8e36-18a89a1e37c0","executionInfo":{"status":"ok","timestamp":1565430103535,"user_tz":-330,"elapsed":52304,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["data[0:2]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>emotions</th>\n","      <th>token_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>34965</th>\n","      <td>i started teaching a class last night on getti...</td>\n","      <td>fear</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>36124</th>\n","      <td>i feel ignored and not tolerated</td>\n","      <td>sadness</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    text emotions  token_size\n","34965  i started teaching a class last night on getti...     fear          36\n","36124                   i feel ignored and not tolerated  sadness           6"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"gAVOvjkqZMJh","colab_type":"code","colab":{}},"source":["get_emotion = lambda t: np.argmax(t)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EroIea1yZT9K","colab_type":"code","outputId":"687ad34e-e2d0-4f9b-fcce-b8267680bc47","executionInfo":{"status":"ok","timestamp":1565430103536,"user_tz":-330,"elapsed":52295,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["get_emotion(target_tensor[0])\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"k51NuYb6ZXKR","colab_type":"code","colab":{}},"source":["emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CPm-GmsZeeB","colab_type":"code","outputId":"aa4aae03-9da0-45df-9977-e0deb1f4397c","executionInfo":{"status":"ok","timestamp":1565430103935,"user_tz":-330,"elapsed":52685,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["emotion_dict[get_emotion(target_tensor[0])]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'fear'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"OhzzUN7KZg4B","colab_type":"code","outputId":"a9f59860-cc59-4b9c-f061-a66acaa770b1","executionInfo":{"status":"ok","timestamp":1565430103936,"user_tz":-330,"elapsed":52681,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Split data\n","\n","# We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models.\n","\n","# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n","input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n","\n","# Show length\n","len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40000, 40000, 5000, 5000, 5000, 5000)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"YqJn-oRBaBEJ","colab_type":"code","colab":{}},"source":["# Data Loader\n","\n","# We can also laod the data into a data loader, which makes it easy to manipulate the data, create batches, and apply further transformations. In PyTorch we can use the DataLoader function.\n","\n","TRAIN_BUFFER_SIZE = len(input_tensor_train)\n","VAL_BUFFER_SIZE = len(input_tensor_val)\n","TEST_BUFFER_SIZE = len(input_tensor_test)\n","BATCH_SIZE = 64\n","TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n","VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n","TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n","\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inputs.word2idx)\n","target_size = num_emotions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bzVPUTEbHzR","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cvr-a8zXbJbp","colab_type":"code","colab":{}},"source":["# convert the data to tensors and pass to the Dataloader \n","# to create an batch iterator\n","\n","class MyData(Dataset):\n","    def __init__(self, X, y):\n","        self.data = X\n","        self.target = y\n","        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n","        \n","    def __getitem__(self, index):\n","        x = self.data[index]\n","        y = self.target[index]\n","        x_len = self.length[index]\n","        return x, y, x_len\n","    \n","    def __len__(self):\n","        return len(self.data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"faW0RmxFbTaI","colab_type":"code","colab":{}},"source":["train_dataset = MyData(input_tensor_train, target_tensor_train)\n","val_dataset = MyData(input_tensor_val, target_tensor_val)\n","test_dataset = MyData(input_tensor_test, target_tensor_test)\n","\n","train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n","                     drop_last=True,\n","                     shuffle=True)\n","val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n","                     drop_last=True,\n","                     shuffle=True)\n","test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n","                     drop_last=True,\n","                     shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bB8a4IE_bkFQ","colab_type":"code","outputId":"74216756-5123-4b50-f885-2397c584c7f5","executionInfo":{"status":"ok","timestamp":1565430104467,"user_tz":-330,"elapsed":53191,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_dataset.batch_size\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"ftpIOpj2bnoQ","colab_type":"code","colab":{}},"source":["# Model\n","# After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details.\n","\n","# Constructing the Model\n","# Below we construct our model:\n","\n","class EmoGRU(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n","        super(EmoGRU, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.hidden_units = hidden_units\n","        self.embedding_dim = embedding_dim\n","        self.vocab_size = vocab_size\n","        self.output_size = output_size\n","        \n","        # layers\n","        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n","        self.fc = nn.Linear(self.hidden_units, self.output_size)\n","    \n","    def initialize_hidden_state(self, device):\n","        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n","    \n","    def forward(self, x, lens, device):\n","        x = self.embedding(x)\n","        self.hidden = self.initialize_hidden_state(device)\n","        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n","        out = output[-1, :, :] \n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        return out, self.hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3J9Oqsqc1bQ","colab_type":"code","colab":{}},"source":["#  Pretesting model\n","\n","### sort batch function to be able to use with pad_packed_sequence\n","def sort_batch(X, y, lengths):\n","    lengths, indx = lengths.sort(dim=0, descending=True)\n","    X = X[indx]\n","    y = y[indx]\n","    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gC-wW6SSdv0I","colab_type":"code","outputId":"84a143d8-b26d-4ea2-ea1d-675ce3cded0e","executionInfo":{"status":"ok","timestamp":1565430105839,"user_tz":-330,"elapsed":54551,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n","model.to(device)\n","\n","# obtain one sample from the data iterator\n","it = iter(train_dataset)\n","x, y, x_len = next(it)\n","\n","# sort the batch first to be able to use with pac_pack sequence\n","xs, ys, lens = sort_batch(x, y, x_len)\n","\n","print(\"Input size: \", xs.size())\n","\n","output, _ = model(xs.to(device), lens, device)\n","print(output.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input size:  torch.Size([69, 64])\n","torch.Size([64, 6])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KUKxqm8feH0h","colab_type":"code","colab":{}},"source":["# Training the Model\n","\n","# Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model.\n","\n","### Enabling cuda\n","use_cuda = True if torch.cuda.is_available() else False\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n","model.to(device)\n","\n","### loss criterion and optimizer for training\n","criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","def loss_function(y, prediction):\n","    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n","    # convert from one-hot encoding to class indices\n","    target = torch.max(y, 1)[1]\n","    loss = criterion(prediction, target) \n","    return loss   #TODO: refer the parameter of these functions as the same\n","    \n","def accuracy(target, logit):\n","    ''' Obtain accuracy for training round '''\n","    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n","    corrects = (torch.max(logit, 1)[1].data == target).sum()\n","    accuracy = 100.0 * corrects / len(logit)\n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqI55rIWfOrI","colab_type":"code","outputId":"152fb3e0-3c8d-465d-e98a-977f437ab306","executionInfo":{"status":"ok","timestamp":1565454811448,"user_tz":-330,"elapsed":3525416,"user":{"displayName":"satchTech","photoUrl":"https://lh5.googleusercontent.com/-lhwGbZExmE0/AAAAAAAAAAI/AAAAAAAAAG0/-zFiC00br70/s64/photo.jpg","userId":"16856691065958831406"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","    \n","    ### Initialize hidden state\n","    # TODO: do initialization here.\n","    total_loss = 0\n","    train_accuracy, val_accuracy = 0, 0\n","    \n","    ### Training\n","    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n","        loss = 0\n","        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n","              \n","        loss += loss_function(targ.to(device), predictions)\n","        batch_loss = (loss / int(targ.shape[1]))        \n","        total_loss += batch_loss\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        batch_accuracy = accuracy(targ.to(device), predictions)\n","        train_accuracy += batch_accuracy\n","        \n","        if batch % 100 == 0:\n","            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n","                                                         batch,\n","                                                         batch_loss.cpu().detach().numpy()))\n","            \n","    ### Validating\n","    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n","        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n","        batch_accuracy = accuracy(targ.to(device), predictions)\n","        val_accuracy += batch_accuracy\n","    \n","    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n","                                                             total_loss / TRAIN_N_BATCH, \n","                                                             train_accuracy / TRAIN_N_BATCH,\n","                                                             val_accuracy / VAL_N_BATCH))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Val. Loss 0.2951\n","Epoch 1 Batch 100 Val. Loss 0.2680\n","Epoch 1 Batch 200 Val. Loss 0.2241\n","Epoch 1 Batch 300 Val. Loss 0.1192\n","Epoch 1 Batch 400 Val. Loss 0.0514\n","Epoch 1 Batch 500 Val. Loss 0.0249\n","Epoch 1 Batch 600 Val. Loss 0.0299\n","Epoch 1 Loss 0.1425 -- Train Acc. 66.0000 -- Val Acc. 91.0000\n","Time taken for 1 epoch 2468.5131521224976 sec\n","\n","Epoch 2 Batch 0 Val. Loss 0.0482\n","Epoch 2 Batch 100 Val. Loss 0.0189\n","Epoch 2 Batch 200 Val. Loss 0.0241\n","Epoch 2 Batch 300 Val. Loss 0.0409\n","Epoch 2 Batch 400 Val. Loss 0.0182\n","Epoch 2 Batch 500 Val. Loss 0.0232\n","Epoch 2 Batch 600 Val. Loss 0.0164\n","Epoch 2 Loss 0.0274 -- Train Acc. 92.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2469.4959762096405 sec\n","\n","Epoch 3 Batch 0 Val. Loss 0.0272\n","Epoch 3 Batch 100 Val. Loss 0.0078\n","Epoch 3 Batch 200 Val. Loss 0.0219\n","Epoch 3 Batch 300 Val. Loss 0.0237\n","Epoch 3 Batch 400 Val. Loss 0.0143\n","Epoch 3 Batch 500 Val. Loss 0.0064\n","Epoch 3 Batch 600 Val. Loss 0.0218\n","Epoch 3 Loss 0.0199 -- Train Acc. 93.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2465.3774077892303 sec\n","\n","Epoch 4 Batch 0 Val. Loss 0.0222\n","Epoch 4 Batch 100 Val. Loss 0.0302\n","Epoch 4 Batch 200 Val. Loss 0.0105\n","Epoch 4 Batch 300 Val. Loss 0.0195\n","Epoch 4 Batch 400 Val. Loss 0.0267\n","Epoch 4 Batch 500 Val. Loss 0.0233\n","Epoch 4 Batch 600 Val. Loss 0.0170\n","Epoch 4 Loss 0.0179 -- Train Acc. 94.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2462.9142706394196 sec\n","\n","Epoch 5 Batch 0 Val. Loss 0.0287\n","Epoch 5 Batch 100 Val. Loss 0.0169\n","Epoch 5 Batch 200 Val. Loss 0.0169\n","Epoch 5 Batch 300 Val. Loss 0.0115\n","Epoch 5 Batch 400 Val. Loss 0.0116\n","Epoch 5 Batch 500 Val. Loss 0.0276\n","Epoch 5 Batch 600 Val. Loss 0.0148\n","Epoch 5 Loss 0.0164 -- Train Acc. 94.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2462.4235043525696 sec\n","\n","Epoch 6 Batch 0 Val. Loss 0.0037\n","Epoch 6 Batch 100 Val. Loss 0.0132\n","Epoch 6 Batch 200 Val. Loss 0.0034\n","Epoch 6 Batch 300 Val. Loss 0.0050\n","Epoch 6 Batch 400 Val. Loss 0.0130\n","Epoch 6 Batch 500 Val. Loss 0.0068\n","Epoch 6 Batch 600 Val. Loss 0.0169\n","Epoch 6 Loss 0.0144 -- Train Acc. 95.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2467.711112976074 sec\n","\n","Epoch 7 Batch 0 Val. Loss 0.0023\n","Epoch 7 Batch 100 Val. Loss 0.0253\n","Epoch 7 Batch 200 Val. Loss 0.0066\n","Epoch 7 Batch 300 Val. Loss 0.0298\n","Epoch 7 Batch 400 Val. Loss 0.0298\n","Epoch 7 Batch 500 Val. Loss 0.0153\n","Epoch 7 Batch 600 Val. Loss 0.0139\n","Epoch 7 Loss 0.0127 -- Train Acc. 96.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2473.9005177021027 sec\n","\n","Epoch 8 Batch 0 Val. Loss 0.0025\n","Epoch 8 Batch 100 Val. Loss 0.0076\n","Epoch 8 Batch 200 Val. Loss 0.0056\n","Epoch 8 Batch 300 Val. Loss 0.0058\n","Epoch 8 Batch 400 Val. Loss 0.0191\n","Epoch 8 Batch 500 Val. Loss 0.0033\n","Epoch 8 Batch 600 Val. Loss 0.0009\n","Epoch 8 Loss 0.0108 -- Train Acc. 96.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2474.858388900757 sec\n","\n","Epoch 9 Batch 0 Val. Loss 0.0022\n","Epoch 9 Batch 100 Val. Loss 0.0050\n","Epoch 9 Batch 200 Val. Loss 0.0119\n","Epoch 9 Batch 300 Val. Loss 0.0062\n","Epoch 9 Batch 400 Val. Loss 0.0028\n","Epoch 9 Batch 500 Val. Loss 0.0124\n","Epoch 9 Batch 600 Val. Loss 0.0346\n","Epoch 9 Loss 0.0087 -- Train Acc. 97.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2475.2711675167084 sec\n","\n","Epoch 10 Batch 0 Val. Loss 0.0014\n","Epoch 10 Batch 100 Val. Loss 0.0006\n","Epoch 10 Batch 200 Val. Loss 0.0193\n","Epoch 10 Batch 300 Val. Loss 0.0011\n","Epoch 10 Batch 400 Val. Loss 0.0016\n","Epoch 10 Batch 500 Val. Loss 0.0350\n","Epoch 10 Batch 600 Val. Loss 0.0069\n","Epoch 10 Loss 0.0084 -- Train Acc. 97.0000 -- Val Acc. 92.0000\n","Time taken for 1 epoch 2484.80894613266 sec\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-JXxMu53fXU4","colab_type":"code","colab":{}},"source":["model.parameters\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_9_4rGwiM71","colab_type":"code","colab":{}},"source":["# Evaluation on the Testing Data\n","\n","test_accuracy = 0\n","all_predictions = []\n","x_raw = []\n","y_raw = []\n","\n","device = \"cuda\" # we don't need GPU to do testing\n","model.to(\"cuda\")\n","\n","for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n","    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n","    batch_accuracy = accuracy(targ.to(device), predictions)\n","    test_accuracy += batch_accuracy\n","    \n","    x_raw = x_raw + [x for x in inp]\n","    y_raw = y_raw + [y for y in targ]\n","    \n","    all_predictions.append(predictions)\n","    \n","print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Sn_98cXiuJ_","colab_type":"code","colab":{}},"source":["#Confusion Matrix!!!!!!\n","\n","### Class to Properly Evaluate our Models\n","class Evaluate():\n","\n","    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n","        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n","        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n","        y_va = target.dot(va_matrix)\n","        F_va = prediction.dot(va_matrix)\n","\n","        # dist is a one row vector with size of the test data passed(emotion)\n","        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n","        res = stats.describe(dist)\n","\n","        # print by default (if silent=False)\n","        if not silent:\n","            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n","\n","        return {\n","            'distances': dist,\n","            'dist_stat': res\n","        }\n","\n","    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n","        \"\"\" Compute only the predicted class \"\"\"\n","        p_2_annotation = dict()\n","\n","        precision_recall_fscore_support = [\n","            (pair[0], pair[1].mean()) for pair in zip(\n","                ['precision', 'recall', 'f1', 'support'],\n","                metrics.precision_recall_fscore_support(target, predictions)\n","            )\n","        ]\n","\n","        metrics.precision_recall_fscore_support(target, predictions)\n","\n","        # confusion matrix\n","        le = LabelEncoder()\n","        target_le = le.fit_transform(target)\n","        predictions_le = le.transform(predictions)\n","        cm = metrics.confusion_matrix(target_le, predictions_le)\n","\n","        # prediction if two annotations are given on test data\n","        if target2:\n","            p_2_annotation = pd.DataFrame(\n","                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n","                columns=['emo','success']\n","            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n","\n","        if not silent:\n","            print(\"Default Classification report\")\n","            print(metrics.classification_report(target, predictions))\n","\n","            # print if target2 was provided\n","            if len(p_2_annotation) > 0:\n","                print('\\nPrecision on 2 annotations:')\n","                for emo in p_2_annotation:\n","                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n","\n","            # print accuracies, precision, recall, and f1\n","            print('\\nAccuracy:')\n","            print(metrics.accuracy_score(target, predictions))\n","            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n","            for to_print in precision_recall_fscore_support[:3]:\n","                print( \"%s: %.2f\" % to_print )\n","\n","            # normalizing the values of the consfusion matrix\n","            print('\\nconfusion matrix\\n %s' % cm)\n","            print('(row=expected, col=predicted)')\n","            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n","\n","        return {\n","            'precision_recall_fscore_support': precision_recall_fscore_support,\n","            'accuracy': metrics.accuracy_score(target, predictions),\n","            'p_2_annotation': p_2_annotation,\n","            'confusion_matrix': cm\n","        }\n","\n","    def predict_class(cls, X_train, y_train, X_test, y_test,\n","                      pipeline, silent=False, target2=None):\n","        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n","        pipeline.fit(X_train, y_train)\n","        predictions = pipeline.predict(X_test)\n","        print(\"predictions computed....\")\n","        return cls.evaluate_class(predictions, y_test, target2, silent)\n","\n","    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n","        \"\"\" Evaluate through probability \"\"\"\n","        # Run normal class evaluator\n","        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n","        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n","\n","        if not silent:\n","            print('\\n - First Emotion Classification Metrics -')\n","            print('\\n - Multiple Emotion rank Metrics -')\n","            print('VA Cosine Distance')\n","\n","        classes_dist = [\n","            (\n","                emo,\n","                cls.va_dist(\n","                    prediction[np.array(target_class) == emo],\n","                    target_rank[np.array(target_class) == emo],\n","                    va_df,\n","                    binarizer,\n","                    emo,\n","                    silent)\n","                ) for emo in binarizer.classes_\n","        ]\n","        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n","\n","        coverage_error = metrics.coverage_error(target_rank, prediction)\n","        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n","        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n","        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n","\n","        # recall at 2\n","        # obtain top two predictions\n","        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n","        recall_at_2 = pd.DataFrame(\n","            [\n","            t in p for t, p in zip(target_class, top2_pred)\n","            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n","\n","        # combine target into sets\n","        if target2:\n","            union_target = [set(t) for t in zip(target_class, target2)]\n","        else:\n","            union_target = [set(t) for t in zip(target_class)]\n","\n","        # precision at k\n","        top_k_pred = [\n","            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n","            for i in range(2, len(binarizer.classes_)+1)]\n","        precision_at_k = [\n","            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n","            for k in range(len(top_k_pred))]\n","\n","        # do this if silent= False\n","        if not silent:\n","            print('\\n')\n","            print(recall_at_2)\n","            print('\\n')\n","            print('p@k')\n","            for pk in precision_at_k:\n","                print(pk[0] + ':\\t' + str(pk[1]))\n","            print('\\ncoverage_error: %f' % coverage_error)\n","            print('average_precision_score: %f' % average_precision_score)\n","            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n","            print('label_ranking_loss: %f' % label_ranking_loss)\n","\n","        return {\n","            'class_eval': class_eval,\n","            'recall_at_2': recall_at_2.to_dict(),\n","            'precision_at_2': precision_at_k,\n","            'classes_dist': classes_dist,\n","            'avg_dist': avg_dist,\n","            'coverage_error': coverage_error,\n","            'average_precision_score': average_precision_score,\n","            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n","            'label_ranking_loss': label_ranking_loss\n","        }\n","\n","\n","    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n","        \"\"\" Output predcations based on training and labels \"\"\"\n","        pipeline.fit(X_train, y_train)\n","        predictions = pipeline.predict_proba(X_test)\n","        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n","        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n","\n","\n","    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n","        \"\"\" Plotting the confusion_matrix\"\"\"\n","        plt.rc('figure', figsize=(4, 4), dpi=100)\n","        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","        plt.title(title)\n","        plt.colorbar()\n","        tick_marks = np.arange(len(my_tags))\n","        target_names = my_tags\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","        \n","        # add normalized values inside the Confusion matrix\n","        fmt = '.2f'\n","        thresh = cm.max() / 2.\n","        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","        plt.tight_layout()\n","        plt.ylabel('True label')\n","        plt.xlabel('Predicted label')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLU_XBnhew3e","colab_type":"code","colab":{}},"source":["evaluator = Evaluate()\n","\n","final_predictions = []\n","\n","for p in all_predictions:\n","    for sub_p in p:\n","        final_predictions.append(sub_p.cpu().detach().numpy())\n","        \n","predictions = [np.argmax(p).item() for p in final_predictions]\n","targets = [np.argmax(t).item() for t in y_raw]\n","correct_predictions = float(np.sum(predictions == targets))\n","\n","# predictions\n","predictions_human_readable = ((x_raw, predictions))\n","# actual targets\n","target_human_readable = ((x_raw,  targets))\n","\n","emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n","\n","# convert results into dataframe\n","model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n","test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n","\n","model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n","test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n","\n","evaluator.evaluate_class(model_test_result.emotion, test.emotion "],"execution_count":0,"outputs":[]}]}