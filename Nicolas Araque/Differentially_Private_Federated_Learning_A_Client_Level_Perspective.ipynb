{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Differentially Private Federated Learning: A Client Level Perspective",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3463pBcrvkD_",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of: \n",
        "Differentially Private Federated Learning: A Client Level Perspective (https://arxiv.org/abs/1712.07557)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E44I7Tc8Y4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def download_github_code():\n",
        "    os.system(\"wget https://raw.githubusercontent.com/tensorflow/privacy/master/privacy/analysis/rdp_accountant.py\")\n",
        "\n",
        "download_github_code()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCeaeD7aN1Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from numpy import linalg as LA\n",
        "from rdp_accountant import compute_rdp  # pylint: disable=g-import-not-at-top\n",
        "from rdp_accountant import get_privacy_spent\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ-G5K-PlmqP",
        "colab_type": "text"
      },
      "source": [
        "# The client class\n",
        "\n",
        "The client class implements the update method. That is, for a given weights that the server sends, the client train those models in his data and then send the deltas and the L2 norm.\n",
        "\n",
        "The constructor of the class needs: \n",
        "\n",
        "\n",
        "\n",
        "*   number: The number of this client. Every client get a number from 0 to num_clients (only needed for debug)\n",
        "*   loader: The data that is private to this client\n",
        "* state_dict: The weights for the first model\n",
        "* batch_size: The batch size that is going to use the client training the local model\n",
        "* epochs: The number of epochs\n",
        "* lr: The learning rate\n",
        "\n",
        "\n",
        "\n",
        "I'm returning the deltas in a dict with the same keys as the state_dict of the \"parent\" model.\n",
        "\n",
        "* wt1: Dict with the same keys as state_dict with the deltas of all the weights\n",
        "* S: Dict with the same keys as state_dict with the L2 norms of all deltas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03TPovwIh3rd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "class client():\n",
        "  def __init__(self, number, loader, state_dict, batch_size = 32, epochs=2, lr=0.01):\n",
        "    self.number = number\n",
        "    self.model = t_model()\n",
        "    self.model.load_state_dict(state_dict)\n",
        "    self.criterion = nn.NLLLoss()\n",
        "    self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
        "    self.epochs = epochs\n",
        "    self.device =  device =  torch.device(\"cuda:0\"\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.dataLoader = loader                                       \n",
        "                                           \n",
        "                                  \n",
        "  #\n",
        "  def update(self, state_dict):\n",
        "    w0 = state_dict\n",
        "    self.model.load_state_dict(state_dict)\n",
        "    self.model.to(self.device)\n",
        "    running_loss = 0\n",
        "    accuracy = 0\n",
        "    for e in range(self.epochs):\n",
        "        # Model in training mode, dropout is on\n",
        "        self.model.train()\n",
        "        accuracy=0\n",
        "        running_loss = 0\n",
        "        for images, labels in self.dataLoader:            \n",
        "            images, labels = images.to(self.device), labels.to(self.device)                       \n",
        "            self.optimizer.zero_grad()            \n",
        "            output = self.model.forward(images)\n",
        "            loss = self.criterion(output, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()            \n",
        "            running_loss += loss.item()        \n",
        "    S ={} \n",
        "    wt1 = {}\n",
        "    for key, value in w0.items():\n",
        "      wt1[key] = self.model.state_dict()[key]  - value   \n",
        "      S[key] = LA.norm(wt1[key].cpu(), 2)\n",
        "    return wt1, S\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZQdtvomGJE",
        "colab_type": "text"
      },
      "source": [
        "# The server class\n",
        "\n",
        "The server class implements the server that holds the central model. \n",
        "\n",
        "The server class needs:\n",
        "\n",
        "* number of clients that is going to create\n",
        "* p_budget: The delta bugdet that we have for the training rounds\n",
        "* Epsilon: The desired epsilon for the Diff Privacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTougkZbiFWa",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "class server():\n",
        "  def __init__(self, number_clients, p_budget, epsilon, sigmat = 1.12):\n",
        "    self.model = t_model()\n",
        "    self.sigmat = sigmat   \n",
        "    self.n_clients = number_clients\n",
        "    self.samples = get_samples(self.n_clients)\n",
        "    self.clients = list()\n",
        "    for i in range(number_clients):\n",
        "      loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=32, sampler=self.samples[i])\n",
        "      self.clients.append(client(i, loader, self.model.state_dict()))\n",
        "    self.p_budget = p_budget\n",
        "    self.epsilon = epsilon\n",
        "    self.testLoader = torch.utils.data.DataLoader(mnist_testset, batch_size=32)\n",
        "    self.device = torch.device(\"cuda:0\"\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.orders = ([1.25, 1.5, 1.75, 2., 2.25, 2.5, 3., 3.5, 4., 4.5] +\n",
        "            list(range(5, 64)) + [128, 256, 512])\n",
        "    \n",
        "    \n",
        "  #Evaluates the accuracy of the current model with the test data.  \n",
        "  def eval_acc(self):\n",
        "    self.model.to(self.device)\n",
        "    #print('Aqui voy!')\n",
        "    running_loss = 0\n",
        "    accuracy = 0\n",
        "    self.model.eval()\n",
        "    suma=0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "    for images, labels in self.testLoader:            \n",
        "        images, labels = images.to(self.device), labels.to(self.device) \n",
        "        output = self.model.forward(images)             \n",
        "        ps = torch.exp(output)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        total += equals.size(0)\n",
        "        suma = suma + equals.sum().item()\n",
        "    else:      \n",
        "        print('Accuracy: ',suma/float(total))\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        " #Given:\n",
        " # mt: number of clients involved in this round. \n",
        "  #deltas: list of dicts with the deltas of every client\n",
        "  #norms: list of dicts with the norms of every weights for every client\n",
        "  #sigma: Sigma to calculate the StdDistribution of the GaussianNormalNoise\n",
        "  #state_dicst: Dict with the current model weights \n",
        "  \n",
        "# This functions apply noise to the given deltas. \n",
        "\n",
        "  \n",
        "  def sanitaze(self,mt, deltas, norms, sigma, state_dict):    \n",
        "    new_dict = {}\n",
        "    for key, value in state_dict.items():\n",
        "      S=[]\n",
        "      for i in range(len(norms)):        \n",
        "        S.append(norms[i][key])\n",
        "      S_value = np.median(S)      \n",
        "      wt = value\n",
        "      prom = 1/float(mt)       \n",
        "      suma = 0\n",
        "      for i in range(len(deltas)):    \n",
        "        clip = (max(1, float(norms[i][key]/S_value)))            \n",
        "        suma = suma + ((deltas[i][key] / clip ))\n",
        "      noise = np.random.normal(0, float(S_value * sigma), size = suma.shape)      \n",
        "      suma = suma.cpu().numpy()\n",
        "      suma = suma*prom\n",
        "      noise = noise*prom\n",
        "      suma = suma + noise  \n",
        "      \n",
        "      suma = torch.from_numpy(suma)\n",
        "      suma = wt + suma.float()\n",
        "      new_dict[key] = suma\n",
        "    return new_dict\n",
        "    \n",
        " \n",
        "  '''\n",
        "  Given the number of clients that we're going to train in each round:\n",
        "  First computes the RDP Privacy Involved in doing a training on:\n",
        "    q: Sampling ratio. The number of clients involved in one round/total of clients\n",
        "    sigmat: The sigma of the Gaussian noise. For this implementation, sigma is the ratio between \n",
        "            StdDeviation and the Sensitivity of the function. In our case the sensitivity of \n",
        "            the function is S. That's why the GaussianNoise is S*sigmat\n",
        "    i: Number of times that we have applied this Gaussian Mechanism\n",
        "    orders: As of today, I don't have any idea of what this is \n",
        "    This returns the RDP Privacy of the set of operations.\n",
        "  Then based on the list of RDP, the orders, and a target epsilon we get the delta_spent\n",
        "  '''\n",
        "  def server_exec(self,mt):    \n",
        "    i=1\n",
        "    while(True):\n",
        "      clear_output()\n",
        "      print('Comunication round: ', i)\n",
        "      self.eval_acc()         \n",
        "      rdp = compute_rdp(float(mt/len(self.clients)), self.sigmat, i, self.orders)\n",
        "      _,delta_spent, opt_order = get_privacy_spent(self.orders, rdp, target_eps=self.epsilon)\n",
        "      print('Delta spent: ', delta_spent)\n",
        "      print('Delta budget: ', self.p_budget)    \n",
        "      if self.p_budget < delta_spent:\n",
        "        break\n",
        "      Zt = np.random.choice(self.clients, mt)      \n",
        "      deltas = []\n",
        "      norms = []\n",
        "      for client in Zt:\n",
        "        #print(client.number)\n",
        "        deltaW, normW = client.update(self.model.state_dict())        \n",
        "        deltas.append(deltaW)\n",
        "        norms.append(normW)\n",
        "      #print('all updates')      \n",
        "      self.model.to('cpu')\n",
        "      new_state_dict = self.sanitaze(mt, deltas, norms, self.sigmat, self.model.state_dict())\n",
        "      #print('sanitaze')\n",
        "      self.model.load_state_dict(new_state_dict)\n",
        "      i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kPlsvs1rRYK",
        "colab_type": "text"
      },
      "source": [
        "# The model class\n",
        "\n",
        "This is the class where we define the model of our setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSQutMrUN-nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class t_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(t_model, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 200)\n",
        "        self.fc2 = nn.Linear(200, 50)\n",
        "        self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))        \n",
        "        x = F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTThdy0R0pN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #Return the samples that each client is going to have as a private training data set. This is a not overlapping set\n",
        "  def get_samples(num_clients):\n",
        "    tam = len(mnist_trainset)\n",
        "    split= int(tam/num_clients)\n",
        "    split_ini = split\n",
        "    indices = list(range(tam))\n",
        "    init=0\n",
        "    samples = []\n",
        "    for i in range(num_clients):     \n",
        "      t_idx = indices[init:split]\n",
        "      t_sampler = SubsetRandomSampler(t_idx)\n",
        "      samples.append(t_sampler)\n",
        "      init = split\n",
        "      split = split+split_ini\n",
        "    return samples "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHYrDQEjOH8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, ), (0.5,))])\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "device =  torch.device(\"cuda:0\"\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_clients = 100\n",
        "train_len = len(mnist_trainset)\n",
        "test_len = len(mnist_testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QLFKtmazQCZ",
        "colab_type": "code",
        "outputId": "8fba9625-1d6a-45bf-cba9-846aa79a7870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#We're creating the Server class. A priv_budget of 0.001 (the max delta) and a Epsilon of 8\n",
        "serv = server(num_clients, 0.001, 8)\n",
        "serv.server_exec(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comunication round:  24\n",
            "Accuracy:  0.8672\n",
            "Delta spent:  0.001221426302927119\n",
            "Delta budget:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0g1fCrtOqOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}