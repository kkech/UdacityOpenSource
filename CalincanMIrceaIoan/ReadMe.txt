Creating an visual processing application with deep learning Cosmetic Failure Detector Model for identifing the cosmetic failures of a product
Due to lack of know how of evaluation or Human error , for cosmetic failure there is an risk to send to customer nonconformities.
Pain Points:
1. Imprecision - The human eye is not capable of making precise measurements, especially on a very small scale. Even when comparing two similar objects, the eye might not notice that one is slightly smaller or larger than the other. This concept also applies to characteristics such as surface roughness, size, and any other factor that needs to be measured. 
2. High risk for escape, according to PFMEA Visual, tactile or audible inspection is rated with 7-8 were rating 10 means no Controls. 
3. Availability of high qualified personnel -> by using Deep learning models one can use new personal for detecting or sorting
Now days machine learning algorithms makes error almost less than 1%. And in the complex process of surgery or medical research, humans definitely makes more than 1 percent error. The error even rises to 5 percent sometimes. This is due to the fact that a machine works in a certain Algorithm but human only sees through their eyes and tries to perceive the problem.


For most of the past 30 years, computer vision technologies have struggled to help humans with visual tasks, even those as mundane as accurately recognizing faces in photographs. Recently, though, breakthroughs in deep learning, an emerging field of artificial intelligence, have finally enabled computers to interpret many kinds of images as successfully as, or better than, people do. Companies are already selling products that exploit the technology, which is likely to take over or assist in a wide range of tasks that people now perform, from driving trucks to reading scans for diagnosing medical disorders


Recent progress in a deep-learning approach known as a convolutional neural network (CNN) is key to the latest strides. To give a simple example of its prowess, consider images of animals. Whereas humans can easily distinguish between a cat and a dog, CNNs allow machines to categorize specific breeds more successfully than people can. It excels because it is better able to learn, and draw inferences from, subtle, telling patterns in the images.


Computer-vision systems powered by deep learning are being developed for a range of applications. The technology is making self-driving cars safer by enhancing the ability to recognize pedestrians. Insurers are starting to apply deep-learning tools to assess damage to cars. In the security camera industry, CNNs are making it possible to understanding crowd behavior, which will make public places and airports safer. In agriculture, deep-learning monitor water levels and help detect crop diseases before they spread.
Convolutional neural networks do not need to be programmed to recognize specific features in images—for example, the shape and size of an animal’s ears. Instead they learn to spot features such as these on their own, through training. To train a CNN to separate an English springer spaniel from a Welsh one, for instance, you start with thousands of images of animals, including examples of either breed. Like most deep-learning networks, CNNs are organized in layers. In the lower layers, they learn simple shapes and edges from the images. In the higher layers, they learn complex and abstract concepts—in this case, features of ears, tails, tongues, fur textures, and so on. Once trained, a CNN can easily decide whether a new image of an animal shows a breed of interest. Bringing this algorithm into the examination process follows a trend in computing that combines visual processing with deep learning, a type of artificial intelligence modeled after neural networks in the brain. Deep learning has a decades-long history in computer science but it only recently has been
applied to visual processing tasks, with great success. The essence of machine learning, i including  deep learning, is that a computer is trained to figure out a problem rather than having the answers programmed into it.(https://news.stanford.edu/2017/01/25/artificial-intelligence-used-identify-skin-cancer/)
Think if a physician only has few experience in diagnosis for example, a trained NN might outperform the physician, especially if the features in the images are very small.
High Scalability, the solution can be easily translated from one plant to another, from automotive industry to another industry, etc. 
Computer-vision systems powered by deep learning are being developed for a range of applications. The technology is making self-driving cars safer by enhancing the ability to recognize pedestrians. Insurers are starting to apply deep-learning tools to assess damage to cars. In the security camera industry, CNNs are making it possible to understanding crowd behavior, which will make public places and airports safer. In agriculture, deep-learning applications can be used to predict crop yields, monitor water levels and help detect crop diseases before they spread.