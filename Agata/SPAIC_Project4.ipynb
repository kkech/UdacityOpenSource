{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPAIC_Project4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agatagruza/private-ai/blob/master/SPAIC_Project4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqk3AMzdcWUW",
        "colab_type": "text"
      },
      "source": [
        "#Project 4: Local Differential Privacy\n",
        "\n",
        "Create a function that flips a virtual coin twice and randomizes data points based on the result. Call this function with incemental databases. More info about algorithm can be foud in chapter 2.3 â€œFormalizing differential privacy\"\" of Synthia Dwork book [The Algorithmic Foundations of Differential Privacy](https://github.com/AceEviliano/Reading-Facebook-Secure-and-Private-AI-Scholarship/blob/master/privacybook.pdf)\n",
        "\n",
        "###GLOSSARY:\n",
        "**Local Differential Privacy** adds noise to function data points (function inputs). Think of it as a adding noise directly to database or having individuals add noise to their own data before even putting it into database. In this settings users are **MOST protected** as they do not need to trust database owner to use their data responsibly.  <br/><br/>\n",
        "**Global Differential Privacy** adds noise to function outputs, which adds noise to the output of the query on the database. That means database itself contains all of the private information. It's only the interface to the data which adds the noise necessary to ptrotect each individual's privacy.   <br/><br/>\n",
        "__***Main difference between Local and Global DP***__: if the database operator is trustworthy, the only difference is that the global differential privacy leads to **more accurate results** with the same level of privacy protection. But this requires database owner to be trustworthy.  Namely, the database owner should **add noise properly**. <br/><br/>\n",
        "**Trusted Curator** is an owner of a database upon which Global Differential privacy is applied. They are trusted to apply DP correctly.  <br/><br/>\n",
        "Basic **sum query** is not differntially private. <br/><br/>\n",
        "Differential Privacy **ALWAYS requires** a form of randomness or noise added to the query to prottect from things like Differencing Attacks. <br/><br/> \n",
        "**Randomized Response** is a technique where a certain degree of randomness can be added to the process that each individual is protected with **\"plausible deniability\" (flipping coin)**. Randomized Response is used in social sciences when trying to learn about the high level trends for a taboo behavior. Flipping a coin is an example of Local Differential Privacy. However **adding privacy comes at the cost of accuracy**, especially if sapmling over **a small number of people**.\n",
        "<br/><br/> \n",
        "**GOALS of Differential Privacy:**\n",
        "- Get the most accurate query results with the greatest amount of privacy, a.k.a. minimize the amount of noise that is added, and maximize the amount of privacy.\n",
        "- Greatest fit with trust models in the actual world (don't waste trust). It looks at who trust or doesn't trust each other in a real world situation to minimize a noise accuracy tradeoff. One of the trategies there is to create create **flexible differential privacy strategies**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKCR1QPQtoWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing torch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZROkETtZSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# actual values from 150 people\n",
        "db = torch.rand(150) > 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_iXOOs9umKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fa16658e-d645-43b4-a32b-d9b491065d8d"
      },
      "source": [
        "db"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "        1, 1, 1, 1, 0, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxiD9lRNunqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean of db with 100 people\n",
        "true_result = torch.mean(db.float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gApQU6EC63_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b077e5b-622a-408e-8197-6315c700c348"
      },
      "source": [
        "true_result"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4933)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-39UISL6-9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query_with_and_without_noise(db):\n",
        "  \n",
        "  #Since we generated our db randomnly, with 50% of being 1 or 0, the mean tends to be around 0.5\n",
        "  #query result over original database created\n",
        "  true_data = torch.mean(db.float())\n",
        "  \n",
        "  # flipping two coins 100 times\n",
        "  first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "  second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "  \n",
        "  # will return 1 only for the places in the database where there actually was a 1 originally \n",
        "  # db.float() * first_coin_flip\n",
        "  \n",
        "  # augmented_database is differentially private !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  augmented_database = db.float() * first_coin_flip + (1-first_coin_flip) * second_coin_flip\n",
        "  # # (1-first_coin_flip) are all the places we want to choose randomly\n",
        "  # torch.mean(augmented_database.float())  skewd results\n",
        "  \n",
        "  # deskew results = TRUE OUTPUT OF THE DATABASE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  with_noise_result = torch.mean(augmented_database.float()) *2 - 0.5\n",
        "  \n",
        "  return true_data, with_noise_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkR46UsJ9Z_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9308e4c-c08b-4596-f727-d0f4154c0c50"
      },
      "source": [
        "# db size 10\n",
        "db = torch.rand(10) > 0.5\n",
        "with_noise_result, true_data = query_with_and_without_noise(db)\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "print(\"With Noise:\" + str(with_noise_result))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise:tensor(0.5000)\n",
            "With Noise:tensor(0.7000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7J2Ac0c-4b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f862452-7efc-4811-d27c-2f9462b98edf"
      },
      "source": [
        "# db size 100\n",
        "db = torch.rand(100) > 0.5\n",
        "with_noise_result, true_data = query_with_and_without_noise(db)\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "print(\"With Noise:\" + str(with_noise_result))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise:tensor(0.4800)\n",
            "With Noise:tensor(0.4400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZJjyXMwqne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "826bbd7a-1aca-4e94-cf31-a3d93377e186"
      },
      "source": [
        "# db size 1000\n",
        "db = torch.rand(1000) > 0.5\n",
        "with_noise_result, true_data = query_with_and_without_noise(db)\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "print(\"With Noise:\" + str(with_noise_result))\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise:tensor(0.4680)\n",
            "With Noise:tensor(0.5060)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKerLNTM-wMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "377b888d-fcd3-4de5-9a86-8d84eaa2545f"
      },
      "source": [
        "# db size 10000\n",
        "db = torch.rand(10000) > 0.5\n",
        "with_noise_result, true_data = query_with_and_without_noise(db)\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "print(\"With Noise:\" + str(with_noise_result))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise:tensor(0.5110)\n",
            "With Noise:tensor(0.5073)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShdrqQ9--wOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}