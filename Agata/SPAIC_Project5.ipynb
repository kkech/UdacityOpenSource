{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPAIC_Project5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agatagruza/private-ai/blob/master/SPAIC_Project5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fipbhCPoT_-H",
        "colab_type": "text"
      },
      "source": [
        "# Project 5: Varying Amounts of Noise\n",
        "Augment the randomized response query from the previous project to allow for varying amounts of randomness to be added. Vary the amount of noise by\n",
        "- Adding a new parameter to the query function. It will now accept the database and some noise parameter which is a percentage. The first coin flip will have varying probabilities of being 1 or 0. Experiment with different values of noise\n",
        "- Properly rebalance the result of the query given this adjustable parameter <br></br>\n",
        "\n",
        "###GLOSSARY:\n",
        "- The size of the data set allows you to add more noise, or more privacy protection to the individuals who are inside the dataset. This is an interesting **trade-off**.\n",
        "- The **counter-intuitive** thing here is that the more private data you have access to, the easier is to protect the privacy of the people who were involved. \n",
        "- The larger dataset is, the more noise you can add while still getting an accurate result.   \n",
        "- With differential privacy (DP),  the opposite is true as DP wants to learn about an aggregation over a large corpus. DP looks for info that is **consistent** across **multiple different individuals**, without learning about single individual person. It looks for repeating statistical information inside the dataset and **filter out any information that is unique to undividual.**. The smaller the dataset, the more it will look like data are unique to each individual.  <br></br>\n",
        "\n",
        "###TAKEAWAYS\n",
        "- The larger the corpus of information that you can work with, the easier it is for you to protect provacy because it's easier for your algorithm to detect that some statistical information is happening in more than one person,  and therefore it is not private or unique or sensitive to that person. Because it's a general characteristic of of humans more and more generally. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIGOaA_VT7-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import torch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPvL227Z6d8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e4910f3a-0738-4fc2-bfaf-e17d2391ffff"
      },
      "source": [
        "# building random database of length 100 that is filled with 1's and 0's\n",
        "db = torch.rand(100) > 0.5\n",
        "db"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "        1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
              "        0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL_ol9PxgK8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_parallel_db(db, index):\n",
        "\n",
        "    return torch.cat((db[0:index], \n",
        "                      db[index+1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7imODLGc8Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_parallel_dbs(db):\n",
        "\n",
        "    parallel_dbs = list()\n",
        "\n",
        "    for i in range(len(db)):\n",
        "        pdb = create_parallel_db(db, i)\n",
        "        parallel_dbs.append(pdb)\n",
        "    \n",
        "    return parallel_dbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T9D1sifhkwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdbs = create_parallel_dbs(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUyrcn92hGzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_db_and_parallels(num_els):\n",
        "    \n",
        "    db = torch.rand(num_els) > 0.5\n",
        "    pdbs = create_parallel_dbs(db)\n",
        "    \n",
        "    return db, pdbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzQ9dYP3aGF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db, noise=0.2):  \n",
        "\n",
        "  # 0.2% probabilty of coin flip will ne a head\n",
        "\n",
        "  true_data = torch.mean(db.float())\n",
        "\n",
        "  # flipping two coins 100 times\n",
        "  first_coin_flip = (torch.rand(len(db)) > noise).float()\n",
        "  second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "\n",
        "  # will return 1 only for the places in the database where there actually was a 1 originally \n",
        "  # db.float() * first_coin_flip\n",
        "\n",
        "  # augmented_database is differentially private !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  augmented_database = db.float() * first_coin_flip + (1-first_coin_flip) * second_coin_flip\n",
        "  # augmented_database_mean = (true_dist_mean * noise) + (noise_dist_mean * (1 - noise))\n",
        "  # # (1-first_coin_flip) are all the places we want to choose randomly\n",
        "  # torch.mean(augmented_database.float())  skewd results\n",
        "\n",
        "  sk_result = augmented_database.float().mean()\n",
        "\n",
        "  # 0.5 comes fromsecond_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "  db_result = ((sk_result / noise) - 0.5) * noise / (1 - noise) \n",
        "\n",
        "  return true_data, db_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApyqnJecoB18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31uNL0pyf874",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94a37628-91c7-4347-cd6c-b7456739286d"
      },
      "source": [
        "# db size=100, noise=0.1 \n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "db_result, true_data = query(db, noise=0.1)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.4200)\n",
            "Without Noise:tensor(0.4444)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CN7-k0ziap3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "25907aa7-ded7-4836-ea2f-744628a05fd5"
      },
      "source": [
        "# db size=100, noise=0.2\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "db_result, true_data = query(db, noise=0.2)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.5600)\n",
            "Without Noise:tensor(0.5500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dA-aVxjidLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98c4af9d-8aa5-4037-9a14-3241c47e55bc"
      },
      "source": [
        "# db size=100, noise=0.4\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "db_result, true_data = query(db, noise=0.4)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.4800)\n",
            "Without Noise:tensor(0.5167)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEM3K6s1iftW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9d4d8ec-dfad-409a-bea2-b8db9a978dc6"
      },
      "source": [
        "# db size=100, noise=0.8\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "db_result, true_data = query(db, noise=0.8)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.4900)\n",
            "Without Noise:tensor(0.3000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y55qC4OHinu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acb635ab-b342-4500-eff2-8101a17566de"
      },
      "source": [
        "# LARGE DATA SET !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# db size=10000, noise=0.1\n",
        "db, pdbs = create_db_and_parallels(10000)\n",
        "db_result, true_data = query(db, noise=0.1)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "# With big data set results are closeto each other. "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.5007)\n",
            "Without Noise:tensor(0.5042)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_PLOxh2iwbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f350a332-85ce-4e82-b874-ca0176cafb54"
      },
      "source": [
        "# LARGE DATA SET !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# db size=10000, noise=0.2\n",
        "db, pdbs = create_db_and_parallels(10000)\n",
        "db_result, true_data = query(db, noise=0.2)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "# With big data set results are closeto each other. "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.4908)\n",
            "Without Noise:tensor(0.4888)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y7Sx8p9mb9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03c2517c-f0d5-4e02-e45c-ce20e4dc4df1"
      },
      "source": [
        "# LARGE DATA SET !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# db size=10000, noise=0.4\n",
        "db, pdbs = create_db_and_parallels(10000)\n",
        "db_result, true_data = query(db, noise=0.4)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "# With big data set results are closeto each other. "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.5087)\n",
            "Without Noise:tensor(0.4905)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSITbxGmcAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b2c24d5-4084-453c-950a-4101cf0d0d20"
      },
      "source": [
        "# LARGE DATA SET !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# db size=10000, noise=0.8\n",
        "db, pdbs = create_db_and_parallels(10000)\n",
        "db_result, true_data = query(db, noise=0.8)\n",
        "print(\"With Noise:\" + str(db_result))\n",
        "print(\"Without Noise:\" + str(true_data))\n",
        "# With big data set results are closeto each other. "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise:tensor(0.5060)\n",
            "Without Noise:tensor(0.4815)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BtERATbmcLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}