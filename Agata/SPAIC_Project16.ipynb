{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPAIC_Project16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agatagruza/private-ai/blob/master/SPAIC_Project16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngv4dJGbp69v",
        "colab_type": "text"
      },
      "source": [
        "#Project 16: Encrypted Deep Learning in Keras\n",
        "\n",
        "You will provifr private prediction by:</br>\n",
        "**Step 1**: Train your model with normal Keras.</br>\n",
        "**Step 2**: Secure and serve your machine learning model (server).</br>\n",
        "**Step 3**: Query the secured model to receive private predictions (client). </br>\n",
        "\n",
        "*Demo Ref: https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1IUKXb8scn3",
        "colab_type": "text"
      },
      "source": [
        "##Step1: Train Your Model in Keras\n",
        "For more info about Keras, check [Keras](https://keras.io/) and  [Keras documentation](https://keras.io/)\n",
        "\n",
        "To train a classification  model with normal Keras use the canonical [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Below example is borrowed from the [reference Keras repository](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSIeVBWXp0IE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "40c0241e-f90f-454b-f505-462cdcef2a95"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3, 3), input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0729 02:58:03.774518 139912994658176 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 2.2995 - acc: 0.1456 - val_loss: 2.2985 - val_acc: 0.1639\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 2.2981 - acc: 0.1754 - val_loss: 2.2970 - val_acc: 0.1855\n",
            "Test loss: 2.2970151245117187\n",
            "Test accuracy: 0.1855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDJPA4goqiyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Save your model's weights for future private prediction\n",
        "model.save('short-conv-mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3NCRKrqtqh5",
        "colab_type": "text"
      },
      "source": [
        "##Step 2: Load and Serve the Model\n",
        "To secure and serve this model, we will need three TFEWorkers (servers). This is because TF Encrypted under the hood uses an encryption technique called [multi-party computation (MPC)](https://en.wikipedia.org/wiki/Secure_multi-party_computation). The idea is to split the model weights and input data into shares, then send a share of each value to the different servers. The key property is that if you look at the share on one server, it reveals nothing about the original value (input data or model weights).</br>\n",
        "\n",
        "We'll define a Syft Keras model like we did in the previous notebook. However, there is a trick: before instantiating this model, we'll run hook = sy.KerasHook(tf.keras). This will add three important new methods to the Keras Sequential class: </br>\n",
        "\n",
        "*   ***share:*** will secure your model via secret sharing; by default, it will use the SecureNN protocol from TF Encrypted to secret share your model between each of the three TFEWorkers. Most importantly, this will add the capability of providing predictions on encrypted data.\n",
        "*   ***serve:*** this function will launch a serving queue, so that the TFEWorkers can can accept prediction requests on the secured model from external clients.\n",
        "*   ***shutdown_workers***: once you are done providing private predictions, you can shut down your model by running this function. It will direct you to shutdown the server processes manually if you've opted to manually manage each worker. </br>\n",
        "\n",
        "To earn more about MPC, go to [blog](https://mortendahl.github.io/2017/04/17/private-deep-learning-with-mpc/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw3jiNwOqjU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a6755473-001b-418a-bb6f-d34038a5da4f"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Activation, Flatten, ReLU, Activation\n",
        "\n",
        "import syft as sy\n",
        "hook = sy.KerasHook(tf.keras)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 02:58:39.404854 139912994658176 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0729 02:58:39.506308 139912994658176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edgfLBMu0k2",
        "colab_type": "text"
      },
      "source": [
        "##Model\n",
        "Below model is almost the saem as before, except it includes a batch_input_shape. This allows TF Encrypted to better optimize the secure computations via predefined tensor shapes. For MNIST demo, we'll send input data with the shape of (1, 28, 28, 1). We also return the logit instead of softmax because this operation is complex to perform using MPC, and we don't need it to serve prediction requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5LxbLFOqjXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (1, 28, 28, 1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3, 3), batch_input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, name=\"logit\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0szB8-jYvHxC",
        "colab_type": "text"
      },
      "source": [
        "## Load Pre-trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Ss4WSGqjZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_weights = 'short-conv-mnist.h5'\n",
        "model.load_weights(pre_trained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU5lYxbzvPd1",
        "colab_type": "text"
      },
      "source": [
        "##Step 3: Setup Your Worker Connectors\n",
        "\n",
        "Now we connect to the TFEWorkers (alice, bob, and carol) required by TF Encrypted to perform private predictions. For each TFEWorker, we have to specify a host.\n",
        "\n",
        "These workers run a TensorFlow server, which we can either manage manually (AUTO = False) or ask the workers to manage for you (AUTO = True). If choosing to manually manage them, we will be instructed to execute a terminal command on each worker's host device after calling model.share() below. If all workers are hosted on a single device (e.g. localhost), we can choose to have Syft automatically manage the worker's TensorFlow server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf8vxVqrqjcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = False\n",
        "\n",
        "alice = sy.TFEWorker(host='localhost:4000', auto_managed=AUTO)\n",
        "bob = sy.TFEWorker(host='localhost:4001', auto_managed=AUTO)\n",
        "carol = sy.TFEWorker(host='localhost:4002', auto_managed=AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy6Wzq8bvhNh",
        "colab_type": "text"
      },
      "source": [
        "##Step 4: Split the Model Into Shares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKACghDFqjhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.share(alice, bob, carol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeLLg4xBvsAJ",
        "colab_type": "text"
      },
      "source": [
        "##Step 5: Launch 3 Servers\n",
        "\n",
        "From other terminal we need to launch:</br>\n",
        "***python -m tf_encrypted.player --config /tmp/tfe.config server0</br>\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server1</br>\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server2***</br> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-UUZUvbwCrv",
        "colab_type": "text"
      },
      "source": [
        "##Step 6: Serve the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h9YL5hiqjf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.serve(num_requests=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YjsbGvxwg_7",
        "colab_type": "text"
      },
      "source": [
        "##Step 7: Run the Client"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgWW8mMqwnqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import syft as sy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pErQAq3iwrpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvrKmkwVwrum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (1, 28, 28, 1)\n",
        "output_shape = (1, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHs72zfcwryr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "261317e8-489f-47be-a2fb-b957c8368217"
      },
      "source": [
        "client = sy.TFEWorker()\n",
        "\n",
        "alice = sy.TFEWorker(host='localhost:4000')\n",
        "bob = sy.TFEWorker(host='localhost:4001')\n",
        "carol = sy.TFEWorker(host='localhost:4002')\n",
        "\n",
        "client.connect_to_model(input_shape, output_shape, alice, bob, carol)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 03:26:04.774584 139912994658176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py:403: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0729 03:26:04.785006 139912994658176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/config.py:300: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0729 03:26:04.785733 139912994658176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/config.py:87: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
            "\n",
            "I0729 03:26:04.788068 139912994658176 session.py:55] Starting session on target 'grpc://localhost:4000' using config graph_options {\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_k7J0cwr2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# User inputs\n",
        "num_tests = 3\n",
        "images, expected_labels = x_test[:num_tests], y_test[:num_tests]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NA7oGvIwr7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, expected_label in zip(images, expected_labels):\n",
        "\n",
        "    res = client.query_model(image.reshape(1, 28, 28, 1))\n",
        "    predicted_label = np.argmax(res)\n",
        "\n",
        "    print(\"The image had label {} and was {} classified as {}\".format(\n",
        "        expected_label,\n",
        "        \"correctly\" if expected_label == predicted_label else \"wrongly\",\n",
        "        predicted_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POelL7zfwMyo",
        "colab_type": "text"
      },
      "source": [
        "##Shutdown the Servers\n",
        "\n",
        "Once above request hit the limit above, the model will no longer be available for serving requests. However it's still secret shared between the three workers above. Therefore we should kill the workers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8KsH7Xcq2FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.shutdown_workers()\n",
        "\n",
        "if not AUTO:\n",
        "    process_ids = !ps aux | grep '[p]ython -m tf_encrypted.player --config /tmp/tfe.config' | awk '{print $2}'\n",
        "    for process_id in process_ids:\n",
        "        !kill {process_id}\n",
        "        print(\"Process ID {id} has been killed.\".format(id=process_id))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}