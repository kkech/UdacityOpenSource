{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPAIC_Project12.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agatagruza/private-ai/blob/master/SPAIC_Project12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKMuBqzdmI7V",
        "colab_type": "text"
      },
      "source": [
        "# Project 12: Use Federated Learning on MNIST\n",
        "Your job is to train on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using Federated Learning. However, the gradient shouldn't come up to central server in raw form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlId_Nqnz0wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfary-Znpah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlKvodVxnpcz",
        "colab_type": "code",
        "outputId": "87bcab37-396e-4d6f-80b6-2a431bb96e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "smith = sy.VirtualWorker(hook, id = \"smith\") #virtual worker, holds data\n",
        "sally = sy.VirtualWorker(hook, id = \"sally\") #virtual worker, holds data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 04:09:58.986621 140427676141440 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcVjjkbmnk9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data distribution across VirtualWorker (using federate method)\n",
        "federated_train_loader = sy.FederatedDataLoader( \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((smith, sally)), \n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_puPfhsnlAT",
        "colab_type": "code",
        "outputId": "8474b6f3-12c0-4519-fba6-785fad42d68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_loader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF9QZAqZ6ibv",
        "colab_type": "text"
      },
      "source": [
        "##Building the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP4dv8Wgnpf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training model parameters\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64 # training batch size \n",
        "        self.test_batch_size = 1000 # testing bacth size \n",
        "        self.epochs = 12 # epoch number\n",
        "        self.seed = 1\n",
        "        self.lr = 0.02  # learning rate\n",
        "        self.momentum = 0.5 \n",
        "        self.no_cuda = False  \n",
        "        self.save_model = False\n",
        "        self.log_interval = 12\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "torch.manual_seed(args.seed) # random number generator\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # switching between CPU and cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVcTRvqbnlCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_default_tensor_type(torch.cuda.FloatTensor) \n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "     \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Ys861D6vA3",
        "colab_type": "text"
      },
      "source": [
        "##Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stqhIlK9nlEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader):\n",
        "        model.send(data.location)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "      \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() \n",
        " \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() \n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, \n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSpHH-V16zWg",
        "colab_type": "text"
      },
      "source": [
        "##Test the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C-45dd4nlHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(1, keepdim=True) \n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AUTjaSznlJS",
        "colab_type": "code",
        "outputId": "101199d9-f736-4c44-cdff-68c003fb204d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Classifier().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) \n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.324064\n",
            "Train Epoch: 1 [768/60032 (1%)]\tLoss: 2.238193\n",
            "Train Epoch: 1 [1536/60032 (3%)]\tLoss: 2.162025\n",
            "Train Epoch: 1 [2304/60032 (4%)]\tLoss: 2.024521\n",
            "Train Epoch: 1 [3072/60032 (5%)]\tLoss: 1.656873\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.286806\n",
            "Train Epoch: 1 [4608/60032 (8%)]\tLoss: 0.874594\n",
            "Train Epoch: 1 [5376/60032 (9%)]\tLoss: 0.881216\n",
            "Train Epoch: 1 [6144/60032 (10%)]\tLoss: 0.516702\n",
            "Train Epoch: 1 [6912/60032 (12%)]\tLoss: 0.499306\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.495695\n",
            "Train Epoch: 1 [8448/60032 (14%)]\tLoss: 0.445575\n",
            "Train Epoch: 1 [9216/60032 (15%)]\tLoss: 0.339261\n",
            "Train Epoch: 1 [9984/60032 (17%)]\tLoss: 0.445339\n",
            "Train Epoch: 1 [10752/60032 (18%)]\tLoss: 0.489623\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.216479\n",
            "Train Epoch: 1 [12288/60032 (20%)]\tLoss: 0.275770\n",
            "Train Epoch: 1 [13056/60032 (22%)]\tLoss: 0.178101\n",
            "Train Epoch: 1 [13824/60032 (23%)]\tLoss: 0.223266\n",
            "Train Epoch: 1 [14592/60032 (24%)]\tLoss: 0.270243\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.374371\n",
            "Train Epoch: 1 [16128/60032 (27%)]\tLoss: 0.249413\n",
            "Train Epoch: 1 [16896/60032 (28%)]\tLoss: 0.265167\n",
            "Train Epoch: 1 [17664/60032 (29%)]\tLoss: 0.227927\n",
            "Train Epoch: 1 [18432/60032 (31%)]\tLoss: 0.125927\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.543316\n",
            "Train Epoch: 1 [19968/60032 (33%)]\tLoss: 0.186094\n",
            "Train Epoch: 1 [20736/60032 (35%)]\tLoss: 0.230211\n",
            "Train Epoch: 1 [21504/60032 (36%)]\tLoss: 0.154370\n",
            "Train Epoch: 1 [22272/60032 (37%)]\tLoss: 0.215078\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.144797\n",
            "Train Epoch: 1 [23808/60032 (40%)]\tLoss: 0.195161\n",
            "Train Epoch: 1 [24576/60032 (41%)]\tLoss: 0.155859\n",
            "Train Epoch: 1 [25344/60032 (42%)]\tLoss: 0.155337\n",
            "Train Epoch: 1 [26112/60032 (43%)]\tLoss: 0.188809\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.270455\n",
            "Train Epoch: 1 [27648/60032 (46%)]\tLoss: 0.172311\n",
            "Train Epoch: 1 [28416/60032 (47%)]\tLoss: 0.149129\n",
            "Train Epoch: 1 [29184/60032 (49%)]\tLoss: 0.134241\n",
            "Train Epoch: 1 [29952/60032 (50%)]\tLoss: 0.208979\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.226183\n",
            "Train Epoch: 1 [31488/60032 (52%)]\tLoss: 0.112413\n",
            "Train Epoch: 1 [32256/60032 (54%)]\tLoss: 0.135189\n",
            "Train Epoch: 1 [33024/60032 (55%)]\tLoss: 0.142496\n",
            "Train Epoch: 1 [33792/60032 (56%)]\tLoss: 0.174923\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.095662\n",
            "Train Epoch: 1 [35328/60032 (59%)]\tLoss: 0.149142\n",
            "Train Epoch: 1 [36096/60032 (60%)]\tLoss: 0.200153\n",
            "Train Epoch: 1 [36864/60032 (61%)]\tLoss: 0.101157\n",
            "Train Epoch: 1 [37632/60032 (63%)]\tLoss: 0.247972\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.150776\n",
            "Train Epoch: 1 [39168/60032 (65%)]\tLoss: 0.137573\n",
            "Train Epoch: 1 [39936/60032 (67%)]\tLoss: 0.125723\n",
            "Train Epoch: 1 [40704/60032 (68%)]\tLoss: 0.036381\n",
            "Train Epoch: 1 [41472/60032 (69%)]\tLoss: 0.239792\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.108809\n",
            "Train Epoch: 1 [43008/60032 (72%)]\tLoss: 0.090098\n",
            "Train Epoch: 1 [43776/60032 (73%)]\tLoss: 0.114981\n",
            "Train Epoch: 1 [44544/60032 (74%)]\tLoss: 0.148459\n",
            "Train Epoch: 1 [45312/60032 (75%)]\tLoss: 0.159316\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.088549\n",
            "Train Epoch: 1 [46848/60032 (78%)]\tLoss: 0.074047\n",
            "Train Epoch: 1 [47616/60032 (79%)]\tLoss: 0.179900\n",
            "Train Epoch: 1 [48384/60032 (81%)]\tLoss: 0.088890\n",
            "Train Epoch: 1 [49152/60032 (82%)]\tLoss: 0.117458\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.048281\n",
            "Train Epoch: 1 [50688/60032 (84%)]\tLoss: 0.266371\n",
            "Train Epoch: 1 [51456/60032 (86%)]\tLoss: 0.130391\n",
            "Train Epoch: 1 [52224/60032 (87%)]\tLoss: 0.237186\n",
            "Train Epoch: 1 [52992/60032 (88%)]\tLoss: 0.061327\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.175746\n",
            "Train Epoch: 1 [54528/60032 (91%)]\tLoss: 0.134553\n",
            "Train Epoch: 1 [55296/60032 (92%)]\tLoss: 0.088439\n",
            "Train Epoch: 1 [56064/60032 (93%)]\tLoss: 0.084108\n",
            "Train Epoch: 1 [56832/60032 (95%)]\tLoss: 0.124535\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.071406\n",
            "Train Epoch: 1 [58368/60032 (97%)]\tLoss: 0.083037\n",
            "Train Epoch: 1 [59136/60032 (99%)]\tLoss: 0.041362\n",
            "Train Epoch: 1 [59904/60032 (100%)]\tLoss: 0.149318\n",
            "\n",
            "Test set: Average loss: 0.1028, Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.064428\n",
            "Train Epoch: 2 [768/60032 (1%)]\tLoss: 0.017767\n",
            "Train Epoch: 2 [1536/60032 (3%)]\tLoss: 0.037942\n",
            "Train Epoch: 2 [2304/60032 (4%)]\tLoss: 0.191788\n",
            "Train Epoch: 2 [3072/60032 (5%)]\tLoss: 0.094358\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.025854\n",
            "Train Epoch: 2 [4608/60032 (8%)]\tLoss: 0.176246\n",
            "Train Epoch: 2 [5376/60032 (9%)]\tLoss: 0.079877\n",
            "Train Epoch: 2 [6144/60032 (10%)]\tLoss: 0.130352\n",
            "Train Epoch: 2 [6912/60032 (12%)]\tLoss: 0.043468\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.085683\n",
            "Train Epoch: 2 [8448/60032 (14%)]\tLoss: 0.293265\n",
            "Train Epoch: 2 [9216/60032 (15%)]\tLoss: 0.183385\n",
            "Train Epoch: 2 [9984/60032 (17%)]\tLoss: 0.129246\n",
            "Train Epoch: 2 [10752/60032 (18%)]\tLoss: 0.069319\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.083568\n",
            "Train Epoch: 2 [12288/60032 (20%)]\tLoss: 0.160791\n",
            "Train Epoch: 2 [13056/60032 (22%)]\tLoss: 0.069334\n",
            "Train Epoch: 2 [13824/60032 (23%)]\tLoss: 0.049925\n",
            "Train Epoch: 2 [14592/60032 (24%)]\tLoss: 0.095012\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.069093\n",
            "Train Epoch: 2 [16128/60032 (27%)]\tLoss: 0.157301\n",
            "Train Epoch: 2 [16896/60032 (28%)]\tLoss: 0.036450\n",
            "Train Epoch: 2 [17664/60032 (29%)]\tLoss: 0.113232\n",
            "Train Epoch: 2 [18432/60032 (31%)]\tLoss: 0.078702\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.175483\n",
            "Train Epoch: 2 [19968/60032 (33%)]\tLoss: 0.026692\n",
            "Train Epoch: 2 [20736/60032 (35%)]\tLoss: 0.150974\n",
            "Train Epoch: 2 [21504/60032 (36%)]\tLoss: 0.021863\n",
            "Train Epoch: 2 [22272/60032 (37%)]\tLoss: 0.078521\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.063904\n",
            "Train Epoch: 2 [23808/60032 (40%)]\tLoss: 0.154823\n",
            "Train Epoch: 2 [24576/60032 (41%)]\tLoss: 0.073148\n",
            "Train Epoch: 2 [25344/60032 (42%)]\tLoss: 0.150097\n",
            "Train Epoch: 2 [26112/60032 (43%)]\tLoss: 0.033558\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.175614\n",
            "Train Epoch: 2 [27648/60032 (46%)]\tLoss: 0.126167\n",
            "Train Epoch: 2 [28416/60032 (47%)]\tLoss: 0.028380\n",
            "Train Epoch: 2 [29184/60032 (49%)]\tLoss: 0.061503\n",
            "Train Epoch: 2 [29952/60032 (50%)]\tLoss: 0.052545\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.089551\n",
            "Train Epoch: 2 [31488/60032 (52%)]\tLoss: 0.050168\n",
            "Train Epoch: 2 [32256/60032 (54%)]\tLoss: 0.103619\n",
            "Train Epoch: 2 [33024/60032 (55%)]\tLoss: 0.127987\n",
            "Train Epoch: 2 [33792/60032 (56%)]\tLoss: 0.040545\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.057719\n",
            "Train Epoch: 2 [35328/60032 (59%)]\tLoss: 0.058627\n",
            "Train Epoch: 2 [36096/60032 (60%)]\tLoss: 0.194922\n",
            "Train Epoch: 2 [36864/60032 (61%)]\tLoss: 0.073248\n",
            "Train Epoch: 2 [37632/60032 (63%)]\tLoss: 0.159740\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.024031\n",
            "Train Epoch: 2 [39168/60032 (65%)]\tLoss: 0.063815\n",
            "Train Epoch: 2 [39936/60032 (67%)]\tLoss: 0.027320\n",
            "Train Epoch: 2 [40704/60032 (68%)]\tLoss: 0.088808\n",
            "Train Epoch: 2 [41472/60032 (69%)]\tLoss: 0.163184\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.129736\n",
            "Train Epoch: 2 [43008/60032 (72%)]\tLoss: 0.071351\n",
            "Train Epoch: 2 [43776/60032 (73%)]\tLoss: 0.057513\n",
            "Train Epoch: 2 [44544/60032 (74%)]\tLoss: 0.032204\n",
            "Train Epoch: 2 [45312/60032 (75%)]\tLoss: 0.033505\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.064772\n",
            "Train Epoch: 2 [46848/60032 (78%)]\tLoss: 0.252463\n",
            "Train Epoch: 2 [47616/60032 (79%)]\tLoss: 0.057590\n",
            "Train Epoch: 2 [48384/60032 (81%)]\tLoss: 0.023403\n",
            "Train Epoch: 2 [49152/60032 (82%)]\tLoss: 0.048915\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.019586\n",
            "Train Epoch: 2 [50688/60032 (84%)]\tLoss: 0.112059\n",
            "Train Epoch: 2 [51456/60032 (86%)]\tLoss: 0.065968\n",
            "Train Epoch: 2 [52224/60032 (87%)]\tLoss: 0.065960\n",
            "Train Epoch: 2 [52992/60032 (88%)]\tLoss: 0.180108\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.037905\n",
            "Train Epoch: 2 [54528/60032 (91%)]\tLoss: 0.004354\n",
            "Train Epoch: 2 [55296/60032 (92%)]\tLoss: 0.036940\n",
            "Train Epoch: 2 [56064/60032 (93%)]\tLoss: 0.012852\n",
            "Train Epoch: 2 [56832/60032 (95%)]\tLoss: 0.131515\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.017619\n",
            "Train Epoch: 2 [58368/60032 (97%)]\tLoss: 0.115619\n",
            "Train Epoch: 2 [59136/60032 (99%)]\tLoss: 0.039110\n",
            "Train Epoch: 2 [59904/60032 (100%)]\tLoss: 0.035642\n",
            "\n",
            "Test set: Average loss: 0.0562, Accuracy: 9842/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.032060\n",
            "Train Epoch: 3 [768/60032 (1%)]\tLoss: 0.061562\n",
            "Train Epoch: 3 [1536/60032 (3%)]\tLoss: 0.065178\n",
            "Train Epoch: 3 [2304/60032 (4%)]\tLoss: 0.032063\n",
            "Train Epoch: 3 [3072/60032 (5%)]\tLoss: 0.022458\n",
            "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.024883\n",
            "Train Epoch: 3 [4608/60032 (8%)]\tLoss: 0.021486\n",
            "Train Epoch: 3 [5376/60032 (9%)]\tLoss: 0.035532\n",
            "Train Epoch: 3 [6144/60032 (10%)]\tLoss: 0.049877\n",
            "Train Epoch: 3 [6912/60032 (12%)]\tLoss: 0.079487\n",
            "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.048899\n",
            "Train Epoch: 3 [8448/60032 (14%)]\tLoss: 0.076181\n",
            "Train Epoch: 3 [9216/60032 (15%)]\tLoss: 0.023460\n",
            "Train Epoch: 3 [9984/60032 (17%)]\tLoss: 0.058180\n",
            "Train Epoch: 3 [10752/60032 (18%)]\tLoss: 0.138088\n",
            "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.047184\n",
            "Train Epoch: 3 [12288/60032 (20%)]\tLoss: 0.145545\n",
            "Train Epoch: 3 [13056/60032 (22%)]\tLoss: 0.054708\n",
            "Train Epoch: 3 [13824/60032 (23%)]\tLoss: 0.046302\n",
            "Train Epoch: 3 [14592/60032 (24%)]\tLoss: 0.154358\n",
            "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.054178\n",
            "Train Epoch: 3 [16128/60032 (27%)]\tLoss: 0.034999\n",
            "Train Epoch: 3 [16896/60032 (28%)]\tLoss: 0.114127\n",
            "Train Epoch: 3 [17664/60032 (29%)]\tLoss: 0.034533\n",
            "Train Epoch: 3 [18432/60032 (31%)]\tLoss: 0.012922\n",
            "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.045240\n",
            "Train Epoch: 3 [19968/60032 (33%)]\tLoss: 0.070259\n",
            "Train Epoch: 3 [20736/60032 (35%)]\tLoss: 0.031188\n",
            "Train Epoch: 3 [21504/60032 (36%)]\tLoss: 0.050311\n",
            "Train Epoch: 3 [22272/60032 (37%)]\tLoss: 0.015431\n",
            "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.063840\n",
            "Train Epoch: 3 [23808/60032 (40%)]\tLoss: 0.045502\n",
            "Train Epoch: 3 [24576/60032 (41%)]\tLoss: 0.045868\n",
            "Train Epoch: 3 [25344/60032 (42%)]\tLoss: 0.055844\n",
            "Train Epoch: 3 [26112/60032 (43%)]\tLoss: 0.014425\n",
            "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.078518\n",
            "Train Epoch: 3 [27648/60032 (46%)]\tLoss: 0.034487\n",
            "Train Epoch: 3 [28416/60032 (47%)]\tLoss: 0.044406\n",
            "Train Epoch: 3 [29184/60032 (49%)]\tLoss: 0.034320\n",
            "Train Epoch: 3 [29952/60032 (50%)]\tLoss: 0.181599\n",
            "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.090594\n",
            "Train Epoch: 3 [31488/60032 (52%)]\tLoss: 0.066509\n",
            "Train Epoch: 3 [32256/60032 (54%)]\tLoss: 0.024328\n",
            "Train Epoch: 3 [33024/60032 (55%)]\tLoss: 0.048220\n",
            "Train Epoch: 3 [33792/60032 (56%)]\tLoss: 0.073962\n",
            "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.023248\n",
            "Train Epoch: 3 [35328/60032 (59%)]\tLoss: 0.082879\n",
            "Train Epoch: 3 [36096/60032 (60%)]\tLoss: 0.041596\n",
            "Train Epoch: 3 [36864/60032 (61%)]\tLoss: 0.272157\n",
            "Train Epoch: 3 [37632/60032 (63%)]\tLoss: 0.050026\n",
            "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.019876\n",
            "Train Epoch: 3 [39168/60032 (65%)]\tLoss: 0.097302\n",
            "Train Epoch: 3 [39936/60032 (67%)]\tLoss: 0.050407\n",
            "Train Epoch: 3 [40704/60032 (68%)]\tLoss: 0.018205\n",
            "Train Epoch: 3 [41472/60032 (69%)]\tLoss: 0.060603\n",
            "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.032054\n",
            "Train Epoch: 3 [43008/60032 (72%)]\tLoss: 0.087978\n",
            "Train Epoch: 3 [43776/60032 (73%)]\tLoss: 0.053277\n",
            "Train Epoch: 3 [44544/60032 (74%)]\tLoss: 0.054280\n",
            "Train Epoch: 3 [45312/60032 (75%)]\tLoss: 0.021979\n",
            "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.055941\n",
            "Train Epoch: 3 [46848/60032 (78%)]\tLoss: 0.015915\n",
            "Train Epoch: 3 [47616/60032 (79%)]\tLoss: 0.051692\n",
            "Train Epoch: 3 [48384/60032 (81%)]\tLoss: 0.086691\n",
            "Train Epoch: 3 [49152/60032 (82%)]\tLoss: 0.022767\n",
            "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.143474\n",
            "Train Epoch: 3 [50688/60032 (84%)]\tLoss: 0.035228\n",
            "Train Epoch: 3 [51456/60032 (86%)]\tLoss: 0.050555\n",
            "Train Epoch: 3 [52224/60032 (87%)]\tLoss: 0.053405\n",
            "Train Epoch: 3 [52992/60032 (88%)]\tLoss: 0.081618\n",
            "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.023677\n",
            "Train Epoch: 3 [54528/60032 (91%)]\tLoss: 0.041711\n",
            "Train Epoch: 3 [55296/60032 (92%)]\tLoss: 0.034352\n",
            "Train Epoch: 3 [56064/60032 (93%)]\tLoss: 0.039098\n",
            "Train Epoch: 3 [56832/60032 (95%)]\tLoss: 0.084130\n",
            "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.012958\n",
            "Train Epoch: 3 [58368/60032 (97%)]\tLoss: 0.060438\n",
            "Train Epoch: 3 [59136/60032 (99%)]\tLoss: 0.069933\n",
            "Train Epoch: 3 [59904/60032 (100%)]\tLoss: 0.153655\n",
            "\n",
            "Test set: Average loss: 0.0448, Accuracy: 9856/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.123895\n",
            "Train Epoch: 4 [768/60032 (1%)]\tLoss: 0.013161\n",
            "Train Epoch: 4 [1536/60032 (3%)]\tLoss: 0.025309\n",
            "Train Epoch: 4 [2304/60032 (4%)]\tLoss: 0.031666\n",
            "Train Epoch: 4 [3072/60032 (5%)]\tLoss: 0.139187\n",
            "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.033193\n",
            "Train Epoch: 4 [4608/60032 (8%)]\tLoss: 0.011813\n",
            "Train Epoch: 4 [5376/60032 (9%)]\tLoss: 0.234500\n",
            "Train Epoch: 4 [6144/60032 (10%)]\tLoss: 0.023957\n",
            "Train Epoch: 4 [6912/60032 (12%)]\tLoss: 0.056938\n",
            "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.120430\n",
            "Train Epoch: 4 [8448/60032 (14%)]\tLoss: 0.016565\n",
            "Train Epoch: 4 [9216/60032 (15%)]\tLoss: 0.016921\n",
            "Train Epoch: 4 [9984/60032 (17%)]\tLoss: 0.099788\n",
            "Train Epoch: 4 [10752/60032 (18%)]\tLoss: 0.022651\n",
            "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.104920\n",
            "Train Epoch: 4 [12288/60032 (20%)]\tLoss: 0.057803\n",
            "Train Epoch: 4 [13056/60032 (22%)]\tLoss: 0.046091\n",
            "Train Epoch: 4 [13824/60032 (23%)]\tLoss: 0.027148\n",
            "Train Epoch: 4 [14592/60032 (24%)]\tLoss: 0.029014\n",
            "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.020425\n",
            "Train Epoch: 4 [16128/60032 (27%)]\tLoss: 0.022171\n",
            "Train Epoch: 4 [16896/60032 (28%)]\tLoss: 0.139598\n",
            "Train Epoch: 4 [17664/60032 (29%)]\tLoss: 0.029171\n",
            "Train Epoch: 4 [18432/60032 (31%)]\tLoss: 0.055355\n",
            "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.018394\n",
            "Train Epoch: 4 [19968/60032 (33%)]\tLoss: 0.030295\n",
            "Train Epoch: 4 [20736/60032 (35%)]\tLoss: 0.008717\n",
            "Train Epoch: 4 [21504/60032 (36%)]\tLoss: 0.094029\n",
            "Train Epoch: 4 [22272/60032 (37%)]\tLoss: 0.020457\n",
            "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.012235\n",
            "Train Epoch: 4 [23808/60032 (40%)]\tLoss: 0.019860\n",
            "Train Epoch: 4 [24576/60032 (41%)]\tLoss: 0.019609\n",
            "Train Epoch: 4 [25344/60032 (42%)]\tLoss: 0.066359\n",
            "Train Epoch: 4 [26112/60032 (43%)]\tLoss: 0.007142\n",
            "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.025303\n",
            "Train Epoch: 4 [27648/60032 (46%)]\tLoss: 0.025423\n",
            "Train Epoch: 4 [28416/60032 (47%)]\tLoss: 0.174208\n",
            "Train Epoch: 4 [29184/60032 (49%)]\tLoss: 0.021445\n",
            "Train Epoch: 4 [29952/60032 (50%)]\tLoss: 0.050511\n",
            "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.023690\n",
            "Train Epoch: 4 [31488/60032 (52%)]\tLoss: 0.024540\n",
            "Train Epoch: 4 [32256/60032 (54%)]\tLoss: 0.014044\n",
            "Train Epoch: 4 [33024/60032 (55%)]\tLoss: 0.026849\n",
            "Train Epoch: 4 [33792/60032 (56%)]\tLoss: 0.090708\n",
            "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.018866\n",
            "Train Epoch: 4 [35328/60032 (59%)]\tLoss: 0.017777\n",
            "Train Epoch: 4 [36096/60032 (60%)]\tLoss: 0.050550\n",
            "Train Epoch: 4 [36864/60032 (61%)]\tLoss: 0.016637\n",
            "Train Epoch: 4 [37632/60032 (63%)]\tLoss: 0.022594\n",
            "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.009016\n",
            "Train Epoch: 4 [39168/60032 (65%)]\tLoss: 0.091870\n",
            "Train Epoch: 4 [39936/60032 (67%)]\tLoss: 0.047522\n",
            "Train Epoch: 4 [40704/60032 (68%)]\tLoss: 0.036398\n",
            "Train Epoch: 4 [41472/60032 (69%)]\tLoss: 0.057594\n",
            "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.035858\n",
            "Train Epoch: 4 [43008/60032 (72%)]\tLoss: 0.053566\n",
            "Train Epoch: 4 [43776/60032 (73%)]\tLoss: 0.116736\n",
            "Train Epoch: 4 [44544/60032 (74%)]\tLoss: 0.015242\n",
            "Train Epoch: 4 [45312/60032 (75%)]\tLoss: 0.009307\n",
            "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.026366\n",
            "Train Epoch: 4 [46848/60032 (78%)]\tLoss: 0.017037\n",
            "Train Epoch: 4 [47616/60032 (79%)]\tLoss: 0.123897\n",
            "Train Epoch: 4 [48384/60032 (81%)]\tLoss: 0.038769\n",
            "Train Epoch: 4 [49152/60032 (82%)]\tLoss: 0.026777\n",
            "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.016556\n",
            "Train Epoch: 4 [50688/60032 (84%)]\tLoss: 0.062857\n",
            "Train Epoch: 4 [51456/60032 (86%)]\tLoss: 0.073451\n",
            "Train Epoch: 4 [52224/60032 (87%)]\tLoss: 0.275010\n",
            "Train Epoch: 4 [52992/60032 (88%)]\tLoss: 0.021313\n",
            "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.020476\n",
            "Train Epoch: 4 [54528/60032 (91%)]\tLoss: 0.019235\n",
            "Train Epoch: 4 [55296/60032 (92%)]\tLoss: 0.039539\n",
            "Train Epoch: 4 [56064/60032 (93%)]\tLoss: 0.054844\n",
            "Train Epoch: 4 [56832/60032 (95%)]\tLoss: 0.088365\n",
            "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.091453\n",
            "Train Epoch: 4 [58368/60032 (97%)]\tLoss: 0.045518\n",
            "Train Epoch: 4 [59136/60032 (99%)]\tLoss: 0.013580\n",
            "Train Epoch: 4 [59904/60032 (100%)]\tLoss: 0.019796\n",
            "\n",
            "Test set: Average loss: 0.0383, Accuracy: 9872/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.058962\n",
            "Train Epoch: 5 [768/60032 (1%)]\tLoss: 0.027227\n",
            "Train Epoch: 5 [1536/60032 (3%)]\tLoss: 0.056837\n",
            "Train Epoch: 5 [2304/60032 (4%)]\tLoss: 0.153891\n",
            "Train Epoch: 5 [3072/60032 (5%)]\tLoss: 0.021927\n",
            "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.041729\n",
            "Train Epoch: 5 [4608/60032 (8%)]\tLoss: 0.011491\n",
            "Train Epoch: 5 [5376/60032 (9%)]\tLoss: 0.015840\n",
            "Train Epoch: 5 [6144/60032 (10%)]\tLoss: 0.039447\n",
            "Train Epoch: 5 [6912/60032 (12%)]\tLoss: 0.025565\n",
            "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.015482\n",
            "Train Epoch: 5 [8448/60032 (14%)]\tLoss: 0.030061\n",
            "Train Epoch: 5 [9216/60032 (15%)]\tLoss: 0.126976\n",
            "Train Epoch: 5 [9984/60032 (17%)]\tLoss: 0.022658\n",
            "Train Epoch: 5 [10752/60032 (18%)]\tLoss: 0.056692\n",
            "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.009734\n",
            "Train Epoch: 5 [12288/60032 (20%)]\tLoss: 0.053900\n",
            "Train Epoch: 5 [13056/60032 (22%)]\tLoss: 0.014737\n",
            "Train Epoch: 5 [13824/60032 (23%)]\tLoss: 0.089917\n",
            "Train Epoch: 5 [14592/60032 (24%)]\tLoss: 0.045818\n",
            "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.011148\n",
            "Train Epoch: 5 [16128/60032 (27%)]\tLoss: 0.009123\n",
            "Train Epoch: 5 [16896/60032 (28%)]\tLoss: 0.028736\n",
            "Train Epoch: 5 [17664/60032 (29%)]\tLoss: 0.004311\n",
            "Train Epoch: 5 [18432/60032 (31%)]\tLoss: 0.149613\n",
            "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.009511\n",
            "Train Epoch: 5 [19968/60032 (33%)]\tLoss: 0.044508\n",
            "Train Epoch: 5 [20736/60032 (35%)]\tLoss: 0.003663\n",
            "Train Epoch: 5 [21504/60032 (36%)]\tLoss: 0.029731\n",
            "Train Epoch: 5 [22272/60032 (37%)]\tLoss: 0.053714\n",
            "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.086232\n",
            "Train Epoch: 5 [23808/60032 (40%)]\tLoss: 0.019226\n",
            "Train Epoch: 5 [24576/60032 (41%)]\tLoss: 0.021648\n",
            "Train Epoch: 5 [25344/60032 (42%)]\tLoss: 0.064297\n",
            "Train Epoch: 5 [26112/60032 (43%)]\tLoss: 0.058448\n",
            "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.084251\n",
            "Train Epoch: 5 [27648/60032 (46%)]\tLoss: 0.031790\n",
            "Train Epoch: 5 [28416/60032 (47%)]\tLoss: 0.041932\n",
            "Train Epoch: 5 [29184/60032 (49%)]\tLoss: 0.070083\n",
            "Train Epoch: 5 [29952/60032 (50%)]\tLoss: 0.006148\n",
            "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.023465\n",
            "Train Epoch: 5 [31488/60032 (52%)]\tLoss: 0.005628\n",
            "Train Epoch: 5 [32256/60032 (54%)]\tLoss: 0.039944\n",
            "Train Epoch: 5 [33024/60032 (55%)]\tLoss: 0.046256\n",
            "Train Epoch: 5 [33792/60032 (56%)]\tLoss: 0.017292\n",
            "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.083212\n",
            "Train Epoch: 5 [35328/60032 (59%)]\tLoss: 0.076253\n",
            "Train Epoch: 5 [36096/60032 (60%)]\tLoss: 0.023815\n",
            "Train Epoch: 5 [36864/60032 (61%)]\tLoss: 0.053340\n",
            "Train Epoch: 5 [37632/60032 (63%)]\tLoss: 0.058968\n",
            "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.028454\n",
            "Train Epoch: 5 [39168/60032 (65%)]\tLoss: 0.010130\n",
            "Train Epoch: 5 [39936/60032 (67%)]\tLoss: 0.004600\n",
            "Train Epoch: 5 [40704/60032 (68%)]\tLoss: 0.167961\n",
            "Train Epoch: 5 [41472/60032 (69%)]\tLoss: 0.058415\n",
            "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.007608\n",
            "Train Epoch: 5 [43008/60032 (72%)]\tLoss: 0.008754\n",
            "Train Epoch: 5 [43776/60032 (73%)]\tLoss: 0.067724\n",
            "Train Epoch: 5 [44544/60032 (74%)]\tLoss: 0.073249\n",
            "Train Epoch: 5 [45312/60032 (75%)]\tLoss: 0.011773\n",
            "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.033220\n",
            "Train Epoch: 5 [46848/60032 (78%)]\tLoss: 0.043822\n",
            "Train Epoch: 5 [47616/60032 (79%)]\tLoss: 0.139342\n",
            "Train Epoch: 5 [48384/60032 (81%)]\tLoss: 0.128831\n",
            "Train Epoch: 5 [49152/60032 (82%)]\tLoss: 0.010690\n",
            "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.022018\n",
            "Train Epoch: 5 [50688/60032 (84%)]\tLoss: 0.069035\n",
            "Train Epoch: 5 [51456/60032 (86%)]\tLoss: 0.087901\n",
            "Train Epoch: 5 [52224/60032 (87%)]\tLoss: 0.018763\n",
            "Train Epoch: 5 [52992/60032 (88%)]\tLoss: 0.009537\n",
            "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.071652\n",
            "Train Epoch: 5 [54528/60032 (91%)]\tLoss: 0.074806\n",
            "Train Epoch: 5 [55296/60032 (92%)]\tLoss: 0.082409\n",
            "Train Epoch: 5 [56064/60032 (93%)]\tLoss: 0.185393\n",
            "Train Epoch: 5 [56832/60032 (95%)]\tLoss: 0.018652\n",
            "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.088715\n",
            "Train Epoch: 5 [58368/60032 (97%)]\tLoss: 0.005379\n",
            "Train Epoch: 5 [59136/60032 (99%)]\tLoss: 0.016646\n",
            "Train Epoch: 5 [59904/60032 (100%)]\tLoss: 0.063481\n",
            "\n",
            "Test set: Average loss: 0.0359, Accuracy: 9880/10000 (99%)\n",
            "\n",
            "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.010032\n",
            "Train Epoch: 6 [768/60032 (1%)]\tLoss: 0.001138\n",
            "Train Epoch: 6 [1536/60032 (3%)]\tLoss: 0.122918\n",
            "Train Epoch: 6 [2304/60032 (4%)]\tLoss: 0.049070\n",
            "Train Epoch: 6 [3072/60032 (5%)]\tLoss: 0.117501\n",
            "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.025429\n",
            "Train Epoch: 6 [4608/60032 (8%)]\tLoss: 0.018468\n",
            "Train Epoch: 6 [5376/60032 (9%)]\tLoss: 0.036104\n",
            "Train Epoch: 6 [6144/60032 (10%)]\tLoss: 0.071801\n",
            "Train Epoch: 6 [6912/60032 (12%)]\tLoss: 0.007446\n",
            "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.013260\n",
            "Train Epoch: 6 [8448/60032 (14%)]\tLoss: 0.016811\n",
            "Train Epoch: 6 [9216/60032 (15%)]\tLoss: 0.061721\n",
            "Train Epoch: 6 [9984/60032 (17%)]\tLoss: 0.038691\n",
            "Train Epoch: 6 [10752/60032 (18%)]\tLoss: 0.024177\n",
            "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.019859\n",
            "Train Epoch: 6 [12288/60032 (20%)]\tLoss: 0.030861\n",
            "Train Epoch: 6 [13056/60032 (22%)]\tLoss: 0.004608\n",
            "Train Epoch: 6 [13824/60032 (23%)]\tLoss: 0.102504\n",
            "Train Epoch: 6 [14592/60032 (24%)]\tLoss: 0.024081\n",
            "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.007218\n",
            "Train Epoch: 6 [16128/60032 (27%)]\tLoss: 0.105019\n",
            "Train Epoch: 6 [16896/60032 (28%)]\tLoss: 0.060534\n",
            "Train Epoch: 6 [17664/60032 (29%)]\tLoss: 0.028824\n",
            "Train Epoch: 6 [18432/60032 (31%)]\tLoss: 0.014787\n",
            "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.103501\n",
            "Train Epoch: 6 [19968/60032 (33%)]\tLoss: 0.044555\n",
            "Train Epoch: 6 [20736/60032 (35%)]\tLoss: 0.074948\n",
            "Train Epoch: 6 [21504/60032 (36%)]\tLoss: 0.078638\n",
            "Train Epoch: 6 [22272/60032 (37%)]\tLoss: 0.088112\n",
            "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.063058\n",
            "Train Epoch: 6 [23808/60032 (40%)]\tLoss: 0.178665\n",
            "Train Epoch: 6 [24576/60032 (41%)]\tLoss: 0.026670\n",
            "Train Epoch: 6 [25344/60032 (42%)]\tLoss: 0.065255\n",
            "Train Epoch: 6 [26112/60032 (43%)]\tLoss: 0.002773\n",
            "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.014183\n",
            "Train Epoch: 6 [27648/60032 (46%)]\tLoss: 0.027645\n",
            "Train Epoch: 6 [28416/60032 (47%)]\tLoss: 0.009892\n",
            "Train Epoch: 6 [29184/60032 (49%)]\tLoss: 0.052983\n",
            "Train Epoch: 6 [29952/60032 (50%)]\tLoss: 0.014563\n",
            "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.057702\n",
            "Train Epoch: 6 [31488/60032 (52%)]\tLoss: 0.090906\n",
            "Train Epoch: 6 [32256/60032 (54%)]\tLoss: 0.009357\n",
            "Train Epoch: 6 [33024/60032 (55%)]\tLoss: 0.009550\n",
            "Train Epoch: 6 [33792/60032 (56%)]\tLoss: 0.038694\n",
            "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.021028\n",
            "Train Epoch: 6 [35328/60032 (59%)]\tLoss: 0.069651\n",
            "Train Epoch: 6 [36096/60032 (60%)]\tLoss: 0.002726\n",
            "Train Epoch: 6 [36864/60032 (61%)]\tLoss: 0.003348\n",
            "Train Epoch: 6 [37632/60032 (63%)]\tLoss: 0.018867\n",
            "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.019720\n",
            "Train Epoch: 6 [39168/60032 (65%)]\tLoss: 0.056278\n",
            "Train Epoch: 6 [39936/60032 (67%)]\tLoss: 0.005690\n",
            "Train Epoch: 6 [40704/60032 (68%)]\tLoss: 0.026320\n",
            "Train Epoch: 6 [41472/60032 (69%)]\tLoss: 0.035494\n",
            "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.016047\n",
            "Train Epoch: 6 [43008/60032 (72%)]\tLoss: 0.004676\n",
            "Train Epoch: 6 [43776/60032 (73%)]\tLoss: 0.039044\n",
            "Train Epoch: 6 [44544/60032 (74%)]\tLoss: 0.040893\n",
            "Train Epoch: 6 [45312/60032 (75%)]\tLoss: 0.143475\n",
            "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.014718\n",
            "Train Epoch: 6 [46848/60032 (78%)]\tLoss: 0.019787\n",
            "Train Epoch: 6 [47616/60032 (79%)]\tLoss: 0.039939\n",
            "Train Epoch: 6 [48384/60032 (81%)]\tLoss: 0.013762\n",
            "Train Epoch: 6 [49152/60032 (82%)]\tLoss: 0.012868\n",
            "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.017910\n",
            "Train Epoch: 6 [50688/60032 (84%)]\tLoss: 0.034081\n",
            "Train Epoch: 6 [51456/60032 (86%)]\tLoss: 0.010225\n",
            "Train Epoch: 6 [52224/60032 (87%)]\tLoss: 0.040427\n",
            "Train Epoch: 6 [52992/60032 (88%)]\tLoss: 0.029696\n",
            "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.002769\n",
            "Train Epoch: 6 [54528/60032 (91%)]\tLoss: 0.007545\n",
            "Train Epoch: 6 [55296/60032 (92%)]\tLoss: 0.007650\n",
            "Train Epoch: 6 [56064/60032 (93%)]\tLoss: 0.070868\n",
            "Train Epoch: 6 [56832/60032 (95%)]\tLoss: 0.012083\n",
            "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.016863\n",
            "Train Epoch: 6 [58368/60032 (97%)]\tLoss: 0.070012\n",
            "Train Epoch: 6 [59136/60032 (99%)]\tLoss: 0.017567\n",
            "Train Epoch: 6 [59904/60032 (100%)]\tLoss: 0.037174\n",
            "\n",
            "Test set: Average loss: 0.0365, Accuracy: 9885/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.062627\n",
            "Train Epoch: 7 [768/60032 (1%)]\tLoss: 0.024135\n",
            "Train Epoch: 7 [1536/60032 (3%)]\tLoss: 0.034960\n",
            "Train Epoch: 7 [2304/60032 (4%)]\tLoss: 0.028477\n",
            "Train Epoch: 7 [3072/60032 (5%)]\tLoss: 0.005828\n",
            "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.019867\n",
            "Train Epoch: 7 [4608/60032 (8%)]\tLoss: 0.007670\n",
            "Train Epoch: 7 [5376/60032 (9%)]\tLoss: 0.016184\n",
            "Train Epoch: 7 [6144/60032 (10%)]\tLoss: 0.029362\n",
            "Train Epoch: 7 [6912/60032 (12%)]\tLoss: 0.029965\n",
            "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.006768\n",
            "Train Epoch: 7 [8448/60032 (14%)]\tLoss: 0.032988\n",
            "Train Epoch: 7 [9216/60032 (15%)]\tLoss: 0.002678\n",
            "Train Epoch: 7 [9984/60032 (17%)]\tLoss: 0.027444\n",
            "Train Epoch: 7 [10752/60032 (18%)]\tLoss: 0.005488\n",
            "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.008120\n",
            "Train Epoch: 7 [12288/60032 (20%)]\tLoss: 0.019698\n",
            "Train Epoch: 7 [13056/60032 (22%)]\tLoss: 0.053225\n",
            "Train Epoch: 7 [13824/60032 (23%)]\tLoss: 0.019076\n",
            "Train Epoch: 7 [14592/60032 (24%)]\tLoss: 0.021067\n",
            "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.002373\n",
            "Train Epoch: 7 [16128/60032 (27%)]\tLoss: 0.013603\n",
            "Train Epoch: 7 [16896/60032 (28%)]\tLoss: 0.034841\n",
            "Train Epoch: 7 [17664/60032 (29%)]\tLoss: 0.051976\n",
            "Train Epoch: 7 [18432/60032 (31%)]\tLoss: 0.010929\n",
            "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.010525\n",
            "Train Epoch: 7 [19968/60032 (33%)]\tLoss: 0.016708\n",
            "Train Epoch: 7 [20736/60032 (35%)]\tLoss: 0.026713\n",
            "Train Epoch: 7 [21504/60032 (36%)]\tLoss: 0.047479\n",
            "Train Epoch: 7 [22272/60032 (37%)]\tLoss: 0.007361\n",
            "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.050166\n",
            "Train Epoch: 7 [23808/60032 (40%)]\tLoss: 0.015153\n",
            "Train Epoch: 7 [24576/60032 (41%)]\tLoss: 0.024162\n",
            "Train Epoch: 7 [25344/60032 (42%)]\tLoss: 0.112202\n",
            "Train Epoch: 7 [26112/60032 (43%)]\tLoss: 0.034932\n",
            "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.010975\n",
            "Train Epoch: 7 [27648/60032 (46%)]\tLoss: 0.019256\n",
            "Train Epoch: 7 [28416/60032 (47%)]\tLoss: 0.033206\n",
            "Train Epoch: 7 [29184/60032 (49%)]\tLoss: 0.051251\n",
            "Train Epoch: 7 [29952/60032 (50%)]\tLoss: 0.085271\n",
            "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.034946\n",
            "Train Epoch: 7 [31488/60032 (52%)]\tLoss: 0.014255\n",
            "Train Epoch: 7 [32256/60032 (54%)]\tLoss: 0.034856\n",
            "Train Epoch: 7 [33024/60032 (55%)]\tLoss: 0.004622\n",
            "Train Epoch: 7 [33792/60032 (56%)]\tLoss: 0.028204\n",
            "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.001594\n",
            "Train Epoch: 7 [35328/60032 (59%)]\tLoss: 0.013236\n",
            "Train Epoch: 7 [36096/60032 (60%)]\tLoss: 0.009459\n",
            "Train Epoch: 7 [36864/60032 (61%)]\tLoss: 0.002850\n",
            "Train Epoch: 7 [37632/60032 (63%)]\tLoss: 0.015285\n",
            "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.001992\n",
            "Train Epoch: 7 [39168/60032 (65%)]\tLoss: 0.010962\n",
            "Train Epoch: 7 [39936/60032 (67%)]\tLoss: 0.031791\n",
            "Train Epoch: 7 [40704/60032 (68%)]\tLoss: 0.037229\n",
            "Train Epoch: 7 [41472/60032 (69%)]\tLoss: 0.001529\n",
            "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.003835\n",
            "Train Epoch: 7 [43008/60032 (72%)]\tLoss: 0.039215\n",
            "Train Epoch: 7 [43776/60032 (73%)]\tLoss: 0.011633\n",
            "Train Epoch: 7 [44544/60032 (74%)]\tLoss: 0.009305\n",
            "Train Epoch: 7 [45312/60032 (75%)]\tLoss: 0.011725\n",
            "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.067249\n",
            "Train Epoch: 7 [46848/60032 (78%)]\tLoss: 0.023521\n",
            "Train Epoch: 7 [47616/60032 (79%)]\tLoss: 0.009891\n",
            "Train Epoch: 7 [48384/60032 (81%)]\tLoss: 0.002683\n",
            "Train Epoch: 7 [49152/60032 (82%)]\tLoss: 0.016824\n",
            "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.013012\n",
            "Train Epoch: 7 [50688/60032 (84%)]\tLoss: 0.011242\n",
            "Train Epoch: 7 [51456/60032 (86%)]\tLoss: 0.009367\n",
            "Train Epoch: 7 [52224/60032 (87%)]\tLoss: 0.029958\n",
            "Train Epoch: 7 [52992/60032 (88%)]\tLoss: 0.005120\n",
            "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.004236\n",
            "Train Epoch: 7 [54528/60032 (91%)]\tLoss: 0.001290\n",
            "Train Epoch: 7 [55296/60032 (92%)]\tLoss: 0.008297\n",
            "Train Epoch: 7 [56064/60032 (93%)]\tLoss: 0.133367\n",
            "Train Epoch: 7 [56832/60032 (95%)]\tLoss: 0.003442\n",
            "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.038392\n",
            "Train Epoch: 7 [58368/60032 (97%)]\tLoss: 0.041394\n",
            "Train Epoch: 7 [59136/60032 (99%)]\tLoss: 0.032627\n",
            "Train Epoch: 7 [59904/60032 (100%)]\tLoss: 0.009298\n",
            "\n",
            "Test set: Average loss: 0.0294, Accuracy: 9904/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.006103\n",
            "Train Epoch: 8 [768/60032 (1%)]\tLoss: 0.058446\n",
            "Train Epoch: 8 [1536/60032 (3%)]\tLoss: 0.114217\n",
            "Train Epoch: 8 [2304/60032 (4%)]\tLoss: 0.011596\n",
            "Train Epoch: 8 [3072/60032 (5%)]\tLoss: 0.099386\n",
            "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.029897\n",
            "Train Epoch: 8 [4608/60032 (8%)]\tLoss: 0.002423\n",
            "Train Epoch: 8 [5376/60032 (9%)]\tLoss: 0.079782\n",
            "Train Epoch: 8 [6144/60032 (10%)]\tLoss: 0.012899\n",
            "Train Epoch: 8 [6912/60032 (12%)]\tLoss: 0.003804\n",
            "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.096319\n",
            "Train Epoch: 8 [8448/60032 (14%)]\tLoss: 0.014628\n",
            "Train Epoch: 8 [9216/60032 (15%)]\tLoss: 0.071104\n",
            "Train Epoch: 8 [9984/60032 (17%)]\tLoss: 0.057053\n",
            "Train Epoch: 8 [10752/60032 (18%)]\tLoss: 0.017303\n",
            "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.018972\n",
            "Train Epoch: 8 [12288/60032 (20%)]\tLoss: 0.009363\n",
            "Train Epoch: 8 [13056/60032 (22%)]\tLoss: 0.010190\n",
            "Train Epoch: 8 [13824/60032 (23%)]\tLoss: 0.049411\n",
            "Train Epoch: 8 [14592/60032 (24%)]\tLoss: 0.001129\n",
            "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.006872\n",
            "Train Epoch: 8 [16128/60032 (27%)]\tLoss: 0.004252\n",
            "Train Epoch: 8 [16896/60032 (28%)]\tLoss: 0.006660\n",
            "Train Epoch: 8 [17664/60032 (29%)]\tLoss: 0.010424\n",
            "Train Epoch: 8 [18432/60032 (31%)]\tLoss: 0.017393\n",
            "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.014636\n",
            "Train Epoch: 8 [19968/60032 (33%)]\tLoss: 0.063393\n",
            "Train Epoch: 8 [20736/60032 (35%)]\tLoss: 0.031739\n",
            "Train Epoch: 8 [21504/60032 (36%)]\tLoss: 0.020460\n",
            "Train Epoch: 8 [22272/60032 (37%)]\tLoss: 0.008784\n",
            "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.011583\n",
            "Train Epoch: 8 [23808/60032 (40%)]\tLoss: 0.003581\n",
            "Train Epoch: 8 [24576/60032 (41%)]\tLoss: 0.014364\n",
            "Train Epoch: 8 [25344/60032 (42%)]\tLoss: 0.026864\n",
            "Train Epoch: 8 [26112/60032 (43%)]\tLoss: 0.076242\n",
            "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.006205\n",
            "Train Epoch: 8 [27648/60032 (46%)]\tLoss: 0.035798\n",
            "Train Epoch: 8 [28416/60032 (47%)]\tLoss: 0.016106\n",
            "Train Epoch: 8 [29184/60032 (49%)]\tLoss: 0.002547\n",
            "Train Epoch: 8 [29952/60032 (50%)]\tLoss: 0.091214\n",
            "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.003222\n",
            "Train Epoch: 8 [31488/60032 (52%)]\tLoss: 0.006548\n",
            "Train Epoch: 8 [32256/60032 (54%)]\tLoss: 0.005919\n",
            "Train Epoch: 8 [33024/60032 (55%)]\tLoss: 0.077826\n",
            "Train Epoch: 8 [33792/60032 (56%)]\tLoss: 0.008457\n",
            "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.033358\n",
            "Train Epoch: 8 [35328/60032 (59%)]\tLoss: 0.014272\n",
            "Train Epoch: 8 [36096/60032 (60%)]\tLoss: 0.063089\n",
            "Train Epoch: 8 [36864/60032 (61%)]\tLoss: 0.042424\n",
            "Train Epoch: 8 [37632/60032 (63%)]\tLoss: 0.048130\n",
            "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.060832\n",
            "Train Epoch: 8 [39168/60032 (65%)]\tLoss: 0.035614\n",
            "Train Epoch: 8 [39936/60032 (67%)]\tLoss: 0.010540\n",
            "Train Epoch: 8 [40704/60032 (68%)]\tLoss: 0.104114\n",
            "Train Epoch: 8 [41472/60032 (69%)]\tLoss: 0.001914\n",
            "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.002706\n",
            "Train Epoch: 8 [43008/60032 (72%)]\tLoss: 0.005622\n",
            "Train Epoch: 8 [43776/60032 (73%)]\tLoss: 0.005145\n",
            "Train Epoch: 8 [44544/60032 (74%)]\tLoss: 0.097432\n",
            "Train Epoch: 8 [45312/60032 (75%)]\tLoss: 0.069312\n",
            "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.007737\n",
            "Train Epoch: 8 [46848/60032 (78%)]\tLoss: 0.002512\n",
            "Train Epoch: 8 [47616/60032 (79%)]\tLoss: 0.013778\n",
            "Train Epoch: 8 [48384/60032 (81%)]\tLoss: 0.012199\n",
            "Train Epoch: 8 [49152/60032 (82%)]\tLoss: 0.011022\n",
            "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.002534\n",
            "Train Epoch: 8 [50688/60032 (84%)]\tLoss: 0.035264\n",
            "Train Epoch: 8 [51456/60032 (86%)]\tLoss: 0.009311\n",
            "Train Epoch: 8 [52224/60032 (87%)]\tLoss: 0.073539\n",
            "Train Epoch: 8 [52992/60032 (88%)]\tLoss: 0.021198\n",
            "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.004903\n",
            "Train Epoch: 8 [54528/60032 (91%)]\tLoss: 0.025028\n",
            "Train Epoch: 8 [55296/60032 (92%)]\tLoss: 0.013932\n",
            "Train Epoch: 8 [56064/60032 (93%)]\tLoss: 0.007291\n",
            "Train Epoch: 8 [56832/60032 (95%)]\tLoss: 0.003599\n",
            "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.063497\n",
            "Train Epoch: 8 [58368/60032 (97%)]\tLoss: 0.004263\n",
            "Train Epoch: 8 [59136/60032 (99%)]\tLoss: 0.058565\n",
            "Train Epoch: 8 [59904/60032 (100%)]\tLoss: 0.032217\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 9882/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.005641\n",
            "Train Epoch: 9 [768/60032 (1%)]\tLoss: 0.020889\n",
            "Train Epoch: 9 [1536/60032 (3%)]\tLoss: 0.011282\n",
            "Train Epoch: 9 [2304/60032 (4%)]\tLoss: 0.007826\n",
            "Train Epoch: 9 [3072/60032 (5%)]\tLoss: 0.006882\n",
            "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.013943\n",
            "Train Epoch: 9 [4608/60032 (8%)]\tLoss: 0.044304\n",
            "Train Epoch: 9 [5376/60032 (9%)]\tLoss: 0.002709\n",
            "Train Epoch: 9 [6144/60032 (10%)]\tLoss: 0.002690\n",
            "Train Epoch: 9 [6912/60032 (12%)]\tLoss: 0.031739\n",
            "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.021068\n",
            "Train Epoch: 9 [8448/60032 (14%)]\tLoss: 0.003171\n",
            "Train Epoch: 9 [9216/60032 (15%)]\tLoss: 0.039721\n",
            "Train Epoch: 9 [9984/60032 (17%)]\tLoss: 0.046800\n",
            "Train Epoch: 9 [10752/60032 (18%)]\tLoss: 0.038894\n",
            "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.001877\n",
            "Train Epoch: 9 [12288/60032 (20%)]\tLoss: 0.043551\n",
            "Train Epoch: 9 [13056/60032 (22%)]\tLoss: 0.006628\n",
            "Train Epoch: 9 [13824/60032 (23%)]\tLoss: 0.004908\n",
            "Train Epoch: 9 [14592/60032 (24%)]\tLoss: 0.035483\n",
            "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.003919\n",
            "Train Epoch: 9 [16128/60032 (27%)]\tLoss: 0.006819\n",
            "Train Epoch: 9 [16896/60032 (28%)]\tLoss: 0.008561\n",
            "Train Epoch: 9 [17664/60032 (29%)]\tLoss: 0.005529\n",
            "Train Epoch: 9 [18432/60032 (31%)]\tLoss: 0.008780\n",
            "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.023758\n",
            "Train Epoch: 9 [19968/60032 (33%)]\tLoss: 0.086963\n",
            "Train Epoch: 9 [20736/60032 (35%)]\tLoss: 0.002075\n",
            "Train Epoch: 9 [21504/60032 (36%)]\tLoss: 0.007354\n",
            "Train Epoch: 9 [22272/60032 (37%)]\tLoss: 0.016466\n",
            "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.011487\n",
            "Train Epoch: 9 [23808/60032 (40%)]\tLoss: 0.014702\n",
            "Train Epoch: 9 [24576/60032 (41%)]\tLoss: 0.011937\n",
            "Train Epoch: 9 [25344/60032 (42%)]\tLoss: 0.016557\n",
            "Train Epoch: 9 [26112/60032 (43%)]\tLoss: 0.031150\n",
            "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.001932\n",
            "Train Epoch: 9 [27648/60032 (46%)]\tLoss: 0.000508\n",
            "Train Epoch: 9 [28416/60032 (47%)]\tLoss: 0.001179\n",
            "Train Epoch: 9 [29184/60032 (49%)]\tLoss: 0.085156\n",
            "Train Epoch: 9 [29952/60032 (50%)]\tLoss: 0.002541\n",
            "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.020406\n",
            "Train Epoch: 9 [31488/60032 (52%)]\tLoss: 0.051698\n",
            "Train Epoch: 9 [32256/60032 (54%)]\tLoss: 0.007025\n",
            "Train Epoch: 9 [33024/60032 (55%)]\tLoss: 0.047779\n",
            "Train Epoch: 9 [33792/60032 (56%)]\tLoss: 0.009226\n",
            "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.009986\n",
            "Train Epoch: 9 [35328/60032 (59%)]\tLoss: 0.026998\n",
            "Train Epoch: 9 [36096/60032 (60%)]\tLoss: 0.006600\n",
            "Train Epoch: 9 [36864/60032 (61%)]\tLoss: 0.057122\n",
            "Train Epoch: 9 [37632/60032 (63%)]\tLoss: 0.006015\n",
            "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.029276\n",
            "Train Epoch: 9 [39168/60032 (65%)]\tLoss: 0.036820\n",
            "Train Epoch: 9 [39936/60032 (67%)]\tLoss: 0.066324\n",
            "Train Epoch: 9 [40704/60032 (68%)]\tLoss: 0.012014\n",
            "Train Epoch: 9 [41472/60032 (69%)]\tLoss: 0.006135\n",
            "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.048380\n",
            "Train Epoch: 9 [43008/60032 (72%)]\tLoss: 0.046230\n",
            "Train Epoch: 9 [43776/60032 (73%)]\tLoss: 0.006733\n",
            "Train Epoch: 9 [44544/60032 (74%)]\tLoss: 0.003588\n",
            "Train Epoch: 9 [45312/60032 (75%)]\tLoss: 0.011495\n",
            "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.004750\n",
            "Train Epoch: 9 [46848/60032 (78%)]\tLoss: 0.052197\n",
            "Train Epoch: 9 [47616/60032 (79%)]\tLoss: 0.009751\n",
            "Train Epoch: 9 [48384/60032 (81%)]\tLoss: 0.018933\n",
            "Train Epoch: 9 [49152/60032 (82%)]\tLoss: 0.171267\n",
            "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.024038\n",
            "Train Epoch: 9 [50688/60032 (84%)]\tLoss: 0.058093\n",
            "Train Epoch: 9 [51456/60032 (86%)]\tLoss: 0.020500\n",
            "Train Epoch: 9 [52224/60032 (87%)]\tLoss: 0.021582\n",
            "Train Epoch: 9 [52992/60032 (88%)]\tLoss: 0.076164\n",
            "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.005687\n",
            "Train Epoch: 9 [54528/60032 (91%)]\tLoss: 0.007353\n",
            "Train Epoch: 9 [55296/60032 (92%)]\tLoss: 0.012824\n",
            "Train Epoch: 9 [56064/60032 (93%)]\tLoss: 0.005086\n",
            "Train Epoch: 9 [56832/60032 (95%)]\tLoss: 0.010866\n",
            "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.007251\n",
            "Train Epoch: 9 [58368/60032 (97%)]\tLoss: 0.036245\n",
            "Train Epoch: 9 [59136/60032 (99%)]\tLoss: 0.003676\n",
            "Train Epoch: 9 [59904/60032 (100%)]\tLoss: 0.006129\n",
            "\n",
            "Test set: Average loss: 0.0329, Accuracy: 9887/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.052739\n",
            "Train Epoch: 10 [768/60032 (1%)]\tLoss: 0.003651\n",
            "Train Epoch: 10 [1536/60032 (3%)]\tLoss: 0.017500\n",
            "Train Epoch: 10 [2304/60032 (4%)]\tLoss: 0.016673\n",
            "Train Epoch: 10 [3072/60032 (5%)]\tLoss: 0.175474\n",
            "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.019752\n",
            "Train Epoch: 10 [4608/60032 (8%)]\tLoss: 0.053276\n",
            "Train Epoch: 10 [5376/60032 (9%)]\tLoss: 0.008944\n",
            "Train Epoch: 10 [6144/60032 (10%)]\tLoss: 0.002442\n",
            "Train Epoch: 10 [6912/60032 (12%)]\tLoss: 0.004209\n",
            "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.007086\n",
            "Train Epoch: 10 [8448/60032 (14%)]\tLoss: 0.017660\n",
            "Train Epoch: 10 [9216/60032 (15%)]\tLoss: 0.063812\n",
            "Train Epoch: 10 [9984/60032 (17%)]\tLoss: 0.026234\n",
            "Train Epoch: 10 [10752/60032 (18%)]\tLoss: 0.003693\n",
            "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.016880\n",
            "Train Epoch: 10 [12288/60032 (20%)]\tLoss: 0.043234\n",
            "Train Epoch: 10 [13056/60032 (22%)]\tLoss: 0.003760\n",
            "Train Epoch: 10 [13824/60032 (23%)]\tLoss: 0.001508\n",
            "Train Epoch: 10 [14592/60032 (24%)]\tLoss: 0.008473\n",
            "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.006034\n",
            "Train Epoch: 10 [16128/60032 (27%)]\tLoss: 0.005774\n",
            "Train Epoch: 10 [16896/60032 (28%)]\tLoss: 0.009661\n",
            "Train Epoch: 10 [17664/60032 (29%)]\tLoss: 0.035979\n",
            "Train Epoch: 10 [18432/60032 (31%)]\tLoss: 0.012193\n",
            "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.002218\n",
            "Train Epoch: 10 [19968/60032 (33%)]\tLoss: 0.007931\n",
            "Train Epoch: 10 [20736/60032 (35%)]\tLoss: 0.034231\n",
            "Train Epoch: 10 [21504/60032 (36%)]\tLoss: 0.008567\n",
            "Train Epoch: 10 [22272/60032 (37%)]\tLoss: 0.023446\n",
            "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.006017\n",
            "Train Epoch: 10 [23808/60032 (40%)]\tLoss: 0.007695\n",
            "Train Epoch: 10 [24576/60032 (41%)]\tLoss: 0.000747\n",
            "Train Epoch: 10 [25344/60032 (42%)]\tLoss: 0.004829\n",
            "Train Epoch: 10 [26112/60032 (43%)]\tLoss: 0.017849\n",
            "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.002410\n",
            "Train Epoch: 10 [27648/60032 (46%)]\tLoss: 0.021411\n",
            "Train Epoch: 10 [28416/60032 (47%)]\tLoss: 0.064822\n",
            "Train Epoch: 10 [29184/60032 (49%)]\tLoss: 0.013277\n",
            "Train Epoch: 10 [29952/60032 (50%)]\tLoss: 0.028672\n",
            "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.024575\n",
            "Train Epoch: 10 [31488/60032 (52%)]\tLoss: 0.003486\n",
            "Train Epoch: 10 [32256/60032 (54%)]\tLoss: 0.015481\n",
            "Train Epoch: 10 [33024/60032 (55%)]\tLoss: 0.026028\n",
            "Train Epoch: 10 [33792/60032 (56%)]\tLoss: 0.037327\n",
            "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.005001\n",
            "Train Epoch: 10 [35328/60032 (59%)]\tLoss: 0.024266\n",
            "Train Epoch: 10 [36096/60032 (60%)]\tLoss: 0.031825\n",
            "Train Epoch: 10 [36864/60032 (61%)]\tLoss: 0.069041\n",
            "Train Epoch: 10 [37632/60032 (63%)]\tLoss: 0.061086\n",
            "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.001790\n",
            "Train Epoch: 10 [39168/60032 (65%)]\tLoss: 0.011051\n",
            "Train Epoch: 10 [39936/60032 (67%)]\tLoss: 0.019862\n",
            "Train Epoch: 10 [40704/60032 (68%)]\tLoss: 0.026407\n",
            "Train Epoch: 10 [41472/60032 (69%)]\tLoss: 0.004665\n",
            "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.003662\n",
            "Train Epoch: 10 [43008/60032 (72%)]\tLoss: 0.041955\n",
            "Train Epoch: 10 [43776/60032 (73%)]\tLoss: 0.006968\n",
            "Train Epoch: 10 [44544/60032 (74%)]\tLoss: 0.020303\n",
            "Train Epoch: 10 [45312/60032 (75%)]\tLoss: 0.004067\n",
            "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.026366\n",
            "Train Epoch: 10 [46848/60032 (78%)]\tLoss: 0.002232\n",
            "Train Epoch: 10 [47616/60032 (79%)]\tLoss: 0.015707\n",
            "Train Epoch: 10 [48384/60032 (81%)]\tLoss: 0.001229\n",
            "Train Epoch: 10 [49152/60032 (82%)]\tLoss: 0.071704\n",
            "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.002918\n",
            "Train Epoch: 10 [50688/60032 (84%)]\tLoss: 0.018279\n",
            "Train Epoch: 10 [51456/60032 (86%)]\tLoss: 0.007452\n",
            "Train Epoch: 10 [52224/60032 (87%)]\tLoss: 0.045233\n",
            "Train Epoch: 10 [52992/60032 (88%)]\tLoss: 0.003369\n",
            "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.012094\n",
            "Train Epoch: 10 [54528/60032 (91%)]\tLoss: 0.008067\n",
            "Train Epoch: 10 [55296/60032 (92%)]\tLoss: 0.049389\n",
            "Train Epoch: 10 [56064/60032 (93%)]\tLoss: 0.010105\n",
            "Train Epoch: 10 [56832/60032 (95%)]\tLoss: 0.023372\n",
            "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.000858\n",
            "Train Epoch: 10 [58368/60032 (97%)]\tLoss: 0.025442\n",
            "Train Epoch: 10 [59136/60032 (99%)]\tLoss: 0.188804\n",
            "Train Epoch: 10 [59904/60032 (100%)]\tLoss: 0.004646\n",
            "\n",
            "Test set: Average loss: 0.0273, Accuracy: 9910/10000 (99%)\n",
            "\n",
            "Train Epoch: 11 [0/60032 (0%)]\tLoss: 0.019413\n",
            "Train Epoch: 11 [768/60032 (1%)]\tLoss: 0.011432\n",
            "Train Epoch: 11 [1536/60032 (3%)]\tLoss: 0.005486\n",
            "Train Epoch: 11 [2304/60032 (4%)]\tLoss: 0.006839\n",
            "Train Epoch: 11 [3072/60032 (5%)]\tLoss: 0.020694\n",
            "Train Epoch: 11 [3840/60032 (6%)]\tLoss: 0.001554\n",
            "Train Epoch: 11 [4608/60032 (8%)]\tLoss: 0.043150\n",
            "Train Epoch: 11 [5376/60032 (9%)]\tLoss: 0.002516\n",
            "Train Epoch: 11 [6144/60032 (10%)]\tLoss: 0.002410\n",
            "Train Epoch: 11 [6912/60032 (12%)]\tLoss: 0.008016\n",
            "Train Epoch: 11 [7680/60032 (13%)]\tLoss: 0.011042\n",
            "Train Epoch: 11 [8448/60032 (14%)]\tLoss: 0.008798\n",
            "Train Epoch: 11 [9216/60032 (15%)]\tLoss: 0.005098\n",
            "Train Epoch: 11 [9984/60032 (17%)]\tLoss: 0.059130\n",
            "Train Epoch: 11 [10752/60032 (18%)]\tLoss: 0.075099\n",
            "Train Epoch: 11 [11520/60032 (19%)]\tLoss: 0.006064\n",
            "Train Epoch: 11 [12288/60032 (20%)]\tLoss: 0.004983\n",
            "Train Epoch: 11 [13056/60032 (22%)]\tLoss: 0.005560\n",
            "Train Epoch: 11 [13824/60032 (23%)]\tLoss: 0.000899\n",
            "Train Epoch: 11 [14592/60032 (24%)]\tLoss: 0.023884\n",
            "Train Epoch: 11 [15360/60032 (26%)]\tLoss: 0.018012\n",
            "Train Epoch: 11 [16128/60032 (27%)]\tLoss: 0.005438\n",
            "Train Epoch: 11 [16896/60032 (28%)]\tLoss: 0.002209\n",
            "Train Epoch: 11 [17664/60032 (29%)]\tLoss: 0.004053\n",
            "Train Epoch: 11 [18432/60032 (31%)]\tLoss: 0.006172\n",
            "Train Epoch: 11 [19200/60032 (32%)]\tLoss: 0.007243\n",
            "Train Epoch: 11 [19968/60032 (33%)]\tLoss: 0.025860\n",
            "Train Epoch: 11 [20736/60032 (35%)]\tLoss: 0.002258\n",
            "Train Epoch: 11 [21504/60032 (36%)]\tLoss: 0.028277\n",
            "Train Epoch: 11 [22272/60032 (37%)]\tLoss: 0.001715\n",
            "Train Epoch: 11 [23040/60032 (38%)]\tLoss: 0.003660\n",
            "Train Epoch: 11 [23808/60032 (40%)]\tLoss: 0.018306\n",
            "Train Epoch: 11 [24576/60032 (41%)]\tLoss: 0.007112\n",
            "Train Epoch: 11 [25344/60032 (42%)]\tLoss: 0.001640\n",
            "Train Epoch: 11 [26112/60032 (43%)]\tLoss: 0.003520\n",
            "Train Epoch: 11 [26880/60032 (45%)]\tLoss: 0.022683\n",
            "Train Epoch: 11 [27648/60032 (46%)]\tLoss: 0.051230\n",
            "Train Epoch: 11 [28416/60032 (47%)]\tLoss: 0.003245\n",
            "Train Epoch: 11 [29184/60032 (49%)]\tLoss: 0.017331\n",
            "Train Epoch: 11 [29952/60032 (50%)]\tLoss: 0.007101\n",
            "Train Epoch: 11 [30720/60032 (51%)]\tLoss: 0.004996\n",
            "Train Epoch: 11 [31488/60032 (52%)]\tLoss: 0.005700\n",
            "Train Epoch: 11 [32256/60032 (54%)]\tLoss: 0.049597\n",
            "Train Epoch: 11 [33024/60032 (55%)]\tLoss: 0.017934\n",
            "Train Epoch: 11 [33792/60032 (56%)]\tLoss: 0.022352\n",
            "Train Epoch: 11 [34560/60032 (58%)]\tLoss: 0.030131\n",
            "Train Epoch: 11 [35328/60032 (59%)]\tLoss: 0.028441\n",
            "Train Epoch: 11 [36096/60032 (60%)]\tLoss: 0.007787\n",
            "Train Epoch: 11 [36864/60032 (61%)]\tLoss: 0.030681\n",
            "Train Epoch: 11 [37632/60032 (63%)]\tLoss: 0.027323\n",
            "Train Epoch: 11 [38400/60032 (64%)]\tLoss: 0.016092\n",
            "Train Epoch: 11 [39168/60032 (65%)]\tLoss: 0.035976\n",
            "Train Epoch: 11 [39936/60032 (67%)]\tLoss: 0.011978\n",
            "Train Epoch: 11 [40704/60032 (68%)]\tLoss: 0.003442\n",
            "Train Epoch: 11 [41472/60032 (69%)]\tLoss: 0.001530\n",
            "Train Epoch: 11 [42240/60032 (70%)]\tLoss: 0.011038\n",
            "Train Epoch: 11 [43008/60032 (72%)]\tLoss: 0.006495\n",
            "Train Epoch: 11 [43776/60032 (73%)]\tLoss: 0.071389\n",
            "Train Epoch: 11 [44544/60032 (74%)]\tLoss: 0.001880\n",
            "Train Epoch: 11 [45312/60032 (75%)]\tLoss: 0.035108\n",
            "Train Epoch: 11 [46080/60032 (77%)]\tLoss: 0.042378\n",
            "Train Epoch: 11 [46848/60032 (78%)]\tLoss: 0.055171\n",
            "Train Epoch: 11 [47616/60032 (79%)]\tLoss: 0.016937\n",
            "Train Epoch: 11 [48384/60032 (81%)]\tLoss: 0.005967\n",
            "Train Epoch: 11 [49152/60032 (82%)]\tLoss: 0.004881\n",
            "Train Epoch: 11 [49920/60032 (83%)]\tLoss: 0.073553\n",
            "Train Epoch: 11 [50688/60032 (84%)]\tLoss: 0.026038\n",
            "Train Epoch: 11 [51456/60032 (86%)]\tLoss: 0.005439\n",
            "Train Epoch: 11 [52224/60032 (87%)]\tLoss: 0.045250\n",
            "Train Epoch: 11 [52992/60032 (88%)]\tLoss: 0.008593\n",
            "Train Epoch: 11 [53760/60032 (90%)]\tLoss: 0.004967\n",
            "Train Epoch: 11 [54528/60032 (91%)]\tLoss: 0.014112\n",
            "Train Epoch: 11 [55296/60032 (92%)]\tLoss: 0.012003\n",
            "Train Epoch: 11 [56064/60032 (93%)]\tLoss: 0.005274\n",
            "Train Epoch: 11 [56832/60032 (95%)]\tLoss: 0.034956\n",
            "Train Epoch: 11 [57600/60032 (96%)]\tLoss: 0.018611\n",
            "Train Epoch: 11 [58368/60032 (97%)]\tLoss: 0.047854\n",
            "Train Epoch: 11 [59136/60032 (99%)]\tLoss: 0.004622\n",
            "Train Epoch: 11 [59904/60032 (100%)]\tLoss: 0.013592\n",
            "\n",
            "Test set: Average loss: 0.0280, Accuracy: 9906/10000 (99%)\n",
            "\n",
            "Train Epoch: 12 [0/60032 (0%)]\tLoss: 0.008251\n",
            "Train Epoch: 12 [768/60032 (1%)]\tLoss: 0.023814\n",
            "Train Epoch: 12 [1536/60032 (3%)]\tLoss: 0.003542\n",
            "Train Epoch: 12 [2304/60032 (4%)]\tLoss: 0.014532\n",
            "Train Epoch: 12 [3072/60032 (5%)]\tLoss: 0.004546\n",
            "Train Epoch: 12 [3840/60032 (6%)]\tLoss: 0.015176\n",
            "Train Epoch: 12 [4608/60032 (8%)]\tLoss: 0.005674\n",
            "Train Epoch: 12 [5376/60032 (9%)]\tLoss: 0.045252\n",
            "Train Epoch: 12 [6144/60032 (10%)]\tLoss: 0.010683\n",
            "Train Epoch: 12 [6912/60032 (12%)]\tLoss: 0.058823\n",
            "Train Epoch: 12 [7680/60032 (13%)]\tLoss: 0.003799\n",
            "Train Epoch: 12 [8448/60032 (14%)]\tLoss: 0.023585\n",
            "Train Epoch: 12 [9216/60032 (15%)]\tLoss: 0.003819\n",
            "Train Epoch: 12 [9984/60032 (17%)]\tLoss: 0.007504\n",
            "Train Epoch: 12 [10752/60032 (18%)]\tLoss: 0.017347\n",
            "Train Epoch: 12 [11520/60032 (19%)]\tLoss: 0.028554\n",
            "Train Epoch: 12 [12288/60032 (20%)]\tLoss: 0.054403\n",
            "Train Epoch: 12 [13056/60032 (22%)]\tLoss: 0.007126\n",
            "Train Epoch: 12 [13824/60032 (23%)]\tLoss: 0.009937\n",
            "Train Epoch: 12 [14592/60032 (24%)]\tLoss: 0.001315\n",
            "Train Epoch: 12 [15360/60032 (26%)]\tLoss: 0.006082\n",
            "Train Epoch: 12 [16128/60032 (27%)]\tLoss: 0.003480\n",
            "Train Epoch: 12 [16896/60032 (28%)]\tLoss: 0.003600\n",
            "Train Epoch: 12 [17664/60032 (29%)]\tLoss: 0.009923\n",
            "Train Epoch: 12 [18432/60032 (31%)]\tLoss: 0.006921\n",
            "Train Epoch: 12 [19200/60032 (32%)]\tLoss: 0.012293\n",
            "Train Epoch: 12 [19968/60032 (33%)]\tLoss: 0.004384\n",
            "Train Epoch: 12 [20736/60032 (35%)]\tLoss: 0.003532\n",
            "Train Epoch: 12 [21504/60032 (36%)]\tLoss: 0.013427\n",
            "Train Epoch: 12 [22272/60032 (37%)]\tLoss: 0.072333\n",
            "Train Epoch: 12 [23040/60032 (38%)]\tLoss: 0.001660\n",
            "Train Epoch: 12 [23808/60032 (40%)]\tLoss: 0.140849\n",
            "Train Epoch: 12 [24576/60032 (41%)]\tLoss: 0.011559\n",
            "Train Epoch: 12 [25344/60032 (42%)]\tLoss: 0.008796\n",
            "Train Epoch: 12 [26112/60032 (43%)]\tLoss: 0.003569\n",
            "Train Epoch: 12 [26880/60032 (45%)]\tLoss: 0.006836\n",
            "Train Epoch: 12 [27648/60032 (46%)]\tLoss: 0.005236\n",
            "Train Epoch: 12 [28416/60032 (47%)]\tLoss: 0.009645\n",
            "Train Epoch: 12 [29184/60032 (49%)]\tLoss: 0.024046\n",
            "Train Epoch: 12 [29952/60032 (50%)]\tLoss: 0.029291\n",
            "Train Epoch: 12 [30720/60032 (51%)]\tLoss: 0.009235\n",
            "Train Epoch: 12 [31488/60032 (52%)]\tLoss: 0.047861\n",
            "Train Epoch: 12 [32256/60032 (54%)]\tLoss: 0.009729\n",
            "Train Epoch: 12 [33024/60032 (55%)]\tLoss: 0.001889\n",
            "Train Epoch: 12 [33792/60032 (56%)]\tLoss: 0.002514\n",
            "Train Epoch: 12 [34560/60032 (58%)]\tLoss: 0.266142\n",
            "Train Epoch: 12 [35328/60032 (59%)]\tLoss: 0.002386\n",
            "Train Epoch: 12 [36096/60032 (60%)]\tLoss: 0.029640\n",
            "Train Epoch: 12 [36864/60032 (61%)]\tLoss: 0.021763\n",
            "Train Epoch: 12 [37632/60032 (63%)]\tLoss: 0.038041\n",
            "Train Epoch: 12 [38400/60032 (64%)]\tLoss: 0.002847\n",
            "Train Epoch: 12 [39168/60032 (65%)]\tLoss: 0.009644\n",
            "Train Epoch: 12 [39936/60032 (67%)]\tLoss: 0.011494\n",
            "Train Epoch: 12 [40704/60032 (68%)]\tLoss: 0.012323\n",
            "Train Epoch: 12 [41472/60032 (69%)]\tLoss: 0.024162\n",
            "Train Epoch: 12 [42240/60032 (70%)]\tLoss: 0.025938\n",
            "Train Epoch: 12 [43008/60032 (72%)]\tLoss: 0.001447\n",
            "Train Epoch: 12 [43776/60032 (73%)]\tLoss: 0.136042\n",
            "Train Epoch: 12 [44544/60032 (74%)]\tLoss: 0.002605\n",
            "Train Epoch: 12 [45312/60032 (75%)]\tLoss: 0.004336\n",
            "Train Epoch: 12 [46080/60032 (77%)]\tLoss: 0.002344\n",
            "Train Epoch: 12 [46848/60032 (78%)]\tLoss: 0.001850\n",
            "Train Epoch: 12 [47616/60032 (79%)]\tLoss: 0.007383\n",
            "Train Epoch: 12 [48384/60032 (81%)]\tLoss: 0.002043\n",
            "Train Epoch: 12 [49152/60032 (82%)]\tLoss: 0.004173\n",
            "Train Epoch: 12 [49920/60032 (83%)]\tLoss: 0.003458\n",
            "Train Epoch: 12 [50688/60032 (84%)]\tLoss: 0.007340\n",
            "Train Epoch: 12 [51456/60032 (86%)]\tLoss: 0.036961\n",
            "Train Epoch: 12 [52224/60032 (87%)]\tLoss: 0.022659\n",
            "Train Epoch: 12 [52992/60032 (88%)]\tLoss: 0.039334\n",
            "Train Epoch: 12 [53760/60032 (90%)]\tLoss: 0.025734\n",
            "Train Epoch: 12 [54528/60032 (91%)]\tLoss: 0.009807\n",
            "Train Epoch: 12 [55296/60032 (92%)]\tLoss: 0.005187\n",
            "Train Epoch: 12 [56064/60032 (93%)]\tLoss: 0.221546\n",
            "Train Epoch: 12 [56832/60032 (95%)]\tLoss: 0.017718\n",
            "Train Epoch: 12 [57600/60032 (96%)]\tLoss: 0.024495\n",
            "Train Epoch: 12 [58368/60032 (97%)]\tLoss: 0.012594\n",
            "Train Epoch: 12 [59136/60032 (99%)]\tLoss: 0.022282\n",
            "Train Epoch: 12 [59904/60032 (100%)]\tLoss: 0.009930\n",
            "\n",
            "Test set: Average loss: 0.0300, Accuracy: 9901/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}