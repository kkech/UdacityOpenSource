{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Seq2seq_translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-akZw-PSFv1",
        "colab_type": "code",
        "outputId": "6a4bc7f2-52a2-406a-ef1a-af05099fd4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk-SxLz5SFv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "        self.vocab = set()\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTFXdyc3Yp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        \n",
        "        self.create_index()\n",
        "                 \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word\n",
        "\n",
        "    def create_tensor(self, line=None):\n",
        "        if line:\n",
        "            return [[self.word2idx[word] for word in line.split(' ')]]\n",
        "        else:\n",
        "            return [[self.word2idx[word] for word in line.split(' ')]  for line in self.lang]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG_n1NcFSeEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "605d31ab-6fd3-45d7-8902-64c27c5f38a6"
      },
      "source": [
        "!wget http://www.manythings.org/anki/deu-eng.zip\n",
        "!unzip deu-eng.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-20 11:46:22--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4541707 (4.3M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip’\n",
            "\n",
            "\rdeu-eng.zip           0%[                    ]       0  --.-KB/s               \rdeu-eng.zip           1%[                    ]  50.41K   232KB/s               \rdeu-eng.zip           4%[                    ] 218.93K   506KB/s               \rdeu-eng.zip          20%[===>                ] 901.60K  1.35MB/s               \rdeu-eng.zip          80%[===============>    ]   3.47M  3.98MB/s               \rdeu-eng.zip         100%[===================>]   4.33M  4.90MB/s    in 0.9s    \n",
            "\n",
            "2019-08-20 11:46:24 (4.90 MB/s) - ‘deu-eng.zip’ saved [4541707/4541707]\n",
            "\n",
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSNhIUC7SFv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.,!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.,!?ßüöä€]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abdSOdMHTP5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    # Read the file and split into lines\n",
        "    lines = open('deu.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnTmBbT2SFwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUUTdDvISFwJ",
        "colab_type": "code",
        "outputId": "7a1f516c-d824-4d38-b8a2-890500a4c812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'deu', False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 195847 sentence pairs\n",
            "Trimmed to 142037 sentence pairs\n",
            "Counted words:\n",
            "eng 12606\n",
            "deu 25107\n",
            "['many teachers have a problem with tom .', 'viele lehrer haben ein problem mit tom .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "merUPgtiSFwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6YdeB4hSFwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDoagqgtSFwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRBEus8kSFwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXTgytwtSFwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ0r0BswSFwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyc7odp1SFwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=10000, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKHCaKErSFwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AcEFJVESFws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H41LgBG9SFwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('Input : ', pair[0])\n",
        "        print('Target: ', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('Output: ', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uim8kFD1SFw5",
        "colab_type": "code",
        "outputId": "8b58f28a-c70c-484a-d358-cb6893760a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 512\n",
        "# encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
        "# attn_decoder = AttnDecoder(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder, attn_decoder, 75000, print_every=500)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 38s (- 94m 54s) (500 0%) 3.2147\n",
            "1m 8s (- 85m 2s) (1000 1%) 3.1529\n",
            "1m 39s (- 81m 30s) (1500 2%) 3.2361\n",
            "2m 10s (- 79m 19s) (2000 2%) 2.9853\n",
            "2m 41s (- 77m 53s) (2500 3%) 3.0844\n",
            "3m 11s (- 76m 46s) (3000 4%) 2.9995\n",
            "3m 42s (- 75m 50s) (3500 4%) 3.0813\n",
            "4m 13s (- 75m 1s) (4000 5%) 3.0405\n",
            "4m 43s (- 74m 9s) (4500 6%) 3.0534\n",
            "5m 14s (- 73m 22s) (5000 6%) 3.1121\n",
            "5m 45s (- 72m 41s) (5500 7%) 3.0310\n",
            "6m 15s (- 72m 1s) (6000 8%) 3.0079\n",
            "6m 46s (- 71m 26s) (6500 8%) 3.0363\n",
            "7m 17s (- 70m 52s) (7000 9%) 2.9108\n",
            "7m 48s (- 70m 17s) (7500 10%) 2.9872\n",
            "8m 19s (- 69m 45s) (8000 10%) 3.0064\n",
            "8m 50s (- 69m 9s) (8500 11%) 2.8868\n",
            "9m 21s (- 68m 37s) (9000 12%) 2.9167\n",
            "9m 52s (- 68m 4s) (9500 12%) 3.0104\n",
            "10m 23s (- 67m 31s) (10000 13%) 2.9249\n",
            "10m 54s (- 66m 57s) (10500 14%) 2.9414\n",
            "11m 24s (- 66m 22s) (11000 14%) 2.8442\n",
            "11m 55s (- 65m 50s) (11500 15%) 2.9026\n",
            "12m 26s (- 65m 17s) (12000 16%) 2.9071\n",
            "12m 56s (- 64m 44s) (12500 16%) 2.8629\n",
            "13m 27s (- 64m 10s) (13000 17%) 2.8434\n",
            "13m 58s (- 63m 38s) (13500 18%) 2.9817\n",
            "14m 28s (- 63m 4s) (14000 18%) 2.9162\n",
            "14m 59s (- 62m 33s) (14500 19%) 2.8342\n",
            "15m 30s (- 62m 0s) (15000 20%) 2.8274\n",
            "16m 0s (- 61m 28s) (15500 20%) 2.8646\n",
            "16m 31s (- 60m 57s) (16000 21%) 2.8741\n",
            "17m 2s (- 60m 25s) (16500 22%) 2.8194\n",
            "17m 33s (- 59m 54s) (17000 22%) 2.7639\n",
            "18m 3s (- 59m 21s) (17500 23%) 2.8350\n",
            "18m 34s (- 58m 48s) (18000 24%) 2.7072\n",
            "19m 5s (- 58m 17s) (18500 24%) 2.7952\n",
            "19m 35s (- 57m 46s) (19000 25%) 2.7132\n",
            "20m 7s (- 57m 16s) (19500 26%) 2.8935\n",
            "20m 38s (- 56m 45s) (20000 26%) 2.9234\n",
            "21m 9s (- 56m 13s) (20500 27%) 2.7396\n",
            "21m 40s (- 55m 43s) (21000 28%) 2.7247\n",
            "22m 11s (- 55m 12s) (21500 28%) 2.7744\n",
            "22m 42s (- 54m 42s) (22000 29%) 2.7699\n",
            "23m 13s (- 54m 10s) (22500 30%) 2.7050\n",
            "23m 45s (- 53m 41s) (23000 30%) 2.7769\n",
            "24m 16s (- 53m 11s) (23500 31%) 2.7063\n",
            "24m 47s (- 52m 39s) (24000 32%) 2.7461\n",
            "25m 17s (- 52m 8s) (24500 32%) 2.6398\n",
            "25m 48s (- 51m 37s) (25000 33%) 2.7026\n",
            "26m 20s (- 51m 7s) (25500 34%) 2.7912\n",
            "26m 51s (- 50m 36s) (26000 34%) 2.7860\n",
            "27m 22s (- 50m 5s) (26500 35%) 2.7334\n",
            "27m 52s (- 49m 34s) (27000 36%) 2.6568\n",
            "28m 24s (- 49m 3s) (27500 36%) 2.8434\n",
            "28m 54s (- 48m 31s) (28000 37%) 2.7713\n",
            "29m 25s (- 48m 0s) (28500 38%) 2.7450\n",
            "29m 55s (- 47m 28s) (29000 38%) 2.5932\n",
            "30m 26s (- 46m 57s) (29500 39%) 2.7575\n",
            "30m 57s (- 46m 26s) (30000 40%) 2.6161\n",
            "31m 28s (- 45m 54s) (30500 40%) 2.6618\n",
            "31m 58s (- 45m 23s) (31000 41%) 2.7295\n",
            "32m 30s (- 44m 53s) (31500 42%) 2.6022\n",
            "33m 1s (- 44m 22s) (32000 42%) 2.7215\n",
            "33m 32s (- 43m 51s) (32500 43%) 2.6189\n",
            "34m 3s (- 43m 20s) (33000 44%) 2.7538\n",
            "34m 34s (- 42m 49s) (33500 44%) 2.5834\n",
            "35m 5s (- 42m 18s) (34000 45%) 2.6350\n",
            "35m 36s (- 41m 47s) (34500 46%) 2.6461\n",
            "36m 7s (- 41m 16s) (35000 46%) 2.6553\n",
            "36m 38s (- 40m 45s) (35500 47%) 2.6304\n",
            "37m 8s (- 40m 14s) (36000 48%) 2.6104\n",
            "37m 39s (- 39m 43s) (36500 48%) 2.6771\n",
            "38m 10s (- 39m 12s) (37000 49%) 2.4552\n",
            "38m 41s (- 38m 41s) (37500 50%) 2.6982\n",
            "39m 12s (- 38m 10s) (38000 50%) 2.4776\n",
            "39m 42s (- 37m 39s) (38500 51%) 2.5204\n",
            "40m 13s (- 37m 7s) (39000 52%) 2.6017\n",
            "40m 43s (- 36m 35s) (39500 52%) 2.5642\n",
            "41m 13s (- 36m 4s) (40000 53%) 2.5307\n",
            "41m 44s (- 35m 33s) (40500 54%) 2.5197\n",
            "42m 14s (- 35m 1s) (41000 54%) 2.5196\n",
            "42m 45s (- 34m 31s) (41500 55%) 2.4194\n",
            "43m 16s (- 34m 0s) (42000 56%) 2.4777\n",
            "43m 47s (- 33m 28s) (42500 56%) 2.5568\n",
            "44m 17s (- 32m 57s) (43000 57%) 2.6139\n",
            "44m 48s (- 32m 26s) (43500 57%) 2.5782\n",
            "45m 19s (- 31m 55s) (44000 58%) 2.6362\n",
            "45m 50s (- 31m 24s) (44500 59%) 2.5538\n",
            "46m 20s (- 30m 53s) (45000 60%) 2.5509\n",
            "46m 52s (- 30m 23s) (45500 60%) 2.4270\n",
            "47m 23s (- 29m 52s) (46000 61%) 2.4854\n",
            "47m 53s (- 29m 21s) (46500 62%) 2.6523\n",
            "48m 25s (- 28m 50s) (47000 62%) 2.5012\n",
            "48m 56s (- 28m 20s) (47500 63%) 2.6030\n",
            "49m 27s (- 27m 49s) (48000 64%) 2.6477\n",
            "49m 58s (- 27m 18s) (48500 64%) 2.6102\n",
            "50m 29s (- 26m 47s) (49000 65%) 2.5608\n",
            "51m 0s (- 26m 16s) (49500 66%) 2.3896\n",
            "51m 31s (- 25m 45s) (50000 66%) 2.5961\n",
            "52m 2s (- 25m 14s) (50500 67%) 2.5018\n",
            "52m 33s (- 24m 44s) (51000 68%) 2.5807\n",
            "53m 4s (- 24m 13s) (51500 68%) 2.5226\n",
            "53m 35s (- 23m 42s) (52000 69%) 2.5110\n",
            "54m 6s (- 23m 11s) (52500 70%) 2.4803\n",
            "54m 37s (- 22m 40s) (53000 70%) 2.6194\n",
            "55m 7s (- 22m 9s) (53500 71%) 2.3717\n",
            "55m 38s (- 21m 38s) (54000 72%) 2.5410\n",
            "56m 9s (- 21m 7s) (54500 72%) 2.5302\n",
            "56m 39s (- 20m 36s) (55000 73%) 2.5920\n",
            "57m 9s (- 20m 5s) (55500 74%) 2.3885\n",
            "57m 40s (- 19m 34s) (56000 74%) 2.4543\n",
            "58m 11s (- 19m 3s) (56500 75%) 2.4633\n",
            "58m 42s (- 18m 32s) (57000 76%) 2.4637\n",
            "59m 13s (- 18m 1s) (57500 76%) 2.4516\n",
            "59m 43s (- 17m 30s) (58000 77%) 2.4800\n",
            "60m 14s (- 16m 59s) (58500 78%) 2.4597\n",
            "60m 45s (- 16m 28s) (59000 78%) 2.4350\n",
            "61m 15s (- 15m 57s) (59500 79%) 2.4747\n",
            "61m 46s (- 15m 26s) (60000 80%) 2.4299\n",
            "62m 17s (- 14m 55s) (60500 80%) 2.6089\n",
            "62m 47s (- 14m 24s) (61000 81%) 2.4887\n",
            "63m 18s (- 13m 53s) (61500 82%) 2.4800\n",
            "63m 48s (- 13m 22s) (62000 82%) 2.4551\n",
            "64m 18s (- 12m 51s) (62500 83%) 2.4156\n",
            "64m 49s (- 12m 20s) (63000 84%) 2.2832\n",
            "65m 20s (- 11m 50s) (63500 84%) 2.4870\n",
            "65m 51s (- 11m 19s) (64000 85%) 2.3849\n",
            "66m 21s (- 10m 48s) (64500 86%) 2.5970\n",
            "66m 52s (- 10m 17s) (65000 86%) 2.5054\n",
            "67m 22s (- 9m 46s) (65500 87%) 2.4527\n",
            "67m 53s (- 9m 15s) (66000 88%) 2.2966\n",
            "68m 24s (- 8m 44s) (66500 88%) 2.3469\n",
            "68m 55s (- 8m 13s) (67000 89%) 2.3340\n",
            "69m 26s (- 7m 42s) (67500 90%) 2.4573\n",
            "69m 57s (- 7m 12s) (68000 90%) 2.4699\n",
            "70m 28s (- 6m 41s) (68500 91%) 2.3445\n",
            "70m 58s (- 6m 10s) (69000 92%) 2.2984\n",
            "71m 29s (- 5m 39s) (69500 92%) 2.4201\n",
            "72m 0s (- 5m 8s) (70000 93%) 2.4152\n",
            "72m 32s (- 4m 37s) (70500 94%) 2.4817\n",
            "73m 2s (- 4m 6s) (71000 94%) 2.4693\n",
            "73m 33s (- 3m 36s) (71500 95%) 2.3923\n",
            "74m 3s (- 3m 5s) (72000 96%) 2.4947\n",
            "74m 34s (- 2m 34s) (72500 96%) 2.3848\n",
            "75m 5s (- 2m 3s) (73000 97%) 2.4590\n",
            "75m 35s (- 1m 32s) (73500 98%) 2.3343\n",
            "76m 5s (- 1m 1s) (74000 98%) 2.2790\n",
            "76m 36s (- 0m 30s) (74500 99%) 2.3331\n",
            "77m 7s (- 0m 0s) (75000 100%) 2.4818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G92C8upsSFw7",
        "colab_type": "code",
        "outputId": "85e889d8-f973-4b11-f573-d728825d15ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "evaluateRandomly(encoder, attn_decoder)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input :  what did tom just tell you ?\n",
            "Target:  was hat tom gerade zu euch gesagt ?\n",
            "Output:  was hat tom es dir dir ?\n",
            "\n",
            "Input :  i keep forgetting her name .\n",
            "Target:  ich vergesse immer wieder , wie sie heißt .\n",
            "Output:  ich namen ihren namen namen .\n",
            "\n",
            "Input :  tom shoved his books into his backpack .\n",
            "Target:  tom stopfte seine bucher in seinen rucksack .\n",
            "Output:  tom fahrt sein bucher bucher bucher .\n",
            "\n",
            "Input :  you owe me an explanation .\n",
            "Target:  du schuldest mir eine erklarung .\n",
            "Output:  du schuldest mir eine erklarung .\n",
            "\n",
            "Input :  the price of rice went up three percent .\n",
            "Target:  reis wurde um drei prozent teurer .\n",
            "Output:  der prozent ist um drei drei drei .\n",
            "\n",
            "Input :  i think we need to call .\n",
            "Target:  ich glaube , wir mussen die wahlen .\n",
            "Output:  wir , wir mussen uns zu rufen .\n",
            "\n",
            "Input :  i ll go and look for tom .\n",
            "Target:  ich gehe tom suchen .\n",
            "Output:  ich werde tom gehen gehen .\n",
            "\n",
            "Input :  what s important is that you re trying .\n",
            "Target:  wichtig ist , dass du es versuchst .\n",
            "Output:  das , was du sich das du .\n",
            "\n",
            "Input :  the weather was perfect yesterday .\n",
            "Target:  das wetter war gestern perfekt .\n",
            "Output:  gestern wetter war gestern uber ein . .\n",
            "\n",
            "Input :  tom blamed the failure on mary .\n",
            "Target:  tom gab maria die schuld an dem fehlschlag .\n",
            "Output:  tom legte maria die auf . .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn4TwE4QSFw-",
        "colab_type": "code",
        "outputId": "fd1d4425-931e-4637-c416-7427848c2bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder, attn_decoder, \"i am good .\")\n",
        "print(output_words)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ich', 'bin', 'gut', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYNFPnaK4ywr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(input_string, input_lang='De'):\n",
        "    st = normalizeString(input_string)\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, st)\n",
        "    return ' '.join(output_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzhFKbH_6ejn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Save\n",
        "torch.save({\n",
        "            'in_lang': 'En',\n",
        "            'out_lang': 'De',\n",
        "            'in_lang_class': input_lang,\n",
        "            'out_lang_class': output_lang,\n",
        "            'encoder_state_dict': encoder.state_dict(),\n",
        "            'decoder_state_dict': attn_decoder.state_dict(),\n",
        "            'hidden_size': hidden_size\n",
        "            }, 'model_En')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg7lM20EWgAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({\n",
        "            'encoder_state_dict': encoder.state_dict(),\n",
        "            'hidden_size': hidden_size\n",
        "            }, 'model_Encoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fFMKZCWq7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({\n",
        "            'decoder_state_dict': attn_decoder.state_dict(),\n",
        "            'hidden_size': hidden_size\n",
        "            }, 'model_Decoder')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}